{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Word2Vec implementation skip-gram with keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "HFc_xxrGLOgZ"
   },
   "id": "HFc_xxrGLOgZ"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
      "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
      "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDr5_S0ZLOgc",
    "outputId": "f48844fa-0450-4617-d10a-acf88bd1b10d"
   },
   "id": "eDr5_S0ZLOgc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hazm import word_tokenize, Lemmatizer, Stemmer, Normalizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "SgmUyOJqpjl0"
   },
   "id": "SgmUyOJqpjl0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "UdcshJKWpjl2"
   },
   "id": "UdcshJKWpjl2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# InteractiveShell.ast_node_interactivity = \"last_expr\""
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RZZpzT2Tpjl3"
   },
   "id": "RZZpzT2Tpjl3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dataset and persian stop words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "xiADf5LmLOgg"
   },
   "id": "xiADf5LmLOgg"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with open(\"Shams_Corpus_Paper3.txt\", \"r\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "with open(\"persian_stopw.txt\", \"r\") as file:\n",
    "    raw_stop_words = file.read()\n",
    "\n",
    "stop_words = word_tokenize(raw_stop_words)\n",
    "\n",
    "\n",
    "def remove_persian_stopword(tokens):\n",
    "    # return [word for word in tokens if not word in stop_words and word and word not in proned]\n",
    "    return [word for word in tokens if not word in stop_words and word]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hFrB4avApjl4"
   },
   "id": "hFrB4avApjl4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing Part\n",
    "### Create Lemmatizer and Stemmer functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "MaquIFK8LOgh"
   },
   "id": "MaquIFK8LOgh"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    return normalizer.normalize(text)\n",
    "\n",
    "\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "\n",
    "def lemma_tokenizer(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # return [lemmatizer.lemmatize(token).split(\"#\")[0] for token in tokens]\n",
    "\n",
    "\n",
    "stemmer = Stemmer()\n",
    "\n",
    "\n",
    "def stem_tokenizer(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "nNscK8Oupjl5"
   },
   "id": "nNscK8Oupjl5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def text_normalization(text):\n",
    "    raw_text = re.sub(r\"-+|\\d+|\\s+\", \" \", text)\n",
    "    raw_text = normalize_text(raw_text)\n",
    "\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "def tokenize_text(text, type=\"lemma\"):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = remove_persian_stopword(tokens)\n",
    "    if type == \"lemma\":\n",
    "        tokens = remove_persian_stopword(lemma_tokenizer(tokens))\n",
    "    elif type == \"stem\":\n",
    "        tokens = remove_persian_stopword(stem_tokenizer(tokens))\n",
    "\n",
    "    return tokens"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "9psrEsscpjl6"
   },
   "id": "9psrEsscpjl6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word tokenize:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "aJEoZB6jLOgj"
   },
   "id": "aJEoZB6jLOgj"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   sentence  \\\n",
       "0                                 دیوان شمس تبریزی (غزلیات)   \n",
       "1                                               1001 - 1500   \n",
       "2  --------------------------------------------------------   \n",
       "3                                                      1001   \n",
       "4      آه در آن شمع منور چه بود\\tکآتش زد در دل و دل را ربود   \n",
       "5         ای زده اندر دل من آتشی\\tسوختم ای دوست بیا زود زود   \n",
       "6         صورت دل صورت مخلوق نیست\\tکز رخ دل حسن خدا رو نمود   \n",
       "7       جز شکرش نیست مرا چاره ای\\tجز لب او نیست مرا هیچ سود   \n",
       "8    یاد کن آن را که یکی صبحدم\\tاین دلم از زلف تو بندی گشود   \n",
       "9     جان من اول که بدیدم تو را\\tجان من از جان تو چیزی شنود   \n",
       "\n",
       "                                         normalized_sent  \\\n",
       "0                              دیوان شمس تبریزی (غزلیات)   \n",
       "1                                                          \n",
       "2                                                          \n",
       "3                                                          \n",
       "4    آه در آن شمع منور چه بود کآتش زد در دل و دل را ربود   \n",
       "5       ای زده اندر دل من آتشی سوختم ای دوست بیا زود زود   \n",
       "6       صورت دل صورت مخلوق نیست کز رخ دل حسن خدا رو نمود   \n",
       "7     جز شکرش نیست مرا چاره‌ای جز لب او نیست مرا هیچ سود   \n",
       "8  یاد کن آن را که یکی صبحدم این دلم از زلف تو بندی گشود   \n",
       "9   جان من اول که بدیدم تو را جان من از جان تو چیزی شنود   \n",
       "\n",
       "                                       tokens  \n",
       "0                        [دیوان, شمس, تبریزی]  \n",
       "1                                          []  \n",
       "2                                          []  \n",
       "3                                          []  \n",
       "4  [آه, شمع, منور, کآتش, زد#زن, دل, دل, ربود]  \n",
       "5    [زده, دل, آتش, سوخت#سوز, دوست, زود, زود]  \n",
       "6            [دل, رخ, دل, حسن, خدا, رو, نمود]  \n",
       "7                        [شکر, چاره, لب, سود]  \n",
       "8    [یاد, صبحدم, دل, زلف, بست#بند, گشود#گشا]  \n",
       "9                [جان, بدیدم, جان, جان, شنود]  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-92c8647b-1660-4524-9d09-f8bc1a2a8d2d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>normalized_sent</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>دیوان شمس تبریزی (غزلیات)</td>\n",
       "      <td>دیوان شمس تبریزی (غزلیات)</td>\n",
       "      <td>[دیوان, شمس, تبریزی]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001 - 1500</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--------------------------------------------------------</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>آه در آن شمع منور چه بود\\tکآتش زد در دل و دل را ربود</td>\n",
       "      <td>آه در آن شمع منور چه بود کآتش زد در دل و دل را ربود</td>\n",
       "      <td>[آه, شمع, منور, کآتش, زد#زن, دل, دل, ربود]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ای زده اندر دل من آتشی\\tسوختم ای دوست بیا زود زود</td>\n",
       "      <td>ای زده اندر دل من آتشی سوختم ای دوست بیا زود زود</td>\n",
       "      <td>[زده, دل, آتش, سوخت#سوز, دوست, زود, زود]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>صورت دل صورت مخلوق نیست\\tکز رخ دل حسن خدا رو نمود</td>\n",
       "      <td>صورت دل صورت مخلوق نیست کز رخ دل حسن خدا رو نمود</td>\n",
       "      <td>[دل, رخ, دل, حسن, خدا, رو, نمود]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>جز شکرش نیست مرا چاره ای\\tجز لب او نیست مرا هیچ سود</td>\n",
       "      <td>جز شکرش نیست مرا چاره‌ای جز لب او نیست مرا هیچ سود</td>\n",
       "      <td>[شکر, چاره, لب, سود]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>یاد کن آن را که یکی صبحدم\\tاین دلم از زلف تو بندی گشود</td>\n",
       "      <td>یاد کن آن را که یکی صبحدم این دلم از زلف تو بندی گشود</td>\n",
       "      <td>[یاد, صبحدم, دل, زلف, بست#بند, گشود#گشا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>جان من اول که بدیدم تو را\\tجان من از جان تو چیزی شنود</td>\n",
       "      <td>جان من اول که بدیدم تو را جان من از جان تو چیزی شنود</td>\n",
       "      <td>[جان, بدیدم, جان, جان, شنود]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92c8647b-1660-4524-9d09-f8bc1a2a8d2d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-92c8647b-1660-4524-9d09-f8bc1a2a8d2d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-92c8647b-1660-4524-9d09-f8bc1a2a8d2d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "data = pd.read_csv(\"Shams_Corpus_Paper3.txt\", names=[\"sentence\"])\n",
    "data[\"normalized_sent\"] = data[\"sentence\"].apply(lambda x: text_normalization(x))\n",
    "data[\"tokens\"] = data[\"normalized_sent\"].apply(lambda x: tokenize_text(x))\n",
    "data.head(10)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lWeRDkcVpjl7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "outputId": "f9ed60d0-c5d9-4414-b658-3d504d23bc1f"
   },
   "id": "lWeRDkcVpjl7"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "wkZec3twLOgj"
   },
   "id": "wkZec3twLOgj"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "37914"
      ]
     },
     "metadata": {},
     "execution_count": 18
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['دیوان', 'شمس', 'تبریزی', 'آه', 'شمع', 'منور', 'کآتش', 'زد#زن', 'دل', 'دل']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "token_df = data[\"tokens\"]\n",
    "del data\n",
    "tokens = token_df.explode().dropna().tolist()\n",
    "len(tokens)\n",
    "tokens[:10]\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "U34cEN9dpjl8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2fbea099-3cc7-4758-de82-a186f37f9688"
   },
   "id": "U34cEN9dpjl8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save tokens with pickle serializer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "5PzUuOrMLOgk"
   },
   "id": "5PzUuOrMLOgk"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"tokens_df_moreth2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(token_df, f)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MDq2nP1mpjl9"
   },
   "id": "MDq2nP1mpjl9"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def concat(*iterables):\n",
    "    for iterable in iterables:\n",
    "        yield from iterable"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kU1FF5utpjl-"
   },
   "id": "kU1FF5utpjl-"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# def generate_training_data(tokens, word_to_id, window):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     n_tokens = len(tokens)\n",
    "#     unique_tokens = len(word_to_id)\n",
    "#     for i in range(n_tokens):\n",
    "#         idx = concat(\n",
    "#             range(max(0, i - window), i), range(i, min(n_tokens, i + window + 1))\n",
    "#         )\n",
    "#         for j in idx:\n",
    "#             if i == j:\n",
    "#                 continue\n",
    "#             X.append(word_to_id[tokens[i]] - 1)\n",
    "#             y.append(word_to_id[tokens[j]] - 1)\n",
    "\n",
    "#     return np.asarray(X), np.asarray(y)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7v_7yt9opjl_"
   },
   "id": "7v_7yt9opjl_"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def generate_data(series, word_to_id, window):\n",
    "    X = []\n",
    "    y = []\n",
    "    for index, tokens in series.items():\n",
    "        n_tokens = len(tokens)\n",
    "        for i in range(n_tokens):\n",
    "            idx = concat(\n",
    "                range(max(0, i - window), i),\n",
    "                range(i, min(n_tokens, i + window + 1))\n",
    "            )\n",
    "            for j in idx:\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                X.append(word_to_id[tokens[i]] - 1)\n",
    "                y.append(word_to_id[tokens[j]] - 1)\n",
    "\n",
    "    return np.asarray(X), np.asarray(y)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "a4X7JnqapjmA"
   },
   "id": "a4X7JnqapjmA"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### generate training data with specified window size\n",
    "#### create word to id and id to word list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "vmQCYjkYLOgl"
   },
   "id": "vmQCYjkYLOgl"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "window_size = 2\n",
    "\n",
    "t = Tokenizer(filters=\"\")\n",
    "t.fit_on_texts(tokens)\n",
    "\n",
    "sorted_count_list = sorted(t.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "word_to_id, id_to_word = t.word_index, t.index_word\n",
    "\n",
    "# X, y = generate_training_data(tokens, word_to_id, window_size)\n",
    "X_sen, y_sen = generate_data(token_df, word_to_id, window_size)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "X-vDeQJjpjmB"
   },
   "id": "X-vDeQJjpjmB"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### delete useless variables cause of lack memory :(("
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "vgzMdHeZLOgm"
   },
   "id": "vgzMdHeZLOgm"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(120272,)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(120272,)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-574de420b70b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0my_sen\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mdel\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mdel\u001B[0m \u001B[0mX_onehot_encoded\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;32mdel\u001B[0m \u001B[0my_onehot_encoded\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_onehot_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "# del X_onehot_encoded\n",
    "# del y_onehot_encoded\n",
    "X_sen.shape\n",
    "y_sen.shape\n",
    "del t\n",
    "del X_onehot_encoded\n",
    "del y_onehot_encoded"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Zdb-9QFypjmB",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "outputId": "cc919242-3486-40b4-ac86-88a58dce2ccd"
   },
   "id": "Zdb-9QFypjmB"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# for i in sorted_count_list:\n",
    "#     if '#' in i[0]:\n",
    "#         print(i)\n",
    "# sorted_count_list[:40]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NcnNnNXhpjmC"
   },
   "id": "NcnNnNXhpjmC"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find less frequent words in corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "SNL9aFWLLOgm"
   },
   "id": "SNL9aFWLLOgm"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "proned = []\n",
    "for i in sorted_count_list:\n",
    "    if i[1] < 3:\n",
    "        proned.append(i[0])\n",
    "stop_words.extend(proned)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "txIAZzUhpjmD"
   },
   "id": "txIAZzUhpjmD"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(120272,)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# X.shape\n",
    "X_sen.shape"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RWwc42glpjmD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5cf3435d-c193-45c1-9979-3adf4a7b6718"
   },
   "id": "RWwc42glpjmD"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Onehot train and test tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "di0vRvqYLOgn"
   },
   "id": "di0vRvqYLOgn"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# echo 1 > /proc/sys/vm/overcommit_memory\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(X_sen)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "one_hotter = onehot_encoder.fit(integer_encoded)\n",
    "X_onehot_encoded = one_hotter.transform(integer_encoded)\n",
    "del X_sen\n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(y_sen)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y_onehot_encoded = one_hotter.transform(integer_encoded)\n",
    "del y_sen"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "yiFaTi0BpjmD"
   },
   "id": "yiFaTi0BpjmD"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"one_hot_encoder.pkl\", \"wb\") as f: \n",
    "#     pickle.dump(one_hotter, f)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "J8-Yeel_pjmE"
   },
   "id": "J8-Yeel_pjmE"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(120272, 2575)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "y_onehot_encoded.shape"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KurddO8opjmE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fc349977-94c4-4a6a-9a6d-2593b4e55255"
   },
   "id": "KurddO8opjmE"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(120272, 2575)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "X_onehot_encoded.shape"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "WCciI_cjpjmF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ada6e378-10f0-4264-b1ee-18f91cb88811"
   },
   "id": "WCciI_cjpjmF"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "del integer_encoded"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "UjCJmNNCpjmF"
   },
   "id": "UjCJmNNCpjmF"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create network model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "w2qFn1ZlLOgo"
   },
   "id": "w2qFn1ZlLOgo"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2575)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               257600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2575)              260075    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 517,675\n",
      "Trainable params: 517,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Dense\n",
    "\n",
    "opt = 'adam'\n",
    "embed_size = 100\n",
    "vocab_size = X_onehot_encoded.shape[1]\n",
    "\n",
    "input_layer = Input(shape=(vocab_size,))\n",
    "embed_layer = Dense(units=embed_size, activation=\"linear\")(input_layer)\n",
    "output_layer = Dense(units=vocab_size, activation=\"softmax\")(embed_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy', 'mse'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "riO6bAwEpjmG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fc92b62e-6d37-4c9d-e340-f9a82276944e"
   },
   "id": "riO6bAwEpjmG"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Learn network :"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Kh-qE8-HLOgp"
   },
   "id": "Kh-qE8-HLOgp"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "940/940 [==============================] - 8s 5ms/step - loss: 7.1247 - accuracy: 0.0196 - mse: 3.8752e-04\n",
      "Epoch 2/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 6.9849 - accuracy: 0.0233 - mse: 3.8719e-04\n",
      "Epoch 3/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 6.9039 - accuracy: 0.0305 - mse: 3.8682e-04\n",
      "Epoch 4/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 6.7563 - accuracy: 0.0389 - mse: 3.8642e-04\n",
      "Epoch 5/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 6.5591 - accuracy: 0.0471 - mse: 3.8589e-04\n",
      "Epoch 6/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 6.3495 - accuracy: 0.0542 - mse: 3.8532e-04\n",
      "Epoch 7/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 6.1511 - accuracy: 0.0580 - mse: 3.8475e-04\n",
      "Epoch 8/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.9732 - accuracy: 0.0611 - mse: 3.8420e-04\n",
      "Epoch 9/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.8170 - accuracy: 0.0619 - mse: 3.8373e-04\n",
      "Epoch 10/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.6812 - accuracy: 0.0623 - mse: 3.8331e-04\n",
      "Epoch 11/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.5625 - accuracy: 0.0621 - mse: 3.8290e-04\n",
      "Epoch 12/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.4586 - accuracy: 0.0621 - mse: 3.8254e-04\n",
      "Epoch 13/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.3672 - accuracy: 0.0622 - mse: 3.8220e-04\n",
      "Epoch 14/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.2870 - accuracy: 0.0623 - mse: 3.8189e-04\n",
      "Epoch 15/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.2155 - accuracy: 0.0618 - mse: 3.8161e-04\n",
      "Epoch 16/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.1522 - accuracy: 0.0630 - mse: 3.8137e-04\n",
      "Epoch 17/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.0953 - accuracy: 0.0629 - mse: 3.8113e-04\n",
      "Epoch 18/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.0451 - accuracy: 0.0625 - mse: 3.8094e-04\n",
      "Epoch 19/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 5.0000 - accuracy: 0.0627 - mse: 3.8076e-04\n",
      "Epoch 20/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.9594 - accuracy: 0.0631 - mse: 3.8061e-04\n",
      "Epoch 21/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.9233 - accuracy: 0.0624 - mse: 3.8048e-04\n",
      "Epoch 22/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.8911 - accuracy: 0.0620 - mse: 3.8038e-04\n",
      "Epoch 23/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.8619 - accuracy: 0.0617 - mse: 3.8029e-04\n",
      "Epoch 24/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.8355 - accuracy: 0.0618 - mse: 3.8020e-04\n",
      "Epoch 25/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.8120 - accuracy: 0.0611 - mse: 3.8013e-04\n",
      "Epoch 26/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.7904 - accuracy: 0.0603 - mse: 3.8010e-04\n",
      "Epoch 27/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.7707 - accuracy: 0.0616 - mse: 3.8006e-04\n",
      "Epoch 28/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.7530 - accuracy: 0.0609 - mse: 3.8004e-04\n",
      "Epoch 29/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.7363 - accuracy: 0.0606 - mse: 3.7998e-04\n",
      "Epoch 30/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.7218 - accuracy: 0.0605 - mse: 3.7998e-04\n",
      "Epoch 31/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.7081 - accuracy: 0.0604 - mse: 3.7996e-04\n",
      "Epoch 32/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6949 - accuracy: 0.0604 - mse: 3.7993e-04\n",
      "Epoch 33/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6836 - accuracy: 0.0604 - mse: 3.7995e-04\n",
      "Epoch 34/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6725 - accuracy: 0.0600 - mse: 3.7991e-04\n",
      "Epoch 35/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6622 - accuracy: 0.0602 - mse: 3.7992e-04\n",
      "Epoch 36/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6529 - accuracy: 0.0600 - mse: 3.7993e-04\n",
      "Epoch 37/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6442 - accuracy: 0.0600 - mse: 3.7994e-04\n",
      "Epoch 38/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6359 - accuracy: 0.0597 - mse: 3.7993e-04\n",
      "Epoch 39/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6279 - accuracy: 0.0599 - mse: 3.7994e-04\n",
      "Epoch 40/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6210 - accuracy: 0.0593 - mse: 3.7993e-04\n",
      "Epoch 41/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6138 - accuracy: 0.0597 - mse: 3.7994e-04\n",
      "Epoch 42/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6073 - accuracy: 0.0596 - mse: 3.7994e-04\n",
      "Epoch 43/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.6011 - accuracy: 0.0592 - mse: 3.7995e-04\n",
      "Epoch 44/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5952 - accuracy: 0.0590 - mse: 3.7995e-04\n",
      "Epoch 45/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5900 - accuracy: 0.0590 - mse: 3.7996e-04\n",
      "Epoch 46/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5845 - accuracy: 0.0588 - mse: 3.7996e-04\n",
      "Epoch 47/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5797 - accuracy: 0.0587 - mse: 3.7998e-04\n",
      "Epoch 48/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5748 - accuracy: 0.0584 - mse: 3.8000e-04\n",
      "Epoch 49/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5704 - accuracy: 0.0590 - mse: 3.7998e-04\n",
      "Epoch 50/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5661 - accuracy: 0.0585 - mse: 3.8000e-04\n",
      "Epoch 51/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5619 - accuracy: 0.0583 - mse: 3.8000e-04\n",
      "Epoch 52/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5580 - accuracy: 0.0590 - mse: 3.8001e-04\n",
      "Epoch 53/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5545 - accuracy: 0.0581 - mse: 3.8005e-04\n",
      "Epoch 54/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5506 - accuracy: 0.0586 - mse: 3.8003e-04\n",
      "Epoch 55/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5471 - accuracy: 0.0583 - mse: 3.8003e-04\n",
      "Epoch 56/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5438 - accuracy: 0.0580 - mse: 3.8005e-04\n",
      "Epoch 57/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5407 - accuracy: 0.0584 - mse: 3.8006e-04\n",
      "Epoch 58/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5377 - accuracy: 0.0578 - mse: 3.8008e-04\n",
      "Epoch 59/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5348 - accuracy: 0.0583 - mse: 3.8008e-04\n",
      "Epoch 60/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5319 - accuracy: 0.0583 - mse: 3.8007e-04\n",
      "Epoch 61/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5290 - accuracy: 0.0583 - mse: 3.8008e-04\n",
      "Epoch 62/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5263 - accuracy: 0.0577 - mse: 3.8010e-04\n",
      "Epoch 63/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5239 - accuracy: 0.0577 - mse: 3.8012e-04\n",
      "Epoch 64/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5214 - accuracy: 0.0579 - mse: 3.8010e-04\n",
      "Epoch 65/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5192 - accuracy: 0.0574 - mse: 3.8013e-04\n",
      "Epoch 66/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5169 - accuracy: 0.0575 - mse: 3.8013e-04\n",
      "Epoch 67/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5147 - accuracy: 0.0574 - mse: 3.8014e-04\n",
      "Epoch 68/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5127 - accuracy: 0.0576 - mse: 3.8016e-04\n",
      "Epoch 69/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5107 - accuracy: 0.0573 - mse: 3.8018e-04\n",
      "Epoch 70/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5086 - accuracy: 0.0571 - mse: 3.8018e-04\n",
      "Epoch 71/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5065 - accuracy: 0.0574 - mse: 3.8017e-04\n",
      "Epoch 72/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5046 - accuracy: 0.0574 - mse: 3.8017e-04\n",
      "Epoch 73/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5030 - accuracy: 0.0577 - mse: 3.8019e-04\n",
      "Epoch 74/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.5012 - accuracy: 0.0575 - mse: 3.8019e-04\n",
      "Epoch 75/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4995 - accuracy: 0.0573 - mse: 3.8021e-04\n",
      "Epoch 76/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4977 - accuracy: 0.0574 - mse: 3.8020e-04\n",
      "Epoch 77/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4962 - accuracy: 0.0565 - mse: 3.8021e-04\n",
      "Epoch 78/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4945 - accuracy: 0.0573 - mse: 3.8022e-04\n",
      "Epoch 79/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4931 - accuracy: 0.0571 - mse: 3.8022e-04\n",
      "Epoch 80/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4915 - accuracy: 0.0574 - mse: 3.8022e-04\n",
      "Epoch 81/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4902 - accuracy: 0.0574 - mse: 3.8024e-04\n",
      "Epoch 82/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4888 - accuracy: 0.0573 - mse: 3.8025e-04\n",
      "Epoch 83/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4877 - accuracy: 0.0570 - mse: 3.8028e-04\n",
      "Epoch 84/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4862 - accuracy: 0.0563 - mse: 3.8026e-04\n",
      "Epoch 85/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4850 - accuracy: 0.0569 - mse: 3.8028e-04\n",
      "Epoch 86/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4838 - accuracy: 0.0570 - mse: 3.8028e-04\n",
      "Epoch 87/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4823 - accuracy: 0.0570 - mse: 3.8029e-04\n",
      "Epoch 88/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4813 - accuracy: 0.0567 - mse: 3.8028e-04\n",
      "Epoch 89/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4798 - accuracy: 0.0574 - mse: 3.8028e-04\n",
      "Epoch 90/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4790 - accuracy: 0.0567 - mse: 3.8031e-04\n",
      "Epoch 91/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4777 - accuracy: 0.0567 - mse: 3.8030e-04\n",
      "Epoch 92/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4769 - accuracy: 0.0571 - mse: 3.8031e-04\n",
      "Epoch 93/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4758 - accuracy: 0.0570 - mse: 3.8032e-04\n",
      "Epoch 94/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4745 - accuracy: 0.0572 - mse: 3.8031e-04\n",
      "Epoch 95/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4736 - accuracy: 0.0561 - mse: 3.8032e-04\n",
      "Epoch 96/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4726 - accuracy: 0.0561 - mse: 3.8033e-04\n",
      "Epoch 97/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4717 - accuracy: 0.0571 - mse: 3.8035e-04\n",
      "Epoch 98/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4709 - accuracy: 0.0564 - mse: 3.8035e-04\n",
      "Epoch 99/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4700 - accuracy: 0.0568 - mse: 3.8036e-04\n",
      "Epoch 100/100\n",
      "940/940 [==============================] - 5s 5ms/step - loss: 4.4691 - accuracy: 0.0571 - mse: 3.8035e-04\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc77785f910>"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "epochs_ = 100\n",
    "model.fit(x=X_onehot_encoded, y=y_onehot_encoded, batch_size=128, epochs=epochs_, verbose=1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "aEhCk3p0pjmG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "37360ca2-4b6d-4495-8820-59123d76743e"
   },
   "id": "aEhCk3p0pjmG"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "58T8opbsLOgp"
   },
   "id": "58T8opbsLOgp"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def n_similar(words, model_, n=10):\n",
    "    for word in words:\n",
    "      word_id = word_to_id[word]\n",
    "      one_hot = one_hotter.transform(np.array([[word_id]]))\n",
    "      result = model_.predict([one_hot]).squeeze()\n",
    "      similars = []\n",
    "      for similar in (id_to_word[id + 1] for id in np.argsort(result)[::-1][:n]):\n",
    "          similars.append(similar)\n",
    "      print(word, '=', similars)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "UK_inNUtpjmH"
   },
   "id": "UK_inNUtpjmH"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "خلق = ['رنگ', 'گل', 'دم', 'دانست#دان', 'جان', 'جگر', 'بو', 'یار', 'سفر', 'یافت#یاب']\n",
      "آتش = ['شکر', 'دل', 'لب', 'تنگ', 'عشق', 'جان', 'شهد', 'کان', 'پر', 'خوش']\n",
      "شادی = ['مست', 'دل', 'میان', 'خویش', 'حقست', 'زیر', 'موسی', 'آفتاب', 'قسمت', 'التیه']\n"
     ]
    }
   ],
   "source": [
    "n_similar(['خلق', 'آتش', 'شادی'], model, n=10)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "b1gd4HanpjmH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dee1d314-adb1-4919-da6e-042362bc824f"
   },
   "id": "b1gd4HanpjmH"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "mfaYGrzALOgx"
   },
   "id": "mfaYGrzALOgx"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(f'mdl_em{embed_size}_ep{epochs_}_vocs{vocab_size}_ws{window_size}_opt{opt}.h5')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "heWoDPS1pjmI"
   },
   "id": "heWoDPS1pjmI"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create word2vec model with pure python:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "6krx4ljMLOgx"
   },
   "id": "6krx4ljMLOgx"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_network(vocab_size, n_embedding):\n",
    "    model = {\n",
    "        \"w1\": np.random.uniform(-1, 1, (vocab_size, n_embedding)),\n",
    "        \"w2\": np.random.uniform(-1, 1, (n_embedding, vocab_size))\n",
    "    }\n",
    "    return model"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MKjD_vNgpjmI"
   },
   "id": "MKjD_vNgpjmI"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = init_network(len(word_to_id), 10)\n",
    "model[\"w1\"].shape"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qqllL3G_pjmJ"
   },
   "id": "qqllL3G_pjmJ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model[\"w2\"].shape"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3QA19E1FpjmJ"
   },
   "id": "3QA19E1FpjmJ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    #     e_x = np.exp(x - np.max(x))\n",
    "    #     return e_x / e_x.sum(axis=0)\n",
    "\n",
    "    res = []\n",
    "    for x in X:\n",
    "        exp = np.exp(x)\n",
    "        res.append(exp / exp.sum())\n",
    "    return res"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "8r39d3VwpjmJ"
   },
   "id": "8r39d3VwpjmJ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def stable_sigmoid(x):\n",
    "    sig = np.where(x < 0, np.exp(x) / (1 + np.exp(x)), 1 / (1 + np.exp(-x)))\n",
    "    return sig"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NcPjJCyIpjmK"
   },
   "id": "NcPjJCyIpjmK"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hp-L7i0BpjmK"
   },
   "id": "hp-L7i0BpjmK"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(X @ model[\"w1\"]).shape"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "CjpjqrzxpjmK"
   },
   "id": "CjpjqrzxpjmK"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(X @ model[\"w1\"] @ model[\"w2\"]).shape\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "PXHVK5otpjmK"
   },
   "id": "PXHVK5otpjmK"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def forward(model, X, return_cache=True):\n",
    "    cache = {}\n",
    "\n",
    "    cache[\"a1\"] = X @ model[\"w1\"]\n",
    "    cache[\"a2\"] = cache[\"a1\"] @ model[\"w2\"]\n",
    "    print(f\"a2 = {cache['a2']}\")\n",
    "    cache[\"z\"] = softmax(cache[\"a2\"])\n",
    "    #     cache[\"z\"] = stable_sigmoid(cache[\"a2\"])\n",
    "\n",
    "    if not return_cache:\n",
    "        return cache[\"z\"]\n",
    "    return cache"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "59PBfArmpjmL"
   },
   "id": "59PBfArmpjmL"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cross_entropy(z, y):\n",
    "    return - np.sum(np.log(z) * y)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "6QBTRWFLpjmL"
   },
   "id": "6QBTRWFLpjmL"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def backward(model, X, y, alpha):\n",
    "    cache = forward(model, X)\n",
    "    #     dl_weight_inp_hidden = np.outer(target_word_vector, np.dot(weight_hidden_output, total_error.T))\n",
    "    #     dl_weight_hidden_output = np.outer(hidden_layer, total_error)\n",
    "    da2 = cache[\"z\"] - y\n",
    "    dw2 = cache[\"a1\"].T @ da2\n",
    "    da1 = da2 @ model[\"w2\"].T\n",
    "    dw1 = X.T @ da1\n",
    "    assert (dw2.shape == model[\"w2\"].shape)\n",
    "    assert (dw1.shape == model[\"w1\"].shape)\n",
    "    model[\"w1\"] -= alpha * dw1\n",
    "    model[\"w2\"] -= alpha * dw2\n",
    "\n",
    "    return cross_entropy(cache[\"z\"], y)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3eb2fzmQpjmL"
   },
   "id": "3eb2fzmQpjmL"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "% config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "model = init_network(len(word_to_id), 10)\n",
    "\n",
    "n_iter = 100\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "history = [backward(model, X, y, learning_rate) for _ in range(n_iter)]\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(range(len(history)), history, color=\"skyblue\")\n",
    "plt.show()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "algo-gL0pjmM"
   },
   "id": "algo-gL0pjmM"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "oD2SjzlUpjmM"
   },
   "id": "oD2SjzlUpjmM"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rLIGbEerpjmM"
   },
   "id": "rLIGbEerpjmM"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learning = one_hot_encode(word_to_id[\"گرم\"], len(word_to_id))\n",
    "result = forward(model, [learning], return_cache=False)[0]\n",
    "result"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ApBljDqmpjmN"
   },
   "id": "ApBljDqmpjmN"
  },
  {
   "cell_type": "raw",
   "source": [
    "np.argsort(result)[::-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% raw\n"
    },
    "id": "K9Yztq6SpjmN"
   },
   "id": "K9Yztq6SpjmN"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.argsort(result)[::-1][0:5]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Q29aqvWnpjmO"
   },
   "id": "Q29aqvWnpjmO"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for word in (id_to_word[id] for id in np.argsort(result)[::-1][0:10]):\n",
    "    print(word)\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-4xt4X_ypjmO"
   },
   "id": "-4xt4X_ypjmO"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_word_similarities(word, model, n_similars=10):\n",
    "    try:\n",
    "        learning = one_hot_encode(word_to_id[word] - 1, len(word_to_id))\n",
    "    except KeyError:\n",
    "        print(f\"Word = {word} is not in corpus\")\n",
    "        exit()\n",
    "    result = forward(model, [learning], return_cache=False)[0]\n",
    "    for word in (id_to_word[id + 1] for id in np.argsort(result)[::-1][0:n_similars]):\n",
    "        print(word)\n",
    "\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "5ltvFUr4pjmP"
   },
   "id": "5ltvFUr4pjmP"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_embedding(model, word):\n",
    "    try:\n",
    "        idx = word_to_id[word] - 1\n",
    "    except KeyError:\n",
    "        print(\"`word` not in corpus\")\n",
    "    one_hot = one_hot_encode(idx, len(word_to_id))\n",
    "    return forward(model, one_hot)[\"a1\"]"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "CBlu5oIFpjmP"
   },
   "id": "CBlu5oIFpjmP"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_embedding(model, \"دیو\")\n"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "e3s7PjVGpjmQ"
   },
   "id": "e3s7PjVGpjmQ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_word_similarities('عیش', model, 10)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "jz83FdBkpjmQ"
   },
   "id": "jz83FdBkpjmQ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_word_similarities('میخانه', model, 10)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "TvP65sDUpjmQ"
   },
   "id": "TvP65sDUpjmQ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_word_similarities('بشر', model, 10)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "53JPB5eQpjmQ"
   },
   "id": "53JPB5eQpjmQ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_word_similarities('ویرانه', model, 10)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "E9LKYt27pjmR"
   },
   "id": "E9LKYt27pjmR"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_word_similarities('حلال', model, 10)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Glsp9R9kpjmR"
   },
   "id": "Glsp9R9kpjmR"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "colab": {
   "name": "word2vec_colab_imp_final.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}