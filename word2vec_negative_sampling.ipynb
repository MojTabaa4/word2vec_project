{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "yv6cKm2Rmqb0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create word2vec model with negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "zEgJ3eu3mqb5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install packages and adjust setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITPPO3_3mqb6",
    "outputId": "5a82b1e7-1c3c-49a9-b282-8a5d6a37facc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting hazm\n",
      "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
      "\u001B[K     |████████████████████████████████| 316 kB 26.8 MB/s \n",
      "\u001B[?25hCollecting nltk==3.3\n",
      "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.4 MB 71.2 MB/s \n",
      "\u001B[?25hCollecting libwapiti>=0.2.1\n",
      "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
      "\u001B[K     |████████████████████████████████| 233 kB 62.0 MB/s \n",
      "\u001B[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
      "Building wheels for collected packages: nltk, libwapiti\n",
      "  Building wheel for nltk (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394485 sha256=74f67cd8301f81a7f7cd7cf5b5856c8112813365760119a7b216dff93cf95b25\n",
      "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
      "  Building wheel for libwapiti (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154103 sha256=6a9af7208b18723300cc2ba1dc8444b4882c2350a1f27b3331b1bdcab92f60d2\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
      "Successfully built nltk libwapiti\n",
      "Installing collected packages: nltk, libwapiti, hazm\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7TX9x9xmqb8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from hazm import word_tokenize, Lemmatizer, Stemmer, Normalizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-84iio8mqb9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5N8IXp-mqb9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "sd_XMPDZmqb-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import corpus and persian stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_9l0K4mmqb_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data.txt\", \"r\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "with open(\"persian_stopw.txt\", \"r\") as file:\n",
    "    raw_stop_words = file.read()\n",
    "\n",
    "stop_words = word_tokenize(raw_stop_words)\n",
    "\n",
    "\n",
    "def remove_persian_stopword(tokens):\n",
    "    # return [word for word in tokens if not word in stop_words and word and word not in proned]\n",
    "    return [word for word in tokens if not word in stop_words and word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNHK7wdnmqb_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "lemmatizer = Lemmatizer()\n",
    "stemmer = Stemmer()\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    return normalizer.normalize(text)\n",
    "\n",
    "\n",
    "def lemma_tokenizer(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    # return [lemmatizer.lemmatize(token).split(\"#\")[0] for token in tokens]\n",
    "\n",
    "\n",
    "def stem_tokenizer(tokens):\n",
    "    return [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SIDwdtEXmqcA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def text_normalization(text):\n",
    "    raw_text = re.sub(r\"-+|\\d+|\\s+\", \" \", text)\n",
    "    raw_text = normalize_text(raw_text)\n",
    "\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "def tokenize_text(text, type=\"lemma\"):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = remove_persian_stopword(tokens)\n",
    "    if type == \"lemma\":\n",
    "        tokens = remove_persian_stopword(lemma_tokenizer(tokens))\n",
    "    elif type == \"stem\":\n",
    "        tokens = remove_persian_stopword(stem_tokenizer(tokens))\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "iqfaZbegmqcA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create tokens dataframe (normalized + lemmatized + removed persian stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "id": "kw-nhVjFmqcB",
    "outputId": "7790d2be-35b3-4d46-dfa8-5019491f031f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                                                    sentence  \\\n",
       "0                                                                                          1   \n",
       "1                   ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی افروخته، در بیشه ی اندیشه ها   \n",
       "2                   امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندان آمدی، چون بخشش و فضل خدا   \n",
       "3            خورشید را حاجب تویی، امید را واجب تویی\\tمطلب تویی طالب تویی، هم منتها، هم مبتدا   \n",
       "4              در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش حاجت خواسته، هم خویشتن کرده روا   \n",
       "5         ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی بهانه ست و دغل، کاین علت آمد، وآن دوا   \n",
       "6       ما زان دغل کژ بین شده، با بی گنه در کین شده\\tگه مست حورالعین شده، گه مست نان و شوربا   \n",
       "7  این سُکر بین، هل عقل را، وین ُنقل بین، هل َنقل را\\tکز بهر نان و بقل را، چندین نشاید ماجرا   \n",
       "8          تدبیر صد رنگ افکنی، بر روم و بر زنگ افکنی\\tواندر میان جنگ افکنی، فی اصطناع لا یری   \n",
       "9          میمال پنهان گوش جان، مینه بهانه بر کسان\\tجان رب خلصنی زنان، والله که لاغست ای کیا   \n",
       "\n",
       "                                                                         normalized_sent  \\\n",
       "0                                                                                          \n",
       "1                ای رستخیز ناگهان، وی رحمت بی منتها ای آتشی افروخته، در بیشه‌ی اندیشه‌ها   \n",
       "2                امروز خندان آمدی، مفتاح زندان آمدی بر مستمندان آمدی، چون بخشش و فضل خدا   \n",
       "3         خورشید را حاجب تویی، امید را واجب تویی مطلب تویی طالب تویی، هم منتها، هم مبتدا   \n",
       "4           در سینه‌ها برخاسته، اندیشه را آراسته هم خویش حاجت خواسته، هم خویشتن کرده روا   \n",
       "5         ای روح بخش بی بدل، وی لذت علم و عمل باقی بهانه ست و دغل، کاین علت آمد، وآن دوا   \n",
       "6    ما زان دغل کژ بین شده، با بی گنه در کین شده گه مست حورالعین شده، گه مست نان و شوربا   \n",
       "7  این سکر بین، هل عقل را، وین نقل بین، هل نقل را کز بهر نان و بقل را، چندین نشاید ماجرا   \n",
       "8       تدبیر صد رنگ افکنی، بر روم و بر زنگ افکنی واندر میان جنگ افکنی، فی اصطناع لا یری   \n",
       "9       میمال پنهان گوش جان، مینه بهانه بر کسان جان رب خلصنی زنان، والله که لاغست ای کیا   \n",
       "\n",
       "                                                                               tokens  \n",
       "0                                                                                  []  \n",
       "1                           [رستخیز, ناگهان, رحمت, منتها, آتش, افروخته, بیشه, اندیشه]  \n",
       "2                                       [خندان, مفتاح, زندان, مستمند, بخشش, فضل, خدا]  \n",
       "3                                [خورشید, حاجب, امید, واجب, مطلب, طالب, منتها, مبتدا]  \n",
       "4              [سینه, برخاسته, اندیشه, آراسته, خویش, حاجت, خواسته, خویشتن, کرده, روا]  \n",
       "5               [روح, بخش, بدل, لذت, علم, عمل, باقی, بهانه, دغل, کاین, علت, وآن, دوا]  \n",
       "6                    [دغل, کژ, بین, گنه, کین, گه, مست, حورالعین, گه, مست, نان, شوربا]  \n",
       "7            [سکر, بین, هل, عقل, وین, نقل, بین, هل, نقل, بهر, نان, بقل, نشاید, ماجرا]  \n",
       "8  [تدبیر, صد, رنگ, افکنی, روم, زنگ, افکنی, واندر, میان, جنگ, افکنی, اصطناع, لا, یری]  \n",
       "9        [میمال, پنهان, گوش, جان, مینه, بهانه, جان, رب, خلصنی, زن, والله, لاغست, کیا]  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-5cb9ec50-d5c2-4b61-b2e7-79ceb1214d94\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>normalized_sent</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی افروخته، در بیشه ی اندیشه ها</td>\n",
       "      <td>ای رستخیز ناگهان، وی رحمت بی منتها ای آتشی افروخته، در بیشه‌ی اندیشه‌ها</td>\n",
       "      <td>[رستخیز, ناگهان, رحمت, منتها, آتش, افروخته, بیشه, اندیشه]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندان آمدی، چون بخشش و فضل خدا</td>\n",
       "      <td>امروز خندان آمدی، مفتاح زندان آمدی بر مستمندان آمدی، چون بخشش و فضل خدا</td>\n",
       "      <td>[خندان, مفتاح, زندان, مستمند, بخشش, فضل, خدا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>خورشید را حاجب تویی، امید را واجب تویی\\tمطلب تویی طالب تویی، هم منتها، هم مبتدا</td>\n",
       "      <td>خورشید را حاجب تویی، امید را واجب تویی مطلب تویی طالب تویی، هم منتها، هم مبتدا</td>\n",
       "      <td>[خورشید, حاجب, امید, واجب, مطلب, طالب, منتها, مبتدا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش حاجت خواسته، هم خویشتن کرده روا</td>\n",
       "      <td>در سینه‌ها برخاسته، اندیشه را آراسته هم خویش حاجت خواسته، هم خویشتن کرده روا</td>\n",
       "      <td>[سینه, برخاسته, اندیشه, آراسته, خویش, حاجت, خواسته, خویشتن, کرده, روا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی بهانه ست و دغل، کاین علت آمد، وآن دوا</td>\n",
       "      <td>ای روح بخش بی بدل، وی لذت علم و عمل باقی بهانه ست و دغل، کاین علت آمد، وآن دوا</td>\n",
       "      <td>[روح, بخش, بدل, لذت, علم, عمل, باقی, بهانه, دغل, کاین, علت, وآن, دوا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ما زان دغل کژ بین شده، با بی گنه در کین شده\\tگه مست حورالعین شده، گه مست نان و شوربا</td>\n",
       "      <td>ما زان دغل کژ بین شده، با بی گنه در کین شده گه مست حورالعین شده، گه مست نان و شوربا</td>\n",
       "      <td>[دغل, کژ, بین, گنه, کین, گه, مست, حورالعین, گه, مست, نان, شوربا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>این سُکر بین، هل عقل را، وین ُنقل بین، هل َنقل را\\tکز بهر نان و بقل را، چندین نشاید ماجرا</td>\n",
       "      <td>این سکر بین، هل عقل را، وین نقل بین، هل نقل را کز بهر نان و بقل را، چندین نشاید ماجرا</td>\n",
       "      <td>[سکر, بین, هل, عقل, وین, نقل, بین, هل, نقل, بهر, نان, بقل, نشاید, ماجرا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>تدبیر صد رنگ افکنی، بر روم و بر زنگ افکنی\\tواندر میان جنگ افکنی، فی اصطناع لا یری</td>\n",
       "      <td>تدبیر صد رنگ افکنی، بر روم و بر زنگ افکنی واندر میان جنگ افکنی، فی اصطناع لا یری</td>\n",
       "      <td>[تدبیر, صد, رنگ, افکنی, روم, زنگ, افکنی, واندر, میان, جنگ, افکنی, اصطناع, لا, یری]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>میمال پنهان گوش جان، مینه بهانه بر کسان\\tجان رب خلصنی زنان، والله که لاغست ای کیا</td>\n",
       "      <td>میمال پنهان گوش جان، مینه بهانه بر کسان جان رب خلصنی زنان، والله که لاغست ای کیا</td>\n",
       "      <td>[میمال, پنهان, گوش, جان, مینه, بهانه, جان, رب, خلصنی, زن, والله, لاغست, کیا]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cb9ec50-d5c2-4b61-b2e7-79ceb1214d94')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5cb9ec50-d5c2-4b61-b2e7-79ceb1214d94 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5cb9ec50-d5c2-4b61-b2e7-79ceb1214d94');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.txt\", names=[\"sentence\"])\n",
    "data[\"normalized_sent\"] = data[\"sentence\"].apply(lambda x: text_normalization(x))\n",
    "data[\"tokens\"] = data[\"normalized_sent\"].apply(lambda x: tokenize_text(x))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_foYGcFmqcB",
    "outputId": "78113035-7e2f-46f2-8591-ff68172d0f45",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "44674"
      ]
     },
     "metadata": {},
     "execution_count": 11
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['رستخیز',\n",
       " 'ناگهان',\n",
       " 'رحمت',\n",
       " 'منتها',\n",
       " 'آتش',\n",
       " 'افروخته',\n",
       " 'بیشه',\n",
       " 'اندیشه',\n",
       " 'خندان',\n",
       " 'مفتاح']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "token_df = data[\"tokens\"]\n",
    "# del data\n",
    "tokens = token_df.explode().dropna().tolist()\n",
    "len(tokens)\n",
    "tokens[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "vK-sWaa1mqcB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create word to id and id to word with keras tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XdUrBYmmqcC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = Tokenizer(filters=\"\")\n",
    "t.fit_on_texts(tokens)\n",
    "\n",
    "sorted_count_list = sorted(t.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "word_to_id, id_to_word = t.word_index, t.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWzNQedomqcC",
    "outputId": "45c7abb2-ae63-47d6-f6f1-50c881d779cf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8920"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(word_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "_lxdmZZBmqcC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generating training data with number of negative samples and window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qKPP2ZjmqcC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_training_data(sentences, window_size, num_negative_s, vocab_size):\n",
    "    # Elements of each training example are appended to these lists.\n",
    "    centers, contexts, labels = [], [], []\n",
    "\n",
    "    # Build the sampling table for vocab_size tokens.\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "    # Iterate over all sentences in corpus\n",
    "    for sequence in tqdm_notebook(sentences, desc='Sentenses', colour=\"MAGENTA\"):\n",
    "\n",
    "        # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "        positive_samples, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequence,\n",
    "            vocabulary_size=vocab_size,\n",
    "            sampling_table=sampling_table,\n",
    "            window_size=window_size,\n",
    "            negative_samples=0\n",
    "        )\n",
    "\n",
    "        # Iterate over each positive skip-gram pair to produce training examples\n",
    "        # with positive context word and negative samples.\n",
    "        for center_word, context_word in positive_samples:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                true_classes=context_class,\n",
    "                num_true=1,\n",
    "                num_sampled=num_negative_s,\n",
    "                unique=True,\n",
    "                range_max=vocab_size,\n",
    "                seed=42,\n",
    "                name=\"negative_sampling\"\n",
    "            )\n",
    "\n",
    "            # Build context and label vectors (for one center word)\n",
    "            negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "\n",
    "            # Concat negative samples with true context word (positive sample)\n",
    "            context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "            # label 1 for positive sample and 0 for negative samples.\n",
    "            label = tf.constant([1] + [0] * num_negative_s, dtype=\"int64\")\n",
    "\n",
    "            # Append each element from the training example to global lists.\n",
    "            centers.append(center_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "\n",
    "    return centers, contexts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "DTnmJJiDmqcD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convert word tokens to their id with word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sc848ScVmqcE",
    "outputId": "f80704da-6b9d-4581-e494-57959424ae4f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[2564, 976, 386, 1424, 24, 1666, 1094, 229],\n",
       " [256, 1234, 452, 3763, 870, 410, 22],\n",
       " [90, 2565, 664, 2011, 977, 345, 1424, 3764],\n",
       " [165, 3765, 229, 1425, 53, 779, 3766, 612, 236, 871],\n",
       " [37, 499, 1667, 978, 326, 2566, 247, 527, 1668, 103, 1095, 2567, 346],\n",
       " [1668, 613, 84, 2012, 665, 50, 9, 3767, 50, 9, 257, 2568],\n",
       " [780, 84, 614, 26, 283, 615, 84, 614, 615, 91, 257, 3768, 1235, 528],\n",
       " [1096, 10, 159, 1669, 529, 723, 1669, 3769, 69, 291, 1669, 3770, 67, 872],\n",
       " [3771, 124, 75, 1, 3772, 527, 1, 292, 3773, 111, 411, 3774, 1097],\n",
       " [171, 32, 3775, 5, 116, 326, 2569, 412, 214, 1098, 64, 724, 284]]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "tokenss = []\n",
    "for row in data[\"tokens\"].dropna().values:\n",
    "    if row:\n",
    "        tokenss.append([word_to_id[token] for token in row])\n",
    "    # print(row)\n",
    "tokenss[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5TVwbhmmqcE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# max_length = 10\n",
    "# padded_tokens = pad_sequences(tokenss, padding='post')\n",
    "# padded_tokens.shape\n",
    "# padded_tokens = padded_tokens.tolist()\n",
    "# padded_tokens = [np.array(lst) for lst in padded_tokens]\n",
    "\n",
    "tokenss = [np.array(lst) for lst in tokenss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NC0zXhjmqcE",
    "outputId": "64c49178-7af4-4dd8-d3d5-baada9f2873a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5316"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "len(tokenss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "XSvG2o57mqcE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create ((center words, contexts words,), labels) for feed to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "2ab577fda5a8498b97f6beed6cc1619e",
      "b6dd9fb1c973453a9394bc873aec53b6",
      "95790e4f7598449ab3f79e94a6813bb2",
      "f7b62156c0aa4a5d87122a5721bec696",
      "2273ffd724ee4f8793755645411098de",
      "6706690efca8400996a135f5fc82ff12",
      "a4bf357c09694e2882e479dac61b133c",
      "36b66208c71f42edaa09898406fb6606",
      "5173b8d2cd864eca9c49f38f245e2ef1",
      "abdf40889b2d4639a991cdf0782ce02a",
      "726187c50d814fbb8b6ea3b2ae4af346"
     ]
    },
    "id": "TXUTZWnCmqcE",
    "outputId": "86c4f5ea-98d7-4af3-97b5-daf195d7ebe7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Sentenses:   0%|          | 0/5316 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ab577fda5a8498b97f6beed6cc1619e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "targets.shape: (69682,)\n",
      "contexts.shape: (69682, 201)\n",
      "labels.shape: (69682, 201)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "num_negative_samples = 200\n",
    "vocab_size = len(word_to_id) + 1\n",
    "\n",
    "centers, contexts, labels = generate_training_data(\n",
    "    sentences=tokenss,\n",
    "    window_size=window_size,\n",
    "    num_negative_s=num_negative_samples,\n",
    "    vocab_size=vocab_size\n",
    ")\n",
    "\n",
    "centers = np.array(centers)\n",
    "contexts = np.array(contexts)[:, :, 0]\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {centers.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uRk2epO5mqcF",
    "outputId": "9d4c1e76-3e2c-4ed6-9bdc-34e5b5cbb258",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 976,  976, 2564,  976, 2564, 1424,  976, 1424,  976, 2564])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  24,  275,   26, ...,   35, 1784,  364],\n",
       "       [1666,  106,  232, ...,  278,  123, 8581],\n",
       "       [  24,  184, 1844, ...,  386, 1030,   23],\n",
       "       ...,\n",
       "       [2564, 1930, 1398, ...,  421, 6991,  479],\n",
       "       [1424, 1080,  527, ...,  571,  200,  981],\n",
       "       [ 976,  342,  245, ..., 6658,   55,  671]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "centers[:10]\n",
    "print()\n",
    "contexts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "nk2-i16CmqcF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Use tensorflow caching feature and set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LPAK8JkmqcF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((centers, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5VewcDcvmqcF",
    "outputId": "d6423bc3-fefe-4c17-8886-6e210a9e18c0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "((<tf.Tensor: shape=(1024,), dtype=int64, numpy=array([ 286, 4185, 2674, ..., 4098, 4356, 3936])>, <tf.Tensor: shape=(1024, 201), dtype=int64, numpy=\n",
      "array([[   8,   66,   26, ..., 1215,  305,  106],\n",
      "       [1504, 1015,    1, ...,  300,  567,  221],\n",
      "       [ 676,    1,    0, ...,  363, 1103,   13],\n",
      "       ...,\n",
      "       [4097,    2,    8, ..., 1067, 8002, 1121],\n",
      "       [4355,  221,   22, ..., 2533, 3480,  169],\n",
      "       [   2,   57, 1770, ...,  127, 1163,  274]])>), <tf.Tensor: shape=(1024, 201), dtype=int64, numpy=\n",
      "array([[1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0]])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Wiguk6XCmqcF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build customize model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQE6u9RGmqcF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            input_length=1,\n",
    "            name=\"center_embedding\"\n",
    "        )\n",
    "        self.context_embedding = layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            input_length=num_negative_samples + 1,\n",
    "            name=\"context_embedding\"\n",
    "        )\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        print()\n",
    "        print(f\"target = {target}\")\n",
    "        print(f\"context = {context}\")\n",
    "        # target: (batch, dummy)\n",
    "        # context: (batch, context)\n",
    "        if len(target.shape) == 2:\n",
    "            target = tf.squeeze(target, axis=1)\n",
    "        # target: (batch,)\n",
    "        word_emb = self.target_embedding(target)\n",
    "        print(f\"word_emb = {word_emb}\")\n",
    "\n",
    "        # word_emb: (batch, embed)\n",
    "        context_emb = self.context_embedding(context)\n",
    "        print(f\"context_emb = {context_emb}\")\n",
    "\n",
    "        # context_emb: (batch, context, embed)\n",
    "        # Einstein summation:\n",
    "        # define element-wise computation: sum(word_emb * context_emb)\n",
    "        # computes the dot product of target and context embeddings from a training pair\n",
    "        dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "        print(f\"dots = {dots}\")\n",
    "\n",
    "        # dots: (batch, context)\n",
    "        return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ClvzqzFmqcG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4858cb19-df59-4f58-99a0-d90746ef79a5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "target = Tensor(\"IteratorGetNext:0\", shape=(1024,), dtype=int64)\n",
      "context = Tensor(\"IteratorGetNext:1\", shape=(1024, 201), dtype=int64)\n",
      "word_emb = Tensor(\"word2_vec/center_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 200), dtype=float32)\n",
      "context_emb = Tensor(\"word2_vec/context_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 201, 200), dtype=float32)\n",
      "dots = Tensor(\"word2_vec/einsum/Einsum:0\", shape=(1024, 201), dtype=float32)\n",
      "\n",
      "target = Tensor(\"IteratorGetNext:0\", shape=(1024,), dtype=int64)\n",
      "context = Tensor(\"IteratorGetNext:1\", shape=(1024, 201), dtype=int64)\n",
      "word_emb = Tensor(\"word2_vec/center_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 200), dtype=float32)\n",
      "context_emb = Tensor(\"word2_vec/context_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 201, 200), dtype=float32)\n",
      "dots = Tensor(\"word2_vec/einsum/Einsum:0\", shape=(1024, 201), dtype=float32)\n",
      "68/68 [==============================] - 4s 12ms/step - loss: 5.3025 - accuracy: 0.0112\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.2720 - accuracy: 0.2351\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.2187 - accuracy: 0.3732\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 5.1114 - accuracy: 0.3513\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.9189 - accuracy: 0.3299\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.6278 - accuracy: 0.3221\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 4.2538 - accuracy: 0.3234\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.8264 - accuracy: 0.3336\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 3.3799 - accuracy: 0.3530\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.9528 - accuracy: 0.3829\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.5739 - accuracy: 0.4239\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2.2518 - accuracy: 0.4716\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.9829 - accuracy: 0.5230\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.7607 - accuracy: 0.5678\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.5783 - accuracy: 0.6076\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.4294 - accuracy: 0.6425\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.3078 - accuracy: 0.6721\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.2085 - accuracy: 0.6956\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.1270 - accuracy: 0.7145\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.0598 - accuracy: 0.7285\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1.0039 - accuracy: 0.7412\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.9572 - accuracy: 0.7502\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.9178 - accuracy: 0.7571\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.8843 - accuracy: 0.7623\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.8558 - accuracy: 0.7665\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.8312 - accuracy: 0.7696\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.8099 - accuracy: 0.7722\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7913 - accuracy: 0.7744\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7751 - accuracy: 0.7757\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7608 - accuracy: 0.7772\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7482 - accuracy: 0.7779\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7369 - accuracy: 0.7786\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7269 - accuracy: 0.7793\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7179 - accuracy: 0.7797\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7098 - accuracy: 0.7799\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.7024 - accuracy: 0.7802\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6958 - accuracy: 0.7806\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6897 - accuracy: 0.7804\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6842 - accuracy: 0.7804\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6791 - accuracy: 0.7805\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6744 - accuracy: 0.7807\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6701 - accuracy: 0.7809\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6662 - accuracy: 0.7808\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6625 - accuracy: 0.7808\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6591 - accuracy: 0.7808\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6559 - accuracy: 0.7805\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6529 - accuracy: 0.7806\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6502 - accuracy: 0.7805\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6476 - accuracy: 0.7805\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 0.6452 - accuracy: 0.7805\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f39d5c5bfd0>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "embedding_dim = 200\n",
    "epochs_ = 50\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "word2vec.fit(dataset, epochs=epochs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Mlqdd8LmqcG",
    "outputId": "f542a7ee-3cf1-4ffb-f679-5a829a8dc8c3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"word2_vec\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " center_embedding (Embedding  multiple                 1784200   \n",
      " )                                                               \n",
      "                                                                 \n",
      " context_embedding (Embeddin  multiple                 1784200   \n",
      " g)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,568,400\n",
      "Trainable params: 3,568,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word2vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRcETY8TmqcG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('center_embedding').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bCJPPhpMmqcG",
    "outputId": "97281cd6-6531-4782-b12b-51d08adba2f0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8921, 200)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create 3d/2d dimentions dataframe for plot interactive scaterplot by plotly library "
   ],
   "metadata": {
    "id": "kD_K6T54D2nj",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "three_dim = PCA(random_state=0).fit_transform(weights)[:,:3]\n",
    "dims3d = pd.DataFrame(three_dim, columns=['x', 'y', 'z'])\n",
    "\n",
    "two_dim = PCA(random_state=0).fit_transform(weights)[:,:2]\n",
    "dims2d = pd.DataFrame(two_dim, columns=['x', 'y'])\n",
    "\n",
    "dims3d"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "inJ05MwFq3Pf",
    "outputId": "c2ce760b-4cc9-4fc6-eed9-ac46c71cb28c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 71,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             x         y         z\n",
       "0    -0.038840 -0.140010 -0.062936\n",
       "1    -0.072194 -0.142408  0.023426\n",
       "2    -1.116818 -0.100878  0.054325\n",
       "3    -0.059786  0.143165 -0.471768\n",
       "4    -0.794100  0.223348  1.273033\n",
       "...        ...       ...       ...\n",
       "8916  0.188877 -0.066858 -0.807359\n",
       "8917 -0.023224 -0.130359 -0.069666\n",
       "8918 -0.050306 -0.014373  0.337730\n",
       "8919 -0.059316 -0.347420  0.103774\n",
       "8920 -0.315374  0.209293  0.272830\n",
       "\n",
       "[8921 rows x 3 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-cdaf6725-b40c-454f-b5a4-114157235a79\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.038840</td>\n",
       "      <td>-0.140010</td>\n",
       "      <td>-0.062936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.072194</td>\n",
       "      <td>-0.142408</td>\n",
       "      <td>0.023426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.116818</td>\n",
       "      <td>-0.100878</td>\n",
       "      <td>0.054325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059786</td>\n",
       "      <td>0.143165</td>\n",
       "      <td>-0.471768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794100</td>\n",
       "      <td>0.223348</td>\n",
       "      <td>1.273033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>0.188877</td>\n",
       "      <td>-0.066858</td>\n",
       "      <td>-0.807359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>-0.023224</td>\n",
       "      <td>-0.130359</td>\n",
       "      <td>-0.069666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8918</th>\n",
       "      <td>-0.050306</td>\n",
       "      <td>-0.014373</td>\n",
       "      <td>0.337730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8919</th>\n",
       "      <td>-0.059316</td>\n",
       "      <td>-0.347420</td>\n",
       "      <td>0.103774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>-0.315374</td>\n",
       "      <td>0.209293</td>\n",
       "      <td>0.272830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8921 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdaf6725-b40c-454f-b5a4-114157235a79')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-cdaf6725-b40c-454f-b5a4-114157235a79 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-cdaf6725-b40c-454f-b5a4-114157235a79');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "words = list(word_to_id.keys())\n",
    "words.append('end')\n",
    "dims2d['token'] = words\n",
    "dims3d['token'] = words\n",
    "dims2d"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Tymhd-dHrtud",
    "outputId": "2c968cc4-0a90-4e28-d907-a71275c6b7bb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 72,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             x         y     token\n",
       "0    -0.038840 -0.140010       جان\n",
       "1    -0.072194 -0.142408        دل\n",
       "2    -1.116818 -0.100878       عشق\n",
       "3    -0.059786  0.143165        سر\n",
       "4    -0.794100  0.223348        سو\n",
       "...        ...       ...       ...\n",
       "8916  0.188877 -0.066858  خیالاتست\n",
       "8917 -0.023224 -0.130359      آکند\n",
       "8918 -0.050306 -0.014373     یکایک\n",
       "8919 -0.059316 -0.347420   ترکانست\n",
       "8920 -0.315374  0.209293       end\n",
       "\n",
       "[8921 rows x 3 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-a6d8ced4-77d9-43d2-afb2-b4a118dbb965\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.038840</td>\n",
       "      <td>-0.140010</td>\n",
       "      <td>جان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.072194</td>\n",
       "      <td>-0.142408</td>\n",
       "      <td>دل</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.116818</td>\n",
       "      <td>-0.100878</td>\n",
       "      <td>عشق</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.059786</td>\n",
       "      <td>0.143165</td>\n",
       "      <td>سر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794100</td>\n",
       "      <td>0.223348</td>\n",
       "      <td>سو</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>0.188877</td>\n",
       "      <td>-0.066858</td>\n",
       "      <td>خیالاتست</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>-0.023224</td>\n",
       "      <td>-0.130359</td>\n",
       "      <td>آکند</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8918</th>\n",
       "      <td>-0.050306</td>\n",
       "      <td>-0.014373</td>\n",
       "      <td>یکایک</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8919</th>\n",
       "      <td>-0.059316</td>\n",
       "      <td>-0.347420</td>\n",
       "      <td>ترکانست</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>-0.315374</td>\n",
       "      <td>0.209293</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8921 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6d8ced4-77d9-43d2-afb2-b4a118dbb965')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a6d8ced4-77d9-43d2-afb2-b4a118dbb965 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a6d8ced4-77d9-43d2-afb2-b4a118dbb965');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dims2d.head(4000).to_pickle(\"dim2d.pkl\")\n",
    "dims3d.head(4000).to_pickle(\"dim3d.pkl\")"
   ],
   "metadata": {
    "id": "KgaWB19JtEsk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wyHjLGETmqcK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save weights of center_embedding layer (word embeddings) to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1vEhS1AmqcK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name = f'weights_nneg{num_negative_samples}_em{embedding_dim}_ep{epochs_}_vocs{vocab_size}_ws{window_size}'\n",
    "np.save(file_name, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "a3rlBiffmqcK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load_file_name = f'weights_nneg{num_negative_samples}_em{embedding_dim}_ep{epochs_}_vocs{vocab_size}_ws{window_size}'\n",
    "# loaded_weights = np.load(load_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "CGoccD-umqcK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Find nearest neighbor word with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IeHnZWT3mqcK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "31fdbfdd-557e-4791-bdc5-e2a2afed9349",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 1.0000002   0.05818215  0.01750027 ... -0.00045787  0.07242609\n",
      "  -0.03293831]\n",
      " [ 0.05818215  1.          0.05692578 ...  0.04686942 -0.10650274\n",
      "   0.01246404]\n",
      " [ 0.01750027  0.05692578  0.9999997  ...  0.07201505 -0.03514342\n",
      "   0.07119064]\n",
      " ...\n",
      " [-0.00045787  0.04686942  0.07201505 ...  0.9999994   0.01036097\n",
      "   0.08479095]\n",
      " [ 0.07242609 -0.10650274 -0.03514342 ...  0.01036097  0.9999998\n",
      "   0.02170496]\n",
      " [-0.03293831  0.01246404  0.07119064 ...  0.08479095  0.02170496\n",
      "   0.99999976]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_matrix = cosine_similarity(weights, weights)\n",
    "print(cosine_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kFiZah0mqcL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8a93c135-f48d-4667-b4b4-eda10754001e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8921, 8921)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "cosine_matrix.shape\n",
    "\n",
    "\n",
    "def cosine_similarity_word(words, cosine_matrix, n=10):\n",
    "    for word in words:\n",
    "        similars = []\n",
    "        for id in cosine_matrix[word_to_id[word]].argsort()[::-1][0:n]:\n",
    "            similars.append(id_to_word[id])\n",
    "        print(word, '=', similars, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R3DL2HjrmqcL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7ee38b27-82d9-4249-9cee-d052e4d44738",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('مه', 114),\n",
       " ('بس', 111),\n",
       " ('دانست#دان', 111),\n",
       " ('ماه', 110),\n",
       " ('کان', 109),\n",
       " ('پر', 109),\n",
       " ('روح', 107),\n",
       " ('عالم', 106),\n",
       " ('نی', 103),\n",
       " ('ره', 102),\n",
       " ('باد', 100),\n",
       " ('تن', 100),\n",
       " ('تبریز', 100),\n",
       " ('کار', 98),\n",
       " ('آنک', 98),\n",
       " ('گرفت#گیر', 95),\n",
       " ('خون', 93),\n",
       " ('پا', 92),\n",
       " ('رخ', 92),\n",
       " ('گه', 91)]"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "sorted_count_list[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "_bSB1q-nmqcL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Vy-vS77t9SKm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "aif2a9tOmqcL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "M7dkiSnymqcL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "UiG_DSZvmqcL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7d292592-5a4d-4f17-c0e0-b08b4507205c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "حسین = ['حسین', 'آبدارست', 'حشرگاه', 'کربلا', 'کربلایی', 'ریاضت', 'مری', 'می\\u200cنهان', 'مجنبان', 'میهمان'] \n",
      "\n",
      "یوسف = ['یوسف', 'فریب', 'مقلتی', 'تجری', 'نتیجه', 'بالولا', 'بین', 'الولا', 'غرق', 'زلیخا'] \n",
      "\n",
      "خسرو = ['خسرو', 'درمکش', 'خسروان', 'دردمید', 'شه', 'ماتست', 'برآور', 'بگفتی', 'الکبرست', 'ساقیست'] \n",
      "\n",
      "فروغ = ['فروغ', 'خجلت', 'صواب', 'فکنده', 'خطا', 'تصرف', 'روا', 'برفروخت', 'دفتر', 'پریدستی'] \n",
      "\n",
      "دجله = ['دجله', 'جیحون', 'صما', 'مقیم', 'پرنم', 'جای', 'کوثر', 'هیبت', 'موش', 'ندامت'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_word(['حسین', 'یوسف', 'خسرو', 'فروغ' ,'دجله'], cosine_matrix, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTMmuzzgmqcL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UehLoTCkmqcL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, j in word_to_id.items():\n",
    "    if 'کم' in i[-2:]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gF1-Db4mmqcM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, j in word_to_id.items():\n",
    "    if '_' in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUW4xepi9mvN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_training_data(sentences, window_size, num_negative_s, vocab_size):\n",
    "    # Elements of each training example are appended to these lists.\n",
    "    centers, contexts, labels = [], [], []\n",
    "\n",
    "    # Build the sampling table for vocab_size tokens.\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "    # Iterate over all sentences in corpus\n",
    "    for sequence in tqdm_notebook(sentences, desc='Sentenses', colour=\"MAGENTA\"):\n",
    "\n",
    "        # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "        positive_samples, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequence,\n",
    "            vocabulary_size=vocab_size,\n",
    "            sampling_table=sampling_table,\n",
    "            window_size=window_size,\n",
    "            negative_samples=0\n",
    "        )\n",
    "\n",
    "        # Iterate over each positive skip-gram pair to produce training examples\n",
    "        # with positive context word and negative samples.\n",
    "        for center_word, context_word in positive_samples:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                true_classes=context_class,\n",
    "                num_true=1,\n",
    "                num_sampled=num_negative_s,\n",
    "                unique=True,\n",
    "                range_max=vocab_size,\n",
    "                seed=42,\n",
    "                name=\"negative_sampling\"\n",
    "            )\n",
    "\n",
    "            # Build context and label vectors (for one center word)\n",
    "            negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "\n",
    "            # Concat negative samples with true context word (positive sample)\n",
    "            context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "            # label 1 for positive sample and 0 for negative samples.\n",
    "            label = tf.constant([1] + [0] * num_negative_s, dtype=\"int64\")\n",
    "\n",
    "            # Append each element from the training example to global lists.\n",
    "            centers.append(center_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "\n",
    "    return centers, contexts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "RRySGgaqnSDA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convert word tokens to their id with word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0y500_TQ9Wz4",
    "outputId": "4ccfc5e7-73ef-4a9b-e1ac-d312f238416a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2565, 976, 386, 1424, 24, 1666, 1094, 229],\n",
       " [256, 1234, 452, 3764, 870, 410, 22],\n",
       " [90, 2566, 664, 2012, 977, 345, 1424, 3765],\n",
       " [165, 3766, 229, 1425, 53, 779, 3767, 612, 236, 871],\n",
       " [37, 499, 1667, 978, 326, 2567, 247, 527, 1668, 103, 1095, 2568, 346],\n",
       " [1668, 613, 84, 2013, 665, 50, 9, 3768, 50, 9, 257, 2569],\n",
       " [780, 84, 614, 26, 283, 615, 84, 614, 615, 91, 257, 3769, 1235, 528],\n",
       " [1096, 10, 159, 1669, 529, 723, 1669, 3770, 69, 291, 1669, 3771, 67, 872],\n",
       " [3772, 124, 75, 1, 3773, 527, 1, 292, 3774, 111, 411, 3775, 1097],\n",
       " [171, 32, 3776, 5, 116, 326, 2570, 412, 214, 1098, 64, 724, 284]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenss = []\n",
    "for row in data[\"tokens\"].dropna().values:\n",
    "    if row:\n",
    "        tokenss.append([word_to_id[token] for token in row])\n",
    "    # print(row)\n",
    "tokenss[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahyUU3JdBP2Z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# max_length = 10\n",
    "# padded_tokens = pad_sequences(tokenss, padding='post')\n",
    "# padded_tokens.shape\n",
    "# padded_tokens = padded_tokens.tolist()\n",
    "# padded_tokens = [np.array(lst) for lst in padded_tokens]\n",
    "\n",
    "tokenss = [np.array(lst) for lst in tokenss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xq49HZOcDnTh",
    "outputId": "c2b60c4b-3914-4dd6-894f-48794277f7cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5316"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "WGlNx4l4nSDE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create ((center words, contexts words,), labels) for feed to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "afd63f39b87f46da9745675251273c45",
      "c9ddda96b9104aba834954ee14e783c7",
      "dea00032a72942448c3ea81d373ee29f",
      "3b20472e23f240308551359547732c3f",
      "b43f912f67014cbca28ee106e34abc6c",
      "ce9a77b5394742cc82bbda2e67892023",
      "ea2edbdc17004f369af35fcfd3aa61ab",
      "3d3212f92d43489dbd2659dd339532ca",
      "3dfaa4073c9d4a9ab2196c860c36f8fb",
      "e59fb63e784a430fa5e3efa4185aa3a6",
      "66436b6dd8eb416ba6a33deccdaee223"
     ]
    },
    "id": "A_8r-fJeFRrq",
    "outputId": "4b8910f2-e98a-4d5d-a1bd-2993ef513cd7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd63f39b87f46da9745675251273c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sentenses:   0%|          | 0/5316 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (69457,)\n",
      "contexts.shape: (69457, 201)\n",
      "labels.shape: (69457, 201)\n"
     ]
    }
   ],
   "source": [
    "window_size = 5\n",
    "num_negative_samples = 200\n",
    "vocab_size = len(word_to_id) + 1\n",
    "\n",
    "centers, contexts, labels = generate_training_data(\n",
    "    sentences=tokenss,\n",
    "    window_size=window_size,\n",
    "    num_negative_s=num_negative_samples,\n",
    "    vocab_size=vocab_size\n",
    ")\n",
    "\n",
    "centers = np.array(centers)\n",
    "contexts = np.array(contexts)[:, :, 0]\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {centers.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rStYwGuYFSgz",
    "outputId": "4bfc287e-4c82-4201-cf5f-7b84b81a439e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1424, 1424, 1424, 1424, 1424, 1424, 1424,  452,  452,  452])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1666,   14, 1273, ..., 2898, 4240,   71],\n",
       "       [2565,  613,   13, ...,  875, 5675, 2930],\n",
       "       [ 976, 2536, 1029, ...,  151, 1438,  563],\n",
       "       ...,\n",
       "       [ 870,    1,  531, ..., 2068,  608, 2819],\n",
       "       [3764, 5778,  531, ...,   29,  332,  120],\n",
       "       [ 256,    7,  626, ...,   15,  237, 1664]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers[:10]\n",
    "print()\n",
    "contexts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "0HJfGW9onSDF",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Use tensorflow caching feature and set batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpVCWt0fFSjt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((centers, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2OYODbNFSmf",
    "outputId": "a38c5a84-55db-4862-a2ac-169e3db3e06e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(1024,), dtype=int64, numpy=array([  22, 3917, 4230, ..., 4160, 1442, 2860])>, <tf.Tensor: shape=(1024, 201), dtype=int64, numpy=\n",
      "array([[ 131,  271,  406, ..., 1324,   48,   70],\n",
      "       [ 185,  762, 2120, ..., 4952,  175,  228],\n",
      "       [4232,  987,    3, ...,   33,  165, 6089],\n",
      "       ...,\n",
      "       [1758,   43,   20, ...,  266, 3292,  458],\n",
      "       [1542,    1,   12, ..., 2382,  152,  536],\n",
      "       [ 295,    6, 3240, ...,  977,  978,  168]])>), <tf.Tensor: shape=(1024, 201), dtype=int64, numpy=\n",
      "array([[1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0],\n",
      "       [1, 0, 0, ..., 0, 0, 0]])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "fSXBvjIHnSDG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build customize model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EQZu0orFSo3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Word2Vec(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            input_length=1,\n",
    "            name=\"center_embedding\"\n",
    "        )\n",
    "        self.context_embedding = layers.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim,\n",
    "            input_length=num_negative_samples + 1,\n",
    "            name=\"context_embedding\"\n",
    "        )\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        print()\n",
    "        print(f\"target = {target}\")\n",
    "        print(f\"context = {context}\")\n",
    "        # target: (batch, dummy)\n",
    "        # context: (batch, context)\n",
    "        if len(target.shape) == 2:\n",
    "            target = tf.squeeze(target, axis=1)\n",
    "        # target: (batch,)\n",
    "        word_emb = self.target_embedding(target)\n",
    "        print(f\"word_emb = {word_emb}\")\n",
    "\n",
    "        # word_emb: (batch, embed)\n",
    "        context_emb = self.context_embedding(context)\n",
    "        print(f\"context_emb = {context_emb}\")\n",
    "\n",
    "        # context_emb: (batch, context, embed)\n",
    "        # Einstein summation:\n",
    "        # define element-wise computation: sum(word_emb * context_emb)\n",
    "        # computes the dot product of target and context embeddings from a training pair\n",
    "        dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "        print(f\"dots = {dots}\")\n",
    "\n",
    "        # dots: (batch, context)\n",
    "        return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rq8KldZCUzIV",
    "outputId": "b3142ec9-d35f-406c-c521-c43f6053120b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "target = Tensor(\"IteratorGetNext:0\", shape=(1024,), dtype=int64)\n",
      "context = Tensor(\"IteratorGetNext:1\", shape=(1024, 201), dtype=int64)\n",
      "word_emb = Tensor(\"word2_vec_7/center_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 200), dtype=float32)\n",
      "context_emb = Tensor(\"word2_vec_7/context_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 201, 200), dtype=float32)\n",
      "dots = Tensor(\"word2_vec_7/einsum/Einsum:0\", shape=(1024, 201), dtype=float32)\n",
      "\n",
      "target = Tensor(\"IteratorGetNext:0\", shape=(1024,), dtype=int64)\n",
      "context = Tensor(\"IteratorGetNext:1\", shape=(1024, 201), dtype=int64)\n",
      "word_emb = Tensor(\"word2_vec_7/center_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 200), dtype=float32)\n",
      "context_emb = Tensor(\"word2_vec_7/context_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 201, 200), dtype=float32)\n",
      "dots = Tensor(\"word2_vec_7/einsum/Einsum:0\", shape=(1024, 201), dtype=float32)\n",
      "67/67 [==============================] - 11s 152ms/step - loss: 5.3026 - accuracy: 0.0106\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 10s 151ms/step - loss: 5.2722 - accuracy: 0.2294\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 5.2200 - accuracy: 0.3661\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 5.1156 - accuracy: 0.3458\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 10s 148ms/step - loss: 4.9287 - accuracy: 0.3244\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 10s 148ms/step - loss: 4.6454 - accuracy: 0.3159\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 4.2808 - accuracy: 0.3184\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 10s 148ms/step - loss: 3.8630 - accuracy: 0.3291\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 3.4240 - accuracy: 0.3483\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 3.0006 - accuracy: 0.3776\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 2.6214 - accuracy: 0.4164\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 2.2962 - accuracy: 0.4621\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 2.0231 - accuracy: 0.5105\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 1.7963 - accuracy: 0.5588\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 1.6095 - accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 10s 143ms/step - loss: 1.4565 - accuracy: 0.6358\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 1.3313 - accuracy: 0.6665\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 1.2289 - accuracy: 0.6905\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 1.1449 - accuracy: 0.7099\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 1.0755 - accuracy: 0.7246\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 1.0179 - accuracy: 0.7376\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.9698 - accuracy: 0.7470\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.9292 - accuracy: 0.7550\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.8948 - accuracy: 0.7611\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.8654 - accuracy: 0.7655\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.8401 - accuracy: 0.7689\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.8182 - accuracy: 0.7715\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.7992 - accuracy: 0.7738\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.7825 - accuracy: 0.7752\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.7678 - accuracy: 0.7764\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.7549 - accuracy: 0.7775\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 10s 150ms/step - loss: 0.7433 - accuracy: 0.7782\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.7330 - accuracy: 0.7786\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 0.7238 - accuracy: 0.7788\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 0.7155 - accuracy: 0.7791\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.7079 - accuracy: 0.7792\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.7011 - accuracy: 0.7793\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 0.6949 - accuracy: 0.7794\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 0.6892 - accuracy: 0.7796\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 0.6841 - accuracy: 0.7797\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.6793 - accuracy: 0.7799\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.6749 - accuracy: 0.7801\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.6708 - accuracy: 0.7802\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 10s 147ms/step - loss: 0.6671 - accuracy: 0.7801\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.6636 - accuracy: 0.7801\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.6603 - accuracy: 0.7801\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 10s 144ms/step - loss: 0.6573 - accuracy: 0.7800\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 10s 145ms/step - loss: 0.6545 - accuracy: 0.7799\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.6519 - accuracy: 0.7799\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 10s 146ms/step - loss: 0.6494 - accuracy: 0.7798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f59a3e4a690>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 200\n",
    "epochs_ = 50\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "word2vec.fit(dataset, epochs=epochs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iuga96he-sI8",
    "outputId": "ff6d10a2-38a2-4da2-b9e7-9b142d83428c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"word2_vec_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " center_embedding (Embedding  multiple                 1784400   \n",
      " )                                                               \n",
      "                                                                 \n",
      " context_embedding (Embeddin  multiple                 1784400   \n",
      " g)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,568,800\n",
      "Trainable params: 3,568,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word2vec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IjCRWT2UzMp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = word2vec.get_layer('center_embedding').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzOFekvTUzQE",
    "outputId": "5bd3d080-2f11-4b24-f3e8-b29e4a24417e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8922, 200)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ux_EmxI9nSDI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save weights of center_embedding layer (word embeddings) to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhqiH-qBmLHg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name = f'weights_nneg{num_negative_samples}_em{embedding_dim}_ep{epochs_}_vocs{vocab_size}_ws{window_size}'\n",
    "np.save(file_name, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrlv5pVQXRf7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_file_name = f'weights_nneg{num_negative_samples}_em{embedding_dim}_ep{epochs_}_vocs{vocab_size}_ws{window_size}'\n",
    "loaded_weights = np.load(load_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "x3wJq0P4nSDJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Find nearest neighbor word with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRcLLGhGGmfe",
    "outputId": "60e5f6fe-f400-45b9-9d7a-8d3e44d41241",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0000001  -0.0833027  -0.02161321 ...  0.03165701  0.00011451\n",
      "  -0.06165543]\n",
      " [-0.0833027   1.          0.08032579 ...  0.01039312 -0.05719611\n",
      "  -0.01495304]\n",
      " [-0.02161321  0.08032579  1.         ... -0.0136863   0.07858521\n",
      "   0.01053756]\n",
      " ...\n",
      " [ 0.03165701  0.01039312 -0.0136863  ...  0.9999998  -0.19599128\n",
      "   0.08485357]\n",
      " [ 0.00011451 -0.05719611  0.07858521 ... -0.19599128  0.99999994\n",
      "  -0.08715412]\n",
      " [-0.06165543 -0.01495304  0.01053756 ...  0.08485357 -0.08715412\n",
      "   0.9999998 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_matrix = cosine_similarity(weights, weights)\n",
    "print(cosine_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCTzJRR_ueRJ",
    "outputId": "3c5aba96-715f-4871-ac0e-4054cef54daf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8922, 8922)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_matrix.shape\n",
    "\n",
    "\n",
    "def cosine_similarity_word(words, cosine_matrix, n=10):\n",
    "    for word in words:\n",
    "        similars = []\n",
    "        for id in cosine_matrix[word_to_id[word]].argsort()[::-1][0:n]:\n",
    "            similars.append(id_to_word[id])\n",
    "        print(word, '=', similars, '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNDHBiDhFac2",
    "outputId": "0ef23380-faa1-4d5f-8459-aa09932c481d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('مه', 114),\n",
       " ('بس', 111),\n",
       " ('دانست#دان', 111),\n",
       " ('ماه', 110),\n",
       " ('کان', 109),\n",
       " ('پر', 109),\n",
       " ('روح', 107),\n",
       " ('عالم', 106),\n",
       " ('نی', 103),\n",
       " ('ره', 102),\n",
       " ('باد', 100),\n",
       " ('تن', 100),\n",
       " ('تبریز', 100),\n",
       " ('کار', 98),\n",
       " ('آنک', 98),\n",
       " ('گرفت#گیر', 95),\n",
       " ('خون', 93),\n",
       " ('پا', 92),\n",
       " ('رخ', 92),\n",
       " ('گه', 91)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_count_list[30:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2MqoVMGIloh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "_mtFn5jQnSDL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uspZBpGlHXa8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ngg5QhPQXhxD",
    "outputId": "9b4c3414-edb1-4605-ad24-6b5b54e347dd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شاه = ['شاه', 'فتادست', 'فساق', 'همامست', 'مباش', 'خسروان', 'شهرست', 'بندگان', 'مکافات', 'گردد\\u200cگر'] \n",
      "\n",
      "یوسف = ['یوسف', 'سیماست', 'زلیخا', 'بریدند', 'نتیجه', 'اندرنگر', 'تمامست', 'دهل', 'اعلا', 'بیچاره'] \n",
      "\n",
      "خسرو = ['خسرو', 'ما\\u200cگر', 'خورشیدروی', 'قباد', 'بشاید', 'بازبیاریم', 'مخدوم', 'انس', 'سرور', 'حسرت'] \n",
      "\n",
      "گل = ['گل', 'هامونست', 'بدریده\\u200cای', 'میوه', 'گرینده', 'سامریست', 'اندرفتد', 'بخندان', 'مپیچان', 'گوارد'] \n",
      "\n",
      "دجله = ['دجله', 'فرات', 'جیحون', 'مقیم', 'صخره', 'صما', 'پرنم', 'بدندی', 'زهر', 'ویس'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_word(['شاه', 'یوسف', 'خسرو', 'گل','دجله'], cosine_matrix, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6zZyXS0FCa0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEu-adE2UzzP",
    "outputId": "98571d76-a47d-4572-ce44-081d937a17e9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "کم\n",
      "حکم\n",
      "شکم\n",
      "حاکم\n",
      "هواکم\n",
      "فقدکم\n",
      "اصحابکم\n",
      "اعقابکم\n",
      "جنبکم\n",
      "ذنبکم\n",
      "ربکم\n",
      "تفاحکم\n",
      "اصباحکم\n",
      "ارواحکم\n",
      "اریاحکم\n",
      "یعقوبکم\n",
      "قدامکم\n",
      "دونکم\n",
      "لحظکم\n",
      "لقیاکم\n",
      "لقائکم\n",
      "شدکم\n",
      "بهواکم\n",
      "عنکم\n",
      "فناکم\n",
      "رایناکم\n",
      "بضیاکم\n",
      "بلاکم\n",
      "غیرکم\n",
      "سواکم\n",
      "حورکم\n",
      "احیاکم\n",
      "حیاتکم\n",
      "یترککم\n",
      "ودکم\n",
      "خلاکم\n",
      "فدیتکم\n",
      "قتیلکم\n",
      "فاتکم\n",
      "بدتکم\n",
      "ایبکم\n",
      "می‌کم\n"
     ]
    }
   ],
   "source": [
    "for i, j in word_to_id.items():\n",
    "    if 'کم' in i[-2:]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPT7884wdz_f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, j in word_to_id.items():\n",
    "    if '_' in i:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "word2vec_negative_sampling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3b20472e23f240308551359547732c3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e59fb63e784a430fa5e3efa4185aa3a6",
      "placeholder": "​",
      "style": "IPY_MODEL_66436b6dd8eb416ba6a33deccdaee223",
      "value": " 5316/5316 [00:17&lt;00:00, 431.85it/s]"
     }
    },
    "3d3212f92d43489dbd2659dd339532ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dfaa4073c9d4a9ab2196c860c36f8fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "MAGENTA",
      "description_width": ""
     }
    },
    "66436b6dd8eb416ba6a33deccdaee223": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afd63f39b87f46da9745675251273c45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c9ddda96b9104aba834954ee14e783c7",
       "IPY_MODEL_dea00032a72942448c3ea81d373ee29f",
       "IPY_MODEL_3b20472e23f240308551359547732c3f"
      ],
      "layout": "IPY_MODEL_b43f912f67014cbca28ee106e34abc6c"
     }
    },
    "b43f912f67014cbca28ee106e34abc6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9ddda96b9104aba834954ee14e783c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce9a77b5394742cc82bbda2e67892023",
      "placeholder": "​",
      "style": "IPY_MODEL_ea2edbdc17004f369af35fcfd3aa61ab",
      "value": "Sentenses: 100%"
     }
    },
    "ce9a77b5394742cc82bbda2e67892023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea00032a72942448c3ea81d373ee29f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d3212f92d43489dbd2659dd339532ca",
      "max": 5316,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dfaa4073c9d4a9ab2196c860c36f8fb",
      "value": 5316
     }
    },
    "e59fb63e784a430fa5e3efa4185aa3a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea2edbdc17004f369af35fcfd3aa61ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ab577fda5a8498b97f6beed6cc1619e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6dd9fb1c973453a9394bc873aec53b6",
       "IPY_MODEL_95790e4f7598449ab3f79e94a6813bb2",
       "IPY_MODEL_f7b62156c0aa4a5d87122a5721bec696"
      ],
      "layout": "IPY_MODEL_2273ffd724ee4f8793755645411098de"
     }
    },
    "b6dd9fb1c973453a9394bc873aec53b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6706690efca8400996a135f5fc82ff12",
      "placeholder": "​",
      "style": "IPY_MODEL_a4bf357c09694e2882e479dac61b133c",
      "value": "Sentenses: 100%"
     }
    },
    "95790e4f7598449ab3f79e94a6813bb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36b66208c71f42edaa09898406fb6606",
      "max": 5316,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5173b8d2cd864eca9c49f38f245e2ef1",
      "value": 5316
     }
    },
    "f7b62156c0aa4a5d87122a5721bec696": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abdf40889b2d4639a991cdf0782ce02a",
      "placeholder": "​",
      "style": "IPY_MODEL_726187c50d814fbb8b6ea3b2ae4af346",
      "value": " 5316/5316 [00:58&lt;00:00, 122.28it/s]"
     }
    },
    "2273ffd724ee4f8793755645411098de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6706690efca8400996a135f5fc82ff12": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4bf357c09694e2882e479dac61b133c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36b66208c71f42edaa09898406fb6606": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5173b8d2cd864eca9c49f38f245e2ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "MAGENTA",
      "description_width": ""
     }
    },
    "abdf40889b2d4639a991cdf0782ce02a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "726187c50d814fbb8b6ea3b2ae4af346": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}