{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "yv6cKm2Rmqb0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Create word2vec model with negative sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "zEgJ3eu3mqb5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Install packages and adjust setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITPPO3_3mqb6",
        "outputId": "49523f64-793e-425e-96c9-a48276aad93d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 58.1 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394486 sha256=23474764d3bd70b608a8f808437d73ebb929b0d2d9f330ce6b3b42caec93166c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154099 sha256=3a6e9abd1b4a2f4587d2d2637594f81b462de903ea7eccb7dd0ca43f18e677a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v7TX9x9xmqb8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from hazm import word_tokenize, Lemmatizer, Stemmer, Normalizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import layers\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8-84iio8mqb9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "# InteractiveShell.ast_node_interactivity = \"last_expr\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z5N8IXp-mqb9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "sd_XMPDZmqb-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Import corpus and persian stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g_9l0K4mmqb_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "with open(\"data.txt\", \"r\") as file:\n",
        "    raw_text = file.read()\n",
        "\n",
        "with open(\"persian_stopw.txt\", \"r\") as file:\n",
        "    raw_stop_words = file.read()\n",
        "\n",
        "stop_words = word_tokenize(raw_stop_words)\n",
        "\n",
        "\n",
        "def remove_persian_stopword(tokens):\n",
        "    # return [word for word in tokens if not word in stop_words and word and word not in proned]\n",
        "    return [word for word in tokens if not word in stop_words and word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LNHK7wdnmqb_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "normalizer = Normalizer()\n",
        "lemmatizer = Lemmatizer()\n",
        "stemmer = Stemmer()\n",
        "\n",
        "\n",
        "def normalize_text(text):\n",
        "    return normalizer.normalize(text)\n",
        "\n",
        "\n",
        "def lemma_tokenizer(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    # return [lemmatizer.lemmatize(token).split(\"#\")[0] for token in tokens]\n",
        "\n",
        "\n",
        "def stem_tokenizer(tokens):\n",
        "    return [stemmer.stem(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SIDwdtEXmqcA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def text_normalization(text):\n",
        "    raw_text = re.sub(r\"-+|\\d+|\\s+\", \" \", text)\n",
        "    raw_text = normalize_text(raw_text)\n",
        "\n",
        "    return raw_text\n",
        "\n",
        "\n",
        "def tokenize_text(text, type=\"lemma\"):\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = remove_persian_stopword(tokens)\n",
        "    if type == \"lemma\":\n",
        "        tokens = remove_persian_stopword(lemma_tokenizer(tokens))\n",
        "    elif type == \"stem\":\n",
        "        tokens = remove_persian_stopword(stem_tokenizer(tokens))\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "iqfaZbegmqcA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Create tokens dataframe (normalized + lemmatized + removed persian stop words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "kw-nhVjFmqcB",
        "outputId": "508fb4e3-5291-4e5e-d2da-1d4255df0597",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                    sentence  \\\n",
              "0                                                                                          1   \n",
              "1                   ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی افروخته، در بیشه ی اندیشه ها   \n",
              "2                   امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندان آمدی، چون بخشش و فضل خدا   \n",
              "3            خورشید را حاجب تویی، امید را واجب تویی\\tمطلب تویی طالب تویی، هم منتها، هم مبتدا   \n",
              "4              در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش حاجت خواسته، هم خویشتن کرده روا   \n",
              "5         ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی بهانه ست و دغل، کاین علت آمد، وآن دوا   \n",
              "6       ما زان دغل کژ بین شده، با بی گنه در کین شده\\tگه مست حورالعین شده، گه مست نان و شوربا   \n",
              "7  این سُکر بین، هل عقل را، وین ُنقل بین، هل َنقل را\\tکز بهر نان و بقل را، چندین نشاید ماجرا   \n",
              "8          تدبیر صد رنگ افکنی، بر روم و بر زنگ افکنی\\tواندر میان جنگ افکنی، فی اصطناع لا یری   \n",
              "9          میمال پنهان گوش جان، مینه بهانه بر کسان\\tجان رب خلصنی زنان، والله که لاغست ای کیا   \n",
              "\n",
              "                                                                         normalized_sent  \\\n",
              "0                                                                                          \n",
              "1                ای رستخیز ناگهان، وی رحمت بی منتها ای آتشی افروخته، در بیشه‌ی اندیشه‌ها   \n",
              "2                امروز خندان آمدی، مفتاح زندان آمدی بر مستمندان آمدی، چون بخشش و فضل خدا   \n",
              "3         خورشید را حاجب تویی، امید را واجب تویی مطلب تویی طالب تویی، هم منتها، هم مبتدا   \n",
              "4           در سینه‌ها برخاسته، اندیشه را آراسته هم خویش حاجت خواسته، هم خویشتن کرده روا   \n",
              "5         ای روح بخش بی بدل، وی لذت علم و عمل باقی بهانه ست و دغل، کاین علت آمد، وآن دوا   \n",
              "6    ما زان دغل کژ بین شده، با بی گنه در کین شده گه مست حورالعین شده، گه مست نان و شوربا   \n",
              "7  این سکر بین، هل عقل را، وین نقل بین، هل نقل را کز بهر نان و بقل را، چندین نشاید ماجرا   \n",
              "8       تدبیر صد رنگ افکنی، بر روم و بر زنگ افکنی واندر میان جنگ افکنی، فی اصطناع لا یری   \n",
              "9       میمال پنهان گوش جان، مینه بهانه بر کسان جان رب خلصنی زنان، والله که لاغست ای کیا   \n",
              "\n",
              "                                                                               tokens  \n",
              "0                                                                                  []  \n",
              "1                           [رستخیز, ناگهان, رحمت, منتها, آتش, افروخته, بیشه, اندیشه]  \n",
              "2                                       [خندان, مفتاح, زندان, مستمند, بخشش, فضل, خدا]  \n",
              "3                                [خورشید, حاجب, امید, واجب, مطلب, طالب, منتها, مبتدا]  \n",
              "4              [سینه, برخاسته, اندیشه, آراسته, خویش, حاجت, خواسته, خویشتن, کرده, روا]  \n",
              "5               [روح, بخش, بدل, لذت, علم, عمل, باقی, بهانه, دغل, کاین, علت, وآن, دوا]  \n",
              "6                    [دغل, کژ, بین, گنه, کین, گه, مست, حورالعین, گه, مست, نان, شوربا]  \n",
              "7            [سکر, بین, هل, عقل, وین, نقل, بین, هل, نقل, بهر, نان, بقل, نشاید, ماجرا]  \n",
              "8  [تدبیر, صد, رنگ, افکنی, روم, زنگ, افکنی, واندر, میان, جنگ, افکنی, اصطناع, لا, یری]  \n",
              "9        [میمال, پنهان, گوش, جان, مینه, بهانه, جان, رب, خلصنی, زن, والله, لاغست, کیا]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f481d720-3daf-472a-b87b-fafd062b8247\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>normalized_sent</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ای رستخیز ناگهان، وی رحمت بی منتها\\tای آتشی افروخته، در بیشه ی اندیشه ها</td>\n",
              "      <td>ای رستخیز ناگهان، وی رحمت بی منتها ای آتشی افروخته، در بیشه‌ی اندیشه‌ها</td>\n",
              "      <td>[رستخیز, ناگهان, رحمت, منتها, آتش, افروخته, بیشه, اندیشه]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>امروز خندان آمدی، مفتاح زندان آمدی\\tبر مستمندان آمدی، چون بخشش و فضل خدا</td>\n",
              "      <td>امروز خندان آمدی، مفتاح زندان آمدی بر مستمندان آمدی، چون بخشش و فضل خدا</td>\n",
              "      <td>[خندان, مفتاح, زندان, مستمند, بخشش, فضل, خدا]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>خورشید را حاجب تویی، امید را واجب تویی\\tمطلب تویی طالب تویی، هم منتها، هم مبتدا</td>\n",
              "      <td>خورشید را حاجب تویی، امید را واجب تویی مطلب تویی طالب تویی، هم منتها، هم مبتدا</td>\n",
              "      <td>[خورشید, حاجب, امید, واجب, مطلب, طالب, منتها, مبتدا]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>در سینه ها برخاسته، اندیشه را آراسته\\tهم خویش حاجت خواسته، هم خویشتن کرده روا</td>\n",
              "      <td>در سینه‌ها برخاسته، اندیشه را آراسته هم خویش حاجت خواسته، هم خویشتن کرده روا</td>\n",
              "      <td>[سینه, برخاسته, اندیشه, آراسته, خویش, حاجت, خواسته, خویشتن, کرده, روا]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ای روح بخش بی بَدَل، وی لذتِ علم و عمل\\tباقی بهانه ست و دغل، کاین علت آمد، وآن دوا</td>\n",
              "      <td>ای روح بخش بی بدل، وی لذت علم و عمل باقی بهانه ست و دغل، کاین علت آمد، وآن دوا</td>\n",
              "      <td>[روح, بخش, بدل, لذت, علم, عمل, باقی, بهانه, دغل, کاین, علت, وآن, دوا]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ما زان دغل کژ بین شده، با بی گنه در کین شده\\tگه مست حورالعین شده، گه مست نان و شوربا</td>\n",
              "      <td>ما زان دغل کژ بین شده، با بی گنه در کین شده گه مست حورالعین شده، گه مست نان و شوربا</td>\n",
              "      <td>[دغل, کژ, بین, گنه, کین, گه, مست, حورالعین, گه, مست, نان, شوربا]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>این سُکر بین، هل عقل را، وین ُنقل بین، هل َنقل را\\tکز بهر نان و بقل را، چندین نشاید ماجرا</td>\n",
              "      <td>این سکر بین، هل عقل را، وین نقل بین، هل نقل را کز بهر نان و بقل را، چندین نشاید ماجرا</td>\n",
              "      <td>[سکر, بین, هل, عقل, وین, نقل, بین, هل, نقل, بهر, نان, بقل, نشاید, ماجرا]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>تدبیر صد رنگ افکنی، بر روم و بر زنگ افکنی\\tواندر میان جنگ افکنی، فی اصطناع لا یری</td>\n",
              "      <td>تدبیر صد رنگ افکنی، بر روم و بر زنگ افکنی واندر میان جنگ افکنی، فی اصطناع لا یری</td>\n",
              "      <td>[تدبیر, صد, رنگ, افکنی, روم, زنگ, افکنی, واندر, میان, جنگ, افکنی, اصطناع, لا, یری]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>میمال پنهان گوش جان، مینه بهانه بر کسان\\tجان رب خلصنی زنان، والله که لاغست ای کیا</td>\n",
              "      <td>میمال پنهان گوش جان، مینه بهانه بر کسان جان رب خلصنی زنان، والله که لاغست ای کیا</td>\n",
              "      <td>[میمال, پنهان, گوش, جان, مینه, بهانه, جان, رب, خلصنی, زن, والله, لاغست, کیا]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f481d720-3daf-472a-b87b-fafd062b8247')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f481d720-3daf-472a-b87b-fafd062b8247 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f481d720-3daf-472a-b87b-fafd062b8247');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data = pd.read_csv(\"data.txt\", names=[\"sentence\"])\n",
        "data[\"normalized_sent\"] = data[\"sentence\"].apply(lambda x: text_normalization(x))\n",
        "data[\"tokens\"] = data[\"normalized_sent\"].apply(lambda x: tokenize_text(x))\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_foYGcFmqcB",
        "outputId": "19063424-013a-40bc-e29d-2afd132c1916",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44674"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['رستخیز',\n",
              " 'ناگهان',\n",
              " 'رحمت',\n",
              " 'منتها',\n",
              " 'آتش',\n",
              " 'افروخته',\n",
              " 'بیشه',\n",
              " 'اندیشه',\n",
              " 'خندان',\n",
              " 'مفتاح']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "token_df = data[\"tokens\"]\n",
        "# del data\n",
        "tokens = token_df.explode().dropna().tolist()\n",
        "len(tokens)\n",
        "tokens[:10]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vK-sWaa1mqcB",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Create word to id and id to word with keras tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5XdUrBYmmqcC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "t = Tokenizer(filters=\"\")\n",
        "t.fit_on_texts(tokens)\n",
        "\n",
        "sorted_count_list = sorted(t.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "word_to_id, id_to_word = t.word_index, t.index_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWzNQedomqcC",
        "outputId": "5ea85fd6-ab72-4f74-e39d-340a6ff7909c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8920"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "len(word_to_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_lxdmZZBmqcC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Generating training data with number of negative samples and window size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8qKPP2ZjmqcC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def generate_training_data(sentences, window_size, num_negative_s, vocab_size):\n",
        "    # Elements of each training example are appended to these lists.\n",
        "    centers, contexts, labels = [], [], []\n",
        "\n",
        "    # Build the sampling table for vocab_size tokens.\n",
        "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "    # Iterate over all sentences in corpus\n",
        "    for sequence in tqdm_notebook(sentences, desc='Sentenses', colour=\"MAGENTA\"):\n",
        "\n",
        "        # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "        positive_samples, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "            sequence,\n",
        "            vocabulary_size=vocab_size,\n",
        "            sampling_table=sampling_table,\n",
        "            window_size=window_size,\n",
        "            negative_samples=0\n",
        "        )\n",
        "\n",
        "        # Iterate over each positive skip-gram pair to produce training examples\n",
        "        # with positive context word and negative samples.\n",
        "        for center_word, context_word in positive_samples:\n",
        "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "\n",
        "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "                true_classes=context_class,\n",
        "                num_true=1,\n",
        "                num_sampled=num_negative_s,\n",
        "                unique=True,\n",
        "                range_max=vocab_size,\n",
        "                seed=42,\n",
        "                name=\"negative_sampling\"\n",
        "            )\n",
        "\n",
        "            # Build context and label vectors (for one center word)\n",
        "            negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
        "\n",
        "            # Concat negative samples with true context word (positive sample)\n",
        "            context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
        "\n",
        "            # label 1 for positive sample and 0 for negative samples.\n",
        "            label = tf.constant([1] + [0] * num_negative_s, dtype=\"int64\")\n",
        "\n",
        "            # Append each element from the training example to global lists.\n",
        "            centers.append(center_word)\n",
        "            contexts.append(context)\n",
        "            labels.append(label)\n",
        "\n",
        "    return centers, contexts, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "DTnmJJiDmqcD",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Convert word tokens to their id with word_to_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sc848ScVmqcE",
        "outputId": "2ad18a87-e9be-4f59-e487-3988f9f9796d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2564, 976, 386, 1424, 24, 1666, 1094, 229],\n",
              " [256, 1234, 452, 3763, 870, 410, 22],\n",
              " [90, 2565, 664, 2011, 977, 345, 1424, 3764],\n",
              " [165, 3765, 229, 1425, 53, 779, 3766, 612, 236, 871],\n",
              " [37, 499, 1667, 978, 326, 2566, 247, 527, 1668, 103, 1095, 2567, 346],\n",
              " [1668, 613, 84, 2012, 665, 50, 9, 3767, 50, 9, 257, 2568],\n",
              " [780, 84, 614, 26, 283, 615, 84, 614, 615, 91, 257, 3768, 1235, 528],\n",
              " [1096, 10, 159, 1669, 529, 723, 1669, 3769, 69, 291, 1669, 3770, 67, 872],\n",
              " [3771, 124, 75, 1, 3772, 527, 1, 292, 3773, 111, 411, 3774, 1097],\n",
              " [171, 32, 3775, 5, 116, 326, 2569, 412, 214, 1098, 64, 724, 284]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tokenss = []\n",
        "for row in data[\"tokens\"].dropna().values:\n",
        "    if row:\n",
        "        tokenss.append([word_to_id[token] for token in row])\n",
        "    # print(row)\n",
        "tokenss[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u5TVwbhmmqcE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# max_length = 10\n",
        "# padded_tokens = pad_sequences(tokenss, padding='post')\n",
        "# padded_tokens.shape\n",
        "# padded_tokens = padded_tokens.tolist()\n",
        "# padded_tokens = [np.array(lst) for lst in padded_tokens]\n",
        "\n",
        "tokenss = [np.array(lst) for lst in tokenss]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NC0zXhjmqcE",
        "outputId": "d3f78c73-1eb6-4e8c-af6d-340ac63085e5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5316"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(tokenss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "XSvG2o57mqcE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Create ((center words, contexts words,), labels) for feed to network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "382195a81ee14640b2df2f349e44c043",
            "b744ffaa56654a68b878d9e59891cf86",
            "b5ccb15a46234943929bcfb420e8c1e5",
            "ce4e5b960eb847e3b9ff794d4028436d",
            "6bdc455b3a7e485fb57d34cea9b67f7d",
            "864bd3b66da146838231cc92d4af323a",
            "43a98a7a68744941888ccda9d8024d35",
            "3c6d01a49b9143d59e2cce292ecfb30e",
            "d8bf8f7f7558449d9046758ec9869467",
            "786cdf1aad6940a487e3c5f3758c3981",
            "d86c56966021401ea2fb37224bb0bdff"
          ]
        },
        "id": "TXUTZWnCmqcE",
        "outputId": "0eaa2eda-5e60-4f77-fe17-6156640d776b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sentenses:   0%|          | 0/5316 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "382195a81ee14640b2df2f349e44c043"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "targets.shape: (68861,)\n",
            "contexts.shape: (68861, 201)\n",
            "labels.shape: (68861, 201)\n"
          ]
        }
      ],
      "source": [
        "window_size = 5\n",
        "num_negative_samples = 200\n",
        "vocab_size = len(word_to_id) + 1\n",
        "\n",
        "centers, contexts, labels = generate_training_data(\n",
        "    sentences=tokenss,\n",
        "    window_size=window_size,\n",
        "    num_negative_s=num_negative_samples,\n",
        "    vocab_size=vocab_size\n",
        ")\n",
        "\n",
        "centers = np.array(centers)\n",
        "contexts = np.array(contexts)[:, :, 0]\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"targets.shape: {centers.shape}\")\n",
        "print(f\"contexts.shape: {contexts.shape}\")\n",
        "print(f\"labels.shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRk2epO5mqcF",
        "outputId": "6ddfd09d-2505-45d5-a844-87d3848f035d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 976,  976,  976,  976,  976,  976, 2011, 2011, 2011, 2011])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 386,  275,   26, ...,   35, 1784,  364],\n",
              "       [  24,  106,  232, ...,  278,  123, 8581],\n",
              "       [1424,  184, 1844, ...,  386, 1030,   23],\n",
              "       ...,\n",
              "       [2565, 1930, 1398, ...,  421, 6991,  479],\n",
              "       [ 664, 1080,  527, ...,  571,  200,  981],\n",
              "       [ 345,  342,  245, ..., 6658,   55,  671]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "centers[:10]\n",
        "print()\n",
        "contexts[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nk2-i16CmqcF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Use tensorflow caching feature and set batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-LPAK8JkmqcF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((centers, contexts), labels))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VewcDcvmqcF",
        "outputId": "8b2bbdd8-99d3-493c-e2e0-fb1ed91da9c6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((<tf.Tensor: shape=(1024,), dtype=int64, numpy=array([4019, 4069,   78, ...,  200,  382,  202])>, <tf.Tensor: shape=(1024, 201), dtype=int64, numpy=\n",
            "array([[  53, 1066,  741, ...,  585,  495,  194],\n",
            "       [  66,  128,    7, ...,  779,  100,   15],\n",
            "       [   1,    0,  392, ..., 3722, 6183, 1987],\n",
            "       ...,\n",
            "       [ 891,    0, 2409, ..., 4870, 1131,  347],\n",
            "       [ 152, 4964,    1, ...,   55,  127, 3228],\n",
            "       [ 193, 2135,  207, ...,  831,  868,  235]])>), <tf.Tensor: shape=(1024, 201), dtype=int64, numpy=\n",
            "array([[1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0]])>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(1):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Wiguk6XCmqcF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Build customize model with keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gQE6u9RGmqcF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class Word2Vec(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        self.target_embedding = layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim,\n",
        "            input_length=1,\n",
        "            name=\"center_embedding\"\n",
        "        )\n",
        "        self.context_embedding = layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim,\n",
        "            input_length=num_negative_samples + 1,\n",
        "            name=\"context_embedding\"\n",
        "        )\n",
        "\n",
        "    def call(self, pair):\n",
        "        target, context = pair\n",
        "        print()\n",
        "        print(f\"target = {target}\")\n",
        "        print(f\"context = {context}\")\n",
        "        # target: (batch, dummy)\n",
        "        # context: (batch, context)\n",
        "        if len(target.shape) == 2:\n",
        "            target = tf.squeeze(target, axis=1)\n",
        "        # target: (batch,)\n",
        "        word_emb = self.target_embedding(target)\n",
        "        print(f\"word_emb = {word_emb}\")\n",
        "\n",
        "        # word_emb: (batch, embed)\n",
        "        context_emb = self.context_embedding(context)\n",
        "        print(f\"context_emb = {context_emb}\")\n",
        "\n",
        "        # context_emb: (batch, context, embed)\n",
        "        # Einstein summation:\n",
        "        # define element-wise computation: sum(word_emb * context_emb)\n",
        "        # computes the dot product of target and context embeddings from a training pair\n",
        "        dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
        "        print(f\"dots = {dots}\")\n",
        "\n",
        "        # dots: (batch, context)\n",
        "        return dots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9ClvzqzFmqcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3811a8ce-8c7b-4dbe-d797-1ec41e5257db",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "target = Tensor(\"IteratorGetNext:0\", shape=(1024,), dtype=int64)\n",
            "context = Tensor(\"IteratorGetNext:1\", shape=(1024, 201), dtype=int64)\n",
            "word_emb = Tensor(\"word2_vec/center_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 200), dtype=float32)\n",
            "context_emb = Tensor(\"word2_vec/context_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 201, 200), dtype=float32)\n",
            "dots = Tensor(\"word2_vec/einsum/Einsum:0\", shape=(1024, 201), dtype=float32)\n",
            "\n",
            "target = Tensor(\"IteratorGetNext:0\", shape=(1024,), dtype=int64)\n",
            "context = Tensor(\"IteratorGetNext:1\", shape=(1024, 201), dtype=int64)\n",
            "word_emb = Tensor(\"word2_vec/center_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 200), dtype=float32)\n",
            "context_emb = Tensor(\"word2_vec/context_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 201, 200), dtype=float32)\n",
            "dots = Tensor(\"word2_vec/einsum/Einsum:0\", shape=(1024, 201), dtype=float32)\n",
            "67/67 [==============================] - 4s 12ms/step - loss: 5.3023 - accuracy: 0.0108\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 1s 12ms/step - loss: 5.2717 - accuracy: 0.2347\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 5.2183 - accuracy: 0.3703\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 5.1113 - accuracy: 0.3516\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 4.9198 - accuracy: 0.3303\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 4.6306 - accuracy: 0.3214\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 4.2601 - accuracy: 0.3240\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 3.8369 - accuracy: 0.3345\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 3.3941 - accuracy: 0.3537\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 2.9695 - accuracy: 0.3824\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 2.5912 - accuracy: 0.4215\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 2.2684 - accuracy: 0.4671\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.9981 - accuracy: 0.5145\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.7741 - accuracy: 0.5623\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.5899 - accuracy: 0.6041\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.4390 - accuracy: 0.6389\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.3155 - accuracy: 0.6680\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.2144 - accuracy: 0.6920\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.1313 - accuracy: 0.7125\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.0626 - accuracy: 0.7282\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 1.0054 - accuracy: 0.7404\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.9576 - accuracy: 0.7501\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.9174 - accuracy: 0.7572\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.8832 - accuracy: 0.7629\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.8540 - accuracy: 0.7676\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.8289 - accuracy: 0.7714\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.8073 - accuracy: 0.7743\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.7884 - accuracy: 0.7764\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.7719 - accuracy: 0.7781\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.7574 - accuracy: 0.7794\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.7446 - accuracy: 0.7802\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.7332 - accuracy: 0.7810\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.7231 - accuracy: 0.7814\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.7140 - accuracy: 0.7818\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.7058 - accuracy: 0.7819\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6984 - accuracy: 0.7821\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6917 - accuracy: 0.7824\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6856 - accuracy: 0.7825\n",
            "Epoch 39/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6800 - accuracy: 0.7826\n",
            "Epoch 40/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6749 - accuracy: 0.7824\n",
            "Epoch 41/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6702 - accuracy: 0.7823\n",
            "Epoch 42/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6659 - accuracy: 0.7822\n",
            "Epoch 43/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6619 - accuracy: 0.7824\n",
            "Epoch 44/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6582 - accuracy: 0.7824\n",
            "Epoch 45/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6548 - accuracy: 0.7824\n",
            "Epoch 46/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6516 - accuracy: 0.7824\n",
            "Epoch 47/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6487 - accuracy: 0.7824\n",
            "Epoch 48/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6459 - accuracy: 0.7823\n",
            "Epoch 49/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6433 - accuracy: 0.7822\n",
            "Epoch 50/50\n",
            "67/67 [==============================] - 1s 11ms/step - loss: 0.6409 - accuracy: 0.7822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f339bef5390>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "embedding_dim = 200\n",
        "epochs_ = 50\n",
        "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
        "word2vec.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "word2vec.fit(dataset, epochs=epochs_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mlqdd8LmqcG",
        "outputId": "23a7edf0-306d-428b-e448-2680cb631515",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"word2_vec\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " center_embedding (Embedding  multiple                 1784200   \n",
            " )                                                               \n",
            "                                                                 \n",
            " context_embedding (Embeddin  multiple                 1784200   \n",
            " g)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,568,400\n",
            "Trainable params: 3,568,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "word2vec.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cRcETY8TmqcG",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "weights = word2vec.get_layer('center_embedding').get_weights()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCJPPhpMmqcG",
        "outputId": "d67bcef5-8b80-4cd1-a9b8-e05f38d56d72",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8921, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create 3d/2d dimentions dataframe for plot interactive scaterplot by plotly library "
      ],
      "metadata": {
        "id": "kD_K6T54D2nj",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "three_dim = PCA(random_state=0).fit_transform(weights)[:,:3]\n",
        "dims3d = pd.DataFrame(three_dim, columns=['x', 'y', 'z'])\n",
        "\n",
        "two_dim = PCA(random_state=0).fit_transform(weights)[:,:2]\n",
        "dims2d = pd.DataFrame(two_dim, columns=['x', 'y'])\n",
        "\n",
        "dims3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "inJ05MwFq3Pf",
        "outputId": "5c1ba6c5-b6e3-49a3-9d2c-65a1c9dcc453",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             x         y         z\n",
              "0    -0.092723  0.041683 -0.118433\n",
              "1    -0.905167 -1.060118 -0.008223\n",
              "2    -0.872322  0.297999  0.571836\n",
              "3    -1.186339 -0.121312  0.090036\n",
              "4    -0.437850  0.352502 -0.226772\n",
              "...        ...       ...       ...\n",
              "8916  0.000476 -0.050569 -0.428646\n",
              "8917 -0.007373  0.064603 -0.079565\n",
              "8918 -0.373082 -0.329419 -0.312470\n",
              "8919 -0.593256  0.340133 -0.487560\n",
              "8920 -0.244244  0.322294 -0.246406\n",
              "\n",
              "[8921 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37784d02-3061-4367-a025-13e42dfa689c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.092723</td>\n",
              "      <td>0.041683</td>\n",
              "      <td>-0.118433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.905167</td>\n",
              "      <td>-1.060118</td>\n",
              "      <td>-0.008223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.872322</td>\n",
              "      <td>0.297999</td>\n",
              "      <td>0.571836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.186339</td>\n",
              "      <td>-0.121312</td>\n",
              "      <td>0.090036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.437850</td>\n",
              "      <td>0.352502</td>\n",
              "      <td>-0.226772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8916</th>\n",
              "      <td>0.000476</td>\n",
              "      <td>-0.050569</td>\n",
              "      <td>-0.428646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8917</th>\n",
              "      <td>-0.007373</td>\n",
              "      <td>0.064603</td>\n",
              "      <td>-0.079565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8918</th>\n",
              "      <td>-0.373082</td>\n",
              "      <td>-0.329419</td>\n",
              "      <td>-0.312470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8919</th>\n",
              "      <td>-0.593256</td>\n",
              "      <td>0.340133</td>\n",
              "      <td>-0.487560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8920</th>\n",
              "      <td>-0.244244</td>\n",
              "      <td>0.322294</td>\n",
              "      <td>-0.246406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8921 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37784d02-3061-4367-a025-13e42dfa689c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37784d02-3061-4367-a025-13e42dfa689c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37784d02-3061-4367-a025-13e42dfa689c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = list(word_to_id.keys())\n",
        "words.append('end')\n",
        "dims2d['token'] = words\n",
        "dims3d['token'] = words\n",
        "dims2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Tymhd-dHrtud",
        "outputId": "6f1ff4ea-46eb-4b68-a183-ffb3d07d173b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             x         y     token\n",
              "0    -0.092723  0.041683       جان\n",
              "1    -0.905167 -1.060118        دل\n",
              "2    -0.872322  0.297999       عشق\n",
              "3    -1.186339 -0.121312        سر\n",
              "4    -0.437850  0.352502        سو\n",
              "...        ...       ...       ...\n",
              "8916  0.000476 -0.050569  خیالاتست\n",
              "8917 -0.007373  0.064603      آکند\n",
              "8918 -0.373082 -0.329419     یکایک\n",
              "8919 -0.593256  0.340133   ترکانست\n",
              "8920 -0.244244  0.322294       end\n",
              "\n",
              "[8921 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64974a08-bb00-4ab7-ba75-58fb91651c3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.092723</td>\n",
              "      <td>0.041683</td>\n",
              "      <td>جان</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.905167</td>\n",
              "      <td>-1.060118</td>\n",
              "      <td>دل</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.872322</td>\n",
              "      <td>0.297999</td>\n",
              "      <td>عشق</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.186339</td>\n",
              "      <td>-0.121312</td>\n",
              "      <td>سر</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.437850</td>\n",
              "      <td>0.352502</td>\n",
              "      <td>سو</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8916</th>\n",
              "      <td>0.000476</td>\n",
              "      <td>-0.050569</td>\n",
              "      <td>خیالاتست</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8917</th>\n",
              "      <td>-0.007373</td>\n",
              "      <td>0.064603</td>\n",
              "      <td>آکند</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8918</th>\n",
              "      <td>-0.373082</td>\n",
              "      <td>-0.329419</td>\n",
              "      <td>یکایک</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8919</th>\n",
              "      <td>-0.593256</td>\n",
              "      <td>0.340133</td>\n",
              "      <td>ترکانست</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8920</th>\n",
              "      <td>-0.244244</td>\n",
              "      <td>0.322294</td>\n",
              "      <td>end</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8921 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64974a08-bb00-4ab7-ba75-58fb91651c3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64974a08-bb00-4ab7-ba75-58fb91651c3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64974a08-bb00-4ab7-ba75-58fb91651c3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dims2d.head(4000).to_pickle(\"dim2d.pkl\")\n",
        "dims3d.head(4000).to_pickle(\"dim3d.pkl\")"
      ],
      "metadata": {
        "id": "KgaWB19JtEsk",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "wyHjLGETmqcK",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Save weights of center_embedding layer (word embeddings) to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "P1vEhS1AmqcK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "file_name = f'weights_nneg{num_negative_samples}_em{embedding_dim}_ep{epochs_}_vocs{vocab_size}_ws{window_size}'\n",
        "np.save(file_name, weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "a3rlBiffmqcK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# load_file_name = f'weights_nneg{num_negative_samples}_em{embedding_dim}_ep{epochs_}_vocs{vocab_size}_ws{window_size}'\n",
        "# loaded_weights = np.load(load_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CGoccD-umqcK",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Find nearest neighbor word with cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IeHnZWT3mqcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcac1352-5124-4b00-c924-2565af7d2bee",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.0000001   0.02488649 -0.14393432 ...  0.05068644  0.09207495\n",
            "  -0.05432859]\n",
            " [ 0.02488649  0.9999999   0.0785493  ...  0.00671925  0.02046589\n",
            "   0.09932837]\n",
            " [-0.14393432  0.0785493   0.9999999  ... -0.04965016  0.04006981\n",
            "  -0.03086856]\n",
            " ...\n",
            " [ 0.05068644  0.00671925 -0.04965016 ...  0.9999998   0.01830586\n",
            "  -0.02928611]\n",
            " [ 0.09207495  0.02046589  0.04006981 ...  0.01830586  0.99999994\n",
            "  -0.01660015]\n",
            " [-0.05432859  0.09932837 -0.03086856 ... -0.02928611 -0.01660015\n",
            "   1.0000001 ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_matrix = cosine_similarity(weights, weights)\n",
        "print(cosine_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2kFiZah0mqcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a324c20a-cc12-47b5-fd7a-220cf4379c42",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8921, 8921)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "cosine_matrix.shape\n",
        "\n",
        "\n",
        "def cosine_similarity_word(words, cosine_matrix, n=10):\n",
        "    for word in words:\n",
        "        similars = []\n",
        "        for id in cosine_matrix[word_to_id[word]].argsort()[::-1][0:n]:\n",
        "            similars.append(id_to_word[id])\n",
        "        print(word, '=', similars, '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "R3DL2HjrmqcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e618d3a-8355-407a-c68d-f4a535865232",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('مه', 114),\n",
              " ('بس', 111),\n",
              " ('دانست#دان', 111),\n",
              " ('ماه', 110),\n",
              " ('کان', 109),\n",
              " ('پر', 109),\n",
              " ('روح', 107),\n",
              " ('عالم', 106),\n",
              " ('نی', 103),\n",
              " ('ره', 102),\n",
              " ('باد', 100),\n",
              " ('تن', 100),\n",
              " ('تبریز', 100),\n",
              " ('کار', 98),\n",
              " ('آنک', 98),\n",
              " ('گرفت#گیر', 95),\n",
              " ('خون', 93),\n",
              " ('پا', 92),\n",
              " ('رخ', 92),\n",
              " ('گه', 91)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "sorted_count_list[30:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save word_to_id and id_to_word into file to use it in web app"
      ],
      "metadata": {
        "id": "mrrghkmBhv60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('word_to_id.pkl', 'wb') as f:\n",
        "    pickle.dump(word_to_id, f)\n",
        "    \n",
        "with open('id_to_word.pkl', 'wb') as f:\n",
        "    pickle.dump(id_to_word, f)"
      ],
      "metadata": {
        "id": "Vy-vS77t9SKm",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "aif2a9tOmqcL",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UiG_DSZvmqcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab1fe04-c5d1-4e66-cf08-0bbd71aa6f12",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "حسین = ['حسین', 'آبدارست', 'حشرگاه', 'حسینی\\u200cگر', 'کربلا', 'کربلایی', 'پولادست', 'تیمم', 'خواهی_تو', 'مری'] \n",
            "\n",
            "یوسف = ['یوسف', 'هلا', 'اندرنگر', 'رونق', 'بریانست', 'کهکشان', 'بنماییمش', 'نبرد', 'پرآشوب', 'برپاست'] \n",
            "\n",
            "خسرو = ['خسرو', 'ربوده\\u200cاند', 'زیبایی', 'زمن', 'دردمید', 'شیرین', 'می\\u200cنروم', 'ماتست', 'غلغلی', 'نی'] \n",
            "\n",
            "فروغ = ['فروغ', 'کالمینا', 'نیزه', 'حکایت', 'تخت', 'بندیدی', 'میران', 'یارکان', 'غمضت', 'والا'] \n",
            "\n",
            "دجله = ['دجله', 'جیحون', 'بودندی', 'بدندی', 'مقیم', 'پرنم', 'صما', 'جوع', 'فرات', 'موش'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "cosine_similarity_word(['حسین', 'یوسف', 'خسرو', 'فروغ' ,'دجله'], cosine_matrix, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UehLoTCkmqcL",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for i, j in word_to_id.items():\n",
        "    if 'کم' in i[-2:]:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gF1-Db4mmqcM",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for i, j in word_to_id.items():\n",
        "    if '_' in i:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUW4xepi9mvN",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def generate_training_data(sentences, window_size, num_negative_s, vocab_size):\n",
        "    # Elements of each training example are appended to these lists.\n",
        "    centers, contexts, labels = [], [], []\n",
        "\n",
        "    # Build the sampling table for vocab_size tokens.\n",
        "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "    # Iterate over all sentences in corpus\n",
        "    for sequence in tqdm_notebook(sentences, desc='Sentenses', colour=\"MAGENTA\"):\n",
        "\n",
        "        # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "        positive_samples, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "            sequence,\n",
        "            vocabulary_size=vocab_size,\n",
        "            sampling_table=sampling_table,\n",
        "            window_size=window_size,\n",
        "            negative_samples=0\n",
        "        )\n",
        "\n",
        "        # Iterate over each positive skip-gram pair to produce training examples\n",
        "        # with positive context word and negative samples.\n",
        "        for center_word, context_word in positive_samples:\n",
        "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "\n",
        "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "                true_classes=context_class,\n",
        "                num_true=1,\n",
        "                num_sampled=num_negative_s,\n",
        "                unique=True,\n",
        "                range_max=vocab_size,\n",
        "                seed=42,\n",
        "                name=\"negative_sampling\"\n",
        "            )\n",
        "\n",
        "            # Build context and label vectors (for one center word)\n",
        "            negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
        "\n",
        "            # Concat negative samples with true context word (positive sample)\n",
        "            context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
        "\n",
        "            # label 1 for positive sample and 0 for negative samples.\n",
        "            label = tf.constant([1] + [0] * num_negative_s, dtype=\"int64\")\n",
        "\n",
        "            # Append each element from the training example to global lists.\n",
        "            centers.append(center_word)\n",
        "            contexts.append(context)\n",
        "            labels.append(label)\n",
        "\n",
        "    return centers, contexts, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RRySGgaqnSDA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Convert word tokens to their id with word_to_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y500_TQ9Wz4",
        "outputId": "4ccfc5e7-73ef-4a9b-e1ac-d312f238416a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[2565, 976, 386, 1424, 24, 1666, 1094, 229],\n",
              " [256, 1234, 452, 3764, 870, 410, 22],\n",
              " [90, 2566, 664, 2012, 977, 345, 1424, 3765],\n",
              " [165, 3766, 229, 1425, 53, 779, 3767, 612, 236, 871],\n",
              " [37, 499, 1667, 978, 326, 2567, 247, 527, 1668, 103, 1095, 2568, 346],\n",
              " [1668, 613, 84, 2013, 665, 50, 9, 3768, 50, 9, 257, 2569],\n",
              " [780, 84, 614, 26, 283, 615, 84, 614, 615, 91, 257, 3769, 1235, 528],\n",
              " [1096, 10, 159, 1669, 529, 723, 1669, 3770, 69, 291, 1669, 3771, 67, 872],\n",
              " [3772, 124, 75, 1, 3773, 527, 1, 292, 3774, 111, 411, 3775, 1097],\n",
              " [171, 32, 3776, 5, 116, 326, 2570, 412, 214, 1098, 64, 724, 284]]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenss = []\n",
        "for row in data[\"tokens\"].dropna().values:\n",
        "    if row:\n",
        "        tokenss.append([word_to_id[token] for token in row])\n",
        "    # print(row)\n",
        "tokenss[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahyUU3JdBP2Z",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# max_length = 10\n",
        "# padded_tokens = pad_sequences(tokenss, padding='post')\n",
        "# padded_tokens.shape\n",
        "# padded_tokens = padded_tokens.tolist()\n",
        "# padded_tokens = [np.array(lst) for lst in padded_tokens]\n",
        "\n",
        "tokenss = [np.array(lst) for lst in tokenss]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq49HZOcDnTh",
        "outputId": "c2b60c4b-3914-4dd6-894f-48794277f7cc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5316"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "WGlNx4l4nSDE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Create ((center words, contexts words,), labels) for feed to network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "afd63f39b87f46da9745675251273c45",
            "c9ddda96b9104aba834954ee14e783c7",
            "dea00032a72942448c3ea81d373ee29f",
            "3b20472e23f240308551359547732c3f",
            "b43f912f67014cbca28ee106e34abc6c",
            "ce9a77b5394742cc82bbda2e67892023",
            "ea2edbdc17004f369af35fcfd3aa61ab",
            "3d3212f92d43489dbd2659dd339532ca",
            "3dfaa4073c9d4a9ab2196c860c36f8fb",
            "e59fb63e784a430fa5e3efa4185aa3a6",
            "66436b6dd8eb416ba6a33deccdaee223"
          ]
        },
        "id": "A_8r-fJeFRrq",
        "outputId": "4b8910f2-e98a-4d5d-a1bd-2993ef513cd7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afd63f39b87f46da9745675251273c45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sentenses:   0%|          | 0/5316 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "targets.shape: (69457,)\n",
            "contexts.shape: (69457, 201)\n",
            "labels.shape: (69457, 201)\n"
          ]
        }
      ],
      "source": [
        "window_size = 5\n",
        "num_negative_samples = 200\n",
        "vocab_size = len(word_to_id) + 1\n",
        "\n",
        "centers, contexts, labels = generate_training_data(\n",
        "    sentences=tokenss,\n",
        "    window_size=window_size,\n",
        "    num_negative_s=num_negative_samples,\n",
        "    vocab_size=vocab_size\n",
        ")\n",
        "\n",
        "centers = np.array(centers)\n",
        "contexts = np.array(contexts)[:, :, 0]\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"targets.shape: {centers.shape}\")\n",
        "print(f\"contexts.shape: {contexts.shape}\")\n",
        "print(f\"labels.shape: {labels.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rStYwGuYFSgz",
        "outputId": "4bfc287e-4c82-4201-cf5f-7b84b81a439e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1424, 1424, 1424, 1424, 1424, 1424, 1424,  452,  452,  452])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1666,   14, 1273, ..., 2898, 4240,   71],\n",
              "       [2565,  613,   13, ...,  875, 5675, 2930],\n",
              "       [ 976, 2536, 1029, ...,  151, 1438,  563],\n",
              "       ...,\n",
              "       [ 870,    1,  531, ..., 2068,  608, 2819],\n",
              "       [3764, 5778,  531, ...,   29,  332,  120],\n",
              "       [ 256,    7,  626, ...,   15,  237, 1664]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "centers[:10]\n",
        "print()\n",
        "contexts[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "0HJfGW9onSDF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Use tensorflow caching feature and set batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpVCWt0fFSjt",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((centers, contexts), labels))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2OYODbNFSmf",
        "outputId": "a38c5a84-55db-4862-a2ac-169e3db3e06e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "((<tf.Tensor: shape=(1024,), dtype=int64, numpy=array([  22, 3917, 4230, ..., 4160, 1442, 2860])>, <tf.Tensor: shape=(1024, 201), dtype=int64, numpy=\n",
            "array([[ 131,  271,  406, ..., 1324,   48,   70],\n",
            "       [ 185,  762, 2120, ..., 4952,  175,  228],\n",
            "       [4232,  987,    3, ...,   33,  165, 6089],\n",
            "       ...,\n",
            "       [1758,   43,   20, ...,  266, 3292,  458],\n",
            "       [1542,    1,   12, ..., 2382,  152,  536],\n",
            "       [ 295,    6, 3240, ...,  977,  978,  168]])>), <tf.Tensor: shape=(1024, 201), dtype=int64, numpy=\n",
            "array([[1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0],\n",
            "       [1, 0, 0, ..., 0, 0, 0]])>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(1):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "fSXBvjIHnSDG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Build customize model with keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EQZu0orFSo3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "class Word2Vec(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        self.target_embedding = layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim,\n",
        "            input_length=1,\n",
        "            name=\"center_embedding\"\n",
        "        )\n",
        "        self.context_embedding = layers.Embedding(\n",
        "            vocab_size,\n",
        "            embedding_dim,\n",
        "            input_length=num_negative_samples + 1,\n",
        "            name=\"context_embedding\"\n",
        "        )\n",
        "\n",
        "    def call(self, pair):\n",
        "        target, context = pair\n",
        "        print()\n",
        "        print(f\"target = {target}\")\n",
        "        print(f\"context = {context}\")\n",
        "        # target: (batch, dummy)\n",
        "        # context: (batch, context)\n",
        "        if len(target.shape) == 2:\n",
        "            target = tf.squeeze(target, axis=1)\n",
        "        # target: (batch,)\n",
        "        word_emb = self.target_embedding(target)\n",
        "        print(f\"word_emb = {word_emb}\")\n",
        "\n",
        "        # word_emb: (batch, embed)\n",
        "        context_emb = self.context_embedding(context)\n",
        "        print(f\"context_emb = {context_emb}\")\n",
        "\n",
        "        # context_emb: (batch, context, embed)\n",
        "        # Einstein summation:\n",
        "        # define element-wise computation: sum(word_emb * context_emb)\n",
        "        # computes the dot product of target and context embeddings from a training pair\n",
        "        dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
        "        print(f\"dots = {dots}\")\n",
        "\n",
        "        # dots: (batch, context)\n",
        "        return dots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq8KldZCUzIV",
        "outputId": "b3142ec9-d35f-406c-c521-c43f6053120b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "target = Tensor(\"IteratorGetNext:0\", shape=(1024,), dtype=int64)\n",
            "context = Tensor(\"IteratorGetNext:1\", shape=(1024, 201), dtype=int64)\n",
            "word_emb = Tensor(\"word2_vec_7/center_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 200), dtype=float32)\n",
            "context_emb = Tensor(\"word2_vec_7/context_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 201, 200), dtype=float32)\n",
            "dots = Tensor(\"word2_vec_7/einsum/Einsum:0\", shape=(1024, 201), dtype=float32)\n",
            "\n",
            "target = Tensor(\"IteratorGetNext:0\", shape=(1024,), dtype=int64)\n",
            "context = Tensor(\"IteratorGetNext:1\", shape=(1024, 201), dtype=int64)\n",
            "word_emb = Tensor(\"word2_vec_7/center_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 200), dtype=float32)\n",
            "context_emb = Tensor(\"word2_vec_7/context_embedding/embedding_lookup/Identity_1:0\", shape=(1024, 201, 200), dtype=float32)\n",
            "dots = Tensor(\"word2_vec_7/einsum/Einsum:0\", shape=(1024, 201), dtype=float32)\n",
            "67/67 [==============================] - 11s 152ms/step - loss: 5.3026 - accuracy: 0.0106\n",
            "Epoch 2/50\n",
            "67/67 [==============================] - 10s 151ms/step - loss: 5.2722 - accuracy: 0.2294\n",
            "Epoch 3/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 5.2200 - accuracy: 0.3661\n",
            "Epoch 4/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 5.1156 - accuracy: 0.3458\n",
            "Epoch 5/50\n",
            "67/67 [==============================] - 10s 148ms/step - loss: 4.9287 - accuracy: 0.3244\n",
            "Epoch 6/50\n",
            "67/67 [==============================] - 10s 148ms/step - loss: 4.6454 - accuracy: 0.3159\n",
            "Epoch 7/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 4.2808 - accuracy: 0.3184\n",
            "Epoch 8/50\n",
            "67/67 [==============================] - 10s 148ms/step - loss: 3.8630 - accuracy: 0.3291\n",
            "Epoch 9/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 3.4240 - accuracy: 0.3483\n",
            "Epoch 10/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 3.0006 - accuracy: 0.3776\n",
            "Epoch 11/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 2.6214 - accuracy: 0.4164\n",
            "Epoch 12/50\n",
            "67/67 [==============================] - 10s 144ms/step - loss: 2.2962 - accuracy: 0.4621\n",
            "Epoch 13/50\n",
            "67/67 [==============================] - 10s 143ms/step - loss: 2.0231 - accuracy: 0.5105\n",
            "Epoch 14/50\n",
            "67/67 [==============================] - 10s 143ms/step - loss: 1.7963 - accuracy: 0.5588\n",
            "Epoch 15/50\n",
            "67/67 [==============================] - 10s 143ms/step - loss: 1.6095 - accuracy: 0.6000\n",
            "Epoch 16/50\n",
            "67/67 [==============================] - 10s 143ms/step - loss: 1.4565 - accuracy: 0.6358\n",
            "Epoch 17/50\n",
            "67/67 [==============================] - 10s 144ms/step - loss: 1.3313 - accuracy: 0.6665\n",
            "Epoch 18/50\n",
            "67/67 [==============================] - 10s 144ms/step - loss: 1.2289 - accuracy: 0.6905\n",
            "Epoch 19/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 1.1449 - accuracy: 0.7099\n",
            "Epoch 20/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 1.0755 - accuracy: 0.7246\n",
            "Epoch 21/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 1.0179 - accuracy: 0.7376\n",
            "Epoch 22/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.9698 - accuracy: 0.7470\n",
            "Epoch 23/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.9292 - accuracy: 0.7550\n",
            "Epoch 24/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.8948 - accuracy: 0.7611\n",
            "Epoch 25/50\n",
            "67/67 [==============================] - 10s 144ms/step - loss: 0.8654 - accuracy: 0.7655\n",
            "Epoch 26/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.8401 - accuracy: 0.7689\n",
            "Epoch 27/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.8182 - accuracy: 0.7715\n",
            "Epoch 28/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.7992 - accuracy: 0.7738\n",
            "Epoch 29/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.7825 - accuracy: 0.7752\n",
            "Epoch 30/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.7678 - accuracy: 0.7764\n",
            "Epoch 31/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.7549 - accuracy: 0.7775\n",
            "Epoch 32/50\n",
            "67/67 [==============================] - 10s 150ms/step - loss: 0.7433 - accuracy: 0.7782\n",
            "Epoch 33/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.7330 - accuracy: 0.7786\n",
            "Epoch 34/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 0.7238 - accuracy: 0.7788\n",
            "Epoch 35/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 0.7155 - accuracy: 0.7791\n",
            "Epoch 36/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.7079 - accuracy: 0.7792\n",
            "Epoch 37/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.7011 - accuracy: 0.7793\n",
            "Epoch 38/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 0.6949 - accuracy: 0.7794\n",
            "Epoch 39/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 0.6892 - accuracy: 0.7796\n",
            "Epoch 40/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 0.6841 - accuracy: 0.7797\n",
            "Epoch 41/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.6793 - accuracy: 0.7799\n",
            "Epoch 42/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.6749 - accuracy: 0.7801\n",
            "Epoch 43/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.6708 - accuracy: 0.7802\n",
            "Epoch 44/50\n",
            "67/67 [==============================] - 10s 147ms/step - loss: 0.6671 - accuracy: 0.7801\n",
            "Epoch 45/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.6636 - accuracy: 0.7801\n",
            "Epoch 46/50\n",
            "67/67 [==============================] - 10s 144ms/step - loss: 0.6603 - accuracy: 0.7801\n",
            "Epoch 47/50\n",
            "67/67 [==============================] - 10s 144ms/step - loss: 0.6573 - accuracy: 0.7800\n",
            "Epoch 48/50\n",
            "67/67 [==============================] - 10s 145ms/step - loss: 0.6545 - accuracy: 0.7799\n",
            "Epoch 49/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.6519 - accuracy: 0.7799\n",
            "Epoch 50/50\n",
            "67/67 [==============================] - 10s 146ms/step - loss: 0.6494 - accuracy: 0.7798\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f59a3e4a690>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_dim = 200\n",
        "epochs_ = 50\n",
        "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
        "word2vec.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "word2vec.fit(dataset, epochs=epochs_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuga96he-sI8",
        "outputId": "ff6d10a2-38a2-4da2-b9e7-9b142d83428c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"word2_vec_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " center_embedding (Embedding  multiple                 1784400   \n",
            " )                                                               \n",
            "                                                                 \n",
            " context_embedding (Embeddin  multiple                 1784400   \n",
            " g)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,568,800\n",
            "Trainable params: 3,568,800\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "word2vec.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IjCRWT2UzMp",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "weights = word2vec.get_layer('center_embedding').get_weights()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzOFekvTUzQE",
        "outputId": "5bd3d080-2f11-4b24-f3e8-b29e4a24417e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8922, 200)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ux_EmxI9nSDI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Save weights of center_embedding layer (word embeddings) to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhqiH-qBmLHg",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "file_name = f'weights_nneg{num_negative_samples}_em{embedding_dim}_ep{epochs_}_vocs{vocab_size}_ws{window_size}'\n",
        "np.save(file_name, weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrlv5pVQXRf7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "load_file_name = f'weights_nneg{num_negative_samples}_em{embedding_dim}_ep{epochs_}_vocs{vocab_size}_ws{window_size}'\n",
        "loaded_weights = np.load(load_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "x3wJq0P4nSDJ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Find nearest neighbor word with cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRcLLGhGGmfe",
        "outputId": "60e5f6fe-f400-45b9-9d7a-8d3e44d41241",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.0000001  -0.0833027  -0.02161321 ...  0.03165701  0.00011451\n",
            "  -0.06165543]\n",
            " [-0.0833027   1.          0.08032579 ...  0.01039312 -0.05719611\n",
            "  -0.01495304]\n",
            " [-0.02161321  0.08032579  1.         ... -0.0136863   0.07858521\n",
            "   0.01053756]\n",
            " ...\n",
            " [ 0.03165701  0.01039312 -0.0136863  ...  0.9999998  -0.19599128\n",
            "   0.08485357]\n",
            " [ 0.00011451 -0.05719611  0.07858521 ... -0.19599128  0.99999994\n",
            "  -0.08715412]\n",
            " [-0.06165543 -0.01495304  0.01053756 ...  0.08485357 -0.08715412\n",
            "   0.9999998 ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cosine_matrix = cosine_similarity(weights, weights)\n",
        "print(cosine_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCTzJRR_ueRJ",
        "outputId": "3c5aba96-715f-4871-ac0e-4054cef54daf",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8922, 8922)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_matrix.shape\n",
        "\n",
        "\n",
        "def cosine_similarity_word(words, cosine_matrix, n=10):\n",
        "    for word in words:\n",
        "        similars = []\n",
        "        for id in cosine_matrix[word_to_id[word]].argsort()[::-1][0:n]:\n",
        "            similars.append(id_to_word[id])\n",
        "        print(word, '=', similars, '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNDHBiDhFac2",
        "outputId": "0ef23380-faa1-4d5f-8459-aa09932c481d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('مه', 114),\n",
              " ('بس', 111),\n",
              " ('دانست#دان', 111),\n",
              " ('ماه', 110),\n",
              " ('کان', 109),\n",
              " ('پر', 109),\n",
              " ('روح', 107),\n",
              " ('عالم', 106),\n",
              " ('نی', 103),\n",
              " ('ره', 102),\n",
              " ('باد', 100),\n",
              " ('تن', 100),\n",
              " ('تبریز', 100),\n",
              " ('کار', 98),\n",
              " ('آنک', 98),\n",
              " ('گرفت#گیر', 95),\n",
              " ('خون', 93),\n",
              " ('پا', 92),\n",
              " ('رخ', 92),\n",
              " ('گه', 91)]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_count_list[30:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2MqoVMGIloh",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_mtFn5jQnSDL",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uspZBpGlHXa8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngg5QhPQXhxD",
        "outputId": "9b4c3414-edb1-4605-ad24-6b5b54e347dd",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "شاه = ['شاه', 'فتادست', 'فساق', 'همامست', 'مباش', 'خسروان', 'شهرست', 'بندگان', 'مکافات', 'گردد\\u200cگر'] \n",
            "\n",
            "یوسف = ['یوسف', 'سیماست', 'زلیخا', 'بریدند', 'نتیجه', 'اندرنگر', 'تمامست', 'دهل', 'اعلا', 'بیچاره'] \n",
            "\n",
            "خسرو = ['خسرو', 'ما\\u200cگر', 'خورشیدروی', 'قباد', 'بشاید', 'بازبیاریم', 'مخدوم', 'انس', 'سرور', 'حسرت'] \n",
            "\n",
            "گل = ['گل', 'هامونست', 'بدریده\\u200cای', 'میوه', 'گرینده', 'سامریست', 'اندرفتد', 'بخندان', 'مپیچان', 'گوارد'] \n",
            "\n",
            "دجله = ['دجله', 'فرات', 'جیحون', 'مقیم', 'صخره', 'صما', 'پرنم', 'بدندی', 'زهر', 'ویس'] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "cosine_similarity_word(['شاه', 'یوسف', 'خسرو', 'گل','دجله'], cosine_matrix, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6zZyXS0FCa0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "word_to_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEu-adE2UzzP",
        "outputId": "98571d76-a47d-4572-ce44-081d937a17e9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "کم\n",
            "حکم\n",
            "شکم\n",
            "حاکم\n",
            "هواکم\n",
            "فقدکم\n",
            "اصحابکم\n",
            "اعقابکم\n",
            "جنبکم\n",
            "ذنبکم\n",
            "ربکم\n",
            "تفاحکم\n",
            "اصباحکم\n",
            "ارواحکم\n",
            "اریاحکم\n",
            "یعقوبکم\n",
            "قدامکم\n",
            "دونکم\n",
            "لحظکم\n",
            "لقیاکم\n",
            "لقائکم\n",
            "شدکم\n",
            "بهواکم\n",
            "عنکم\n",
            "فناکم\n",
            "رایناکم\n",
            "بضیاکم\n",
            "بلاکم\n",
            "غیرکم\n",
            "سواکم\n",
            "حورکم\n",
            "احیاکم\n",
            "حیاتکم\n",
            "یترککم\n",
            "ودکم\n",
            "خلاکم\n",
            "فدیتکم\n",
            "قتیلکم\n",
            "فاتکم\n",
            "بدتکم\n",
            "ایبکم\n",
            "می‌کم\n"
          ]
        }
      ],
      "source": [
        "for i, j in word_to_id.items():\n",
        "    if 'کم' in i[-2:]:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPT7884wdz_f",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for i, j in word_to_id.items():\n",
        "    if '_' in i:\n",
        "        print(i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "word2vec_negative_sampling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b20472e23f240308551359547732c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e59fb63e784a430fa5e3efa4185aa3a6",
            "placeholder": "​",
            "style": "IPY_MODEL_66436b6dd8eb416ba6a33deccdaee223",
            "value": " 5316/5316 [00:17&lt;00:00, 431.85it/s]"
          }
        },
        "3d3212f92d43489dbd2659dd339532ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dfaa4073c9d4a9ab2196c860c36f8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": "MAGENTA",
            "description_width": ""
          }
        },
        "66436b6dd8eb416ba6a33deccdaee223": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afd63f39b87f46da9745675251273c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9ddda96b9104aba834954ee14e783c7",
              "IPY_MODEL_dea00032a72942448c3ea81d373ee29f",
              "IPY_MODEL_3b20472e23f240308551359547732c3f"
            ],
            "layout": "IPY_MODEL_b43f912f67014cbca28ee106e34abc6c"
          }
        },
        "b43f912f67014cbca28ee106e34abc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ddda96b9104aba834954ee14e783c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9a77b5394742cc82bbda2e67892023",
            "placeholder": "​",
            "style": "IPY_MODEL_ea2edbdc17004f369af35fcfd3aa61ab",
            "value": "Sentenses: 100%"
          }
        },
        "ce9a77b5394742cc82bbda2e67892023": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea00032a72942448c3ea81d373ee29f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d3212f92d43489dbd2659dd339532ca",
            "max": 5316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3dfaa4073c9d4a9ab2196c860c36f8fb",
            "value": 5316
          }
        },
        "e59fb63e784a430fa5e3efa4185aa3a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea2edbdc17004f369af35fcfd3aa61ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "382195a81ee14640b2df2f349e44c043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b744ffaa56654a68b878d9e59891cf86",
              "IPY_MODEL_b5ccb15a46234943929bcfb420e8c1e5",
              "IPY_MODEL_ce4e5b960eb847e3b9ff794d4028436d"
            ],
            "layout": "IPY_MODEL_6bdc455b3a7e485fb57d34cea9b67f7d"
          }
        },
        "b744ffaa56654a68b878d9e59891cf86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_864bd3b66da146838231cc92d4af323a",
            "placeholder": "​",
            "style": "IPY_MODEL_43a98a7a68744941888ccda9d8024d35",
            "value": "Sentenses: 100%"
          }
        },
        "b5ccb15a46234943929bcfb420e8c1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c6d01a49b9143d59e2cce292ecfb30e",
            "max": 5316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8bf8f7f7558449d9046758ec9869467",
            "value": 5316
          }
        },
        "ce4e5b960eb847e3b9ff794d4028436d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786cdf1aad6940a487e3c5f3758c3981",
            "placeholder": "​",
            "style": "IPY_MODEL_d86c56966021401ea2fb37224bb0bdff",
            "value": " 5316/5316 [00:58&lt;00:00, 118.46it/s]"
          }
        },
        "6bdc455b3a7e485fb57d34cea9b67f7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "864bd3b66da146838231cc92d4af323a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a98a7a68744941888ccda9d8024d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c6d01a49b9143d59e2cce292ecfb30e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8bf8f7f7558449d9046758ec9869467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": "MAGENTA",
            "description_width": ""
          }
        },
        "786cdf1aad6940a487e3c5f3758c3981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86c56966021401ea2fb37224bb0bdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}