{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caf6ab00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from hazm import word_tokenize, Lemmatizer, Stemmer, Normalizer\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67f0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d9f4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "دیوان شمس تبریزی (غزلیات)    صورت دل صورت مخلوق نیست\\tکز رخ دل حسن خدا رو نمود\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = pd.read_csv('Shams_Corpus_Paper3.txt')\n",
    "raw_text.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7e79b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.getcwd() + \"/Shams_Corpus_Paper3.txt\", \"rt\")\n",
    "raw_text = file.read()\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f3cef90",
   "metadata": {},
   "source": [
    "#raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673044c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_persian_stopword(tokens):\n",
    "    file = open(os.getcwd() + \"/persian_stopw.txt\", \"rt\")\n",
    "    raw_stop_words = file.read()\n",
    "    file.close()\n",
    "\n",
    "    stop_words = word_tokenize(raw_stop_words)\n",
    "\n",
    "    return [word for word in tokens if not word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc545103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    normalizer = Normalizer()\n",
    "    \n",
    "    return normalizer.normalize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8bd82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_tokenizer(tokens):\n",
    "    lemmatizer = Lemmatizer()    \n",
    "    return [lemmatizer.lemmatize(token).split(\"#\")[-1] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32725243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokenizer(tokens):\n",
    "    stemmer = Stemmer()\n",
    "    return [stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7245f720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78389"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = \"\".join([i for i in raw_text if not i.isdigit()])\n",
    "raw_text = re.sub(r\"-+|\\d+\", \"\", raw_text)\n",
    "\n",
    "raw_text = normalize_text(raw_text)\n",
    "\n",
    "raw_tokens = word_tokenize(raw_text)\n",
    "len(raw_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ff051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43de9372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47335"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = remove_persian_stopword(raw_tokens)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f815ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fc0ec86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('دل', 621),\n",
       " ('جان', 587),\n",
       " ('عشق', 455),\n",
       " ('سر', 390),\n",
       " ('شمس', 210),\n",
       " ('خوش', 187),\n",
       " ('آب', 179),\n",
       " ('دست', 175),\n",
       " ('سوی', 174),\n",
       " ('چشم', 171),\n",
       " ('خویش', 171),\n",
       " ('جهان', 167),\n",
       " ('صد', 165),\n",
       " ('یار', 162),\n",
       " ('دم', 154),\n",
       " ('روی', 145),\n",
       " ('شب', 143),\n",
       " ('کار', 141),\n",
       " ('رو', 140),\n",
       " ('مست', 138)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_list = sorted(t.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "count_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8dd20c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45614\n",
      "45349\n"
     ]
    }
   ],
   "source": [
    "lammatized_tokens = remove_persian_stopword(lemma_tokenizer(tokens))\n",
    "print(len(lammatized_tokens))\n",
    "\n",
    "stemmed_tokens = remove_persian_stopword(stem_tokenizer(tokens))\n",
    "print(len(stemmed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1de54105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['دیوان',\n",
       " 'شمس',\n",
       " 'تبریزی',\n",
       " 'غزلیات',\n",
       " 'آه',\n",
       " 'شمع',\n",
       " 'منور',\n",
       " 'کآتش',\n",
       " 'زن',\n",
       " 'دل',\n",
       " 'دل',\n",
       " 'ربود',\n",
       " 'زده',\n",
       " 'دل',\n",
       " 'آتش',\n",
       " 'سوز',\n",
       " 'دوست',\n",
       " 'زود',\n",
       " 'زود',\n",
       " 'دل']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lammatized_tokens[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7677d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95529f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(*iterables):\n",
    "    for iterable in iterables:\n",
    "        yield from iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3661ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(id, vocab_size):\n",
    "    res = [0] * vocab_size\n",
    "    res[id] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19cf7241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(tokens, word_to_id, window):\n",
    "    X = []\n",
    "    y = []\n",
    "    n_tokens = len(tokens)\n",
    "    #     unique_tokens = len(word_to_id)\n",
    "    for i in range(n_tokens):\n",
    "        idx = concat(\n",
    "            range(max(0, i - window), i), range(i, min(n_tokens, i + window + 1))\n",
    "        )\n",
    "        for j in idx:\n",
    "            if i == j:\n",
    "                continue\n",
    "            X.append(one_hot_encode(word_to_id[tokens[i]] - 1, len(word_to_id)))\n",
    "            y.append(one_hot_encode(word_to_id[tokens[j]] - 1, len(word_to_id)))\n",
    "\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82f9caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data_imp(tokens, word_to_id, window):\n",
    "    X = []\n",
    "    y = []\n",
    "    n_tokens = len(tokens)\n",
    "    unique_tokens = len(word_to_id)\n",
    "    for i in range(n_tokens):\n",
    "        idx = concat(\n",
    "            range(max(0, i - window), i), range(i, min(n_tokens, i + window + 1))\n",
    "        )\n",
    "        for j in idx:\n",
    "            if i == j:\n",
    "                continue\n",
    "            X.append(word_to_id[tokens[i]] - 1)\n",
    "            y.append(word_to_id[tokens[j]] - 1)\n",
    "\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aa2aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(tokens, word_to_id, window):\n",
    "    X = []\n",
    "    y = []\n",
    "    unique_token = len(word_to_id)\n",
    "    n_tokens = len(tokens)\n",
    "    #     unique_tokens = len(word_to_id)\n",
    "    for i in range(n_tokens):\n",
    "        idx = concat(\n",
    "            range(max(0, i - window), i), \n",
    "            range(i, min(n_tokens, i + window + 1))\n",
    "        )\n",
    "\n",
    "        X.append(one_hot_encode(word_to_id[tokens[i]] - 1, unique_token))\n",
    "        y.append(one_hot_encode_agg(tokens, unique_token, idx, i))\n",
    "\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17a873f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_agg(tokens, vocab_size, idx, i):\n",
    "    res = [0] * vocab_size\n",
    "    for id in idx:\n",
    "        if i == id:\n",
    "            continue\n",
    "        res[word_to_id[tokens[id]] - 1] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a3653f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_ = lammatized_tokens\n",
    "t = Tokenizer(filters=\"\")\n",
    "t.fit_on_texts(tokens_)\n",
    "sorted_count_list = sorted(t.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "word_to_id, id_to_word = t.word_index, t.index_word\n",
    "X, y = generate_training_data_imp(tokens_, word_to_id, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c96627d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'دل': 1,\n",
       " 'جان': 2,\n",
       " 'عشق': 3,\n",
       " 'سر': 4,\n",
       " 'دان': 5,\n",
       " 'رو': 6,\n",
       " 'گو': 7,\n",
       " 'گرد': 8,\n",
       " 'بین': 9,\n",
       " 'مست': 10,\n",
       " 'سو': 11,\n",
       " 'شمس': 12,\n",
       " 'چشم': 13,\n",
       " 'خوش': 14,\n",
       " 'آب': 15,\n",
       " 'دست': 16,\n",
       " 'عاشق': 17,\n",
       " 'زن': 18,\n",
       " 'یار': 19,\n",
       " 'جهان': 20,\n",
       " 'خویش': 21,\n",
       " 'کار': 22,\n",
       " 'شب': 23,\n",
       " 'پر': 24,\n",
       " 'صد': 25,\n",
       " 'کش': 26,\n",
       " 'دم': 27,\n",
       " 'روز': 28,\n",
       " 'روی': 29,\n",
       " 'آ': 30,\n",
       " 'شکر': 31,\n",
       " 'خور': 32,\n",
       " 'آتش': 33,\n",
       " 'گل': 34,\n",
       " 'خون': 35,\n",
       " 'غم': 36,\n",
       " 'خاک': 37,\n",
       " 'نی': 38,\n",
       " 'نگر': 39,\n",
       " 'بس': 40,\n",
       " 'ماه': 41,\n",
       " 'باده': 42,\n",
       " 'ره': 43,\n",
       " 'کو': 44,\n",
       " 'عقل': 45,\n",
       " 'رس': 46,\n",
       " 'مه': 47,\n",
       " 'نور': 48,\n",
       " 'بند': 49,\n",
       " 'باز': 50,\n",
       " 'تن': 51,\n",
       " 'لب': 52,\n",
       " 'لطف': 53,\n",
       " 'خورشید': 54,\n",
       " 'ترش': 55,\n",
       " 'شیر': 56,\n",
       " 'خانه': 57,\n",
       " 'رخ': 58,\n",
       " 'جو': 59,\n",
       " 'چرخ': 60,\n",
       " 'جمله': 61,\n",
       " 'نظر': 62,\n",
       " 'آخر': 63,\n",
       " 'عالم': 64,\n",
       " 'گوش': 65,\n",
       " 'جام': 66,\n",
       " 'زین': 67,\n",
       " 'آفتاب': 68,\n",
       " 'پرده': 69,\n",
       " 'تبریز': 70,\n",
       " 'دین': 71,\n",
       " 'باغ': 72,\n",
       " 'باد': 73,\n",
       " 'دور': 74,\n",
       " 'شاه': 75,\n",
       " 'زر': 76,\n",
       " 'شه': 77,\n",
       " 'سیر': 78,\n",
       " 'دریا': 79,\n",
       " 'چونک': 80,\n",
       " 'ساقی': 81,\n",
       " 'سنگ': 82,\n",
       " 'تبریزی': 83,\n",
       " 'خواب': 84,\n",
       " 'شکن': 85,\n",
       " 'گشت': 86,\n",
       " 'پی': 87,\n",
       " 'خبر': 88,\n",
       " 'پای': 89,\n",
       " 'شنو': 90,\n",
       " 'روح': 91,\n",
       " 'نقش': 92,\n",
       " 'زه': 93,\n",
       " 'می': 94,\n",
       " 'شراب': 95,\n",
       " 'کان': 96,\n",
       " 'دیده': 97,\n",
       " 'برون': 98,\n",
       " 'درد': 99,\n",
       " 'مرغ': 100,\n",
       " 'بحر': 101,\n",
       " 'زیر': 102,\n",
       " 'میان': 103,\n",
       " 'مس': 104,\n",
       " 'خدا': 105,\n",
       " 'خمار': 106,\n",
       " 'گه': 107,\n",
       " 'خم': 108,\n",
       " 'دوست': 109,\n",
       " 'رنگ': 110,\n",
       " 'بهر': 111,\n",
       " 'وان': 112,\n",
       " 'خار': 113,\n",
       " 'خام': 114,\n",
       " 'پا': 115,\n",
       " 'آنک': 116,\n",
       " 'خیال': 117,\n",
       " 'سایه': 118,\n",
       " 'نفس': 119,\n",
       " 'لا': 120,\n",
       " 'خر': 121,\n",
       " 'روان': 122,\n",
       " 'خواجه': 123,\n",
       " 'پسر': 124,\n",
       " 'بد': 125,\n",
       " 'کف': 126,\n",
       " 'فلک': 127,\n",
       " 'سلام': 128,\n",
       " 'دهان': 129,\n",
       " 'خوان': 130,\n",
       " 'غیر': 131,\n",
       " 'خلق': 132,\n",
       " 'بو': 133,\n",
       " 'سفر': 134,\n",
       " 'کم': 135,\n",
       " 'خو': 136,\n",
       " 'زمین': 137,\n",
       " 'شمع': 138,\n",
       " 'سوز': 139,\n",
       " 'بنده': 140,\n",
       " 'لحظه': 141,\n",
       " 'کنار': 142,\n",
       " 'بدان': 143,\n",
       " 'دام': 144,\n",
       " 'دوش': 145,\n",
       " 'مرد': 146,\n",
       " 'یوسف': 147,\n",
       " 'جمال': 148,\n",
       " 'شوم': 149,\n",
       " 'مگیر': 150,\n",
       " 'زار': 151,\n",
       " 'زخم': 152,\n",
       " 'میر': 153,\n",
       " 'حال': 154,\n",
       " 'نیم': 155,\n",
       " 'سحر': 156,\n",
       " 'شکار': 157,\n",
       " 'اندیشه': 158,\n",
       " 'پنهان': 159,\n",
       " 'آسمان': 160,\n",
       " 'سخن': 161,\n",
       " 'گشا': 162,\n",
       " 'توبه': 163,\n",
       " 'حسن': 164,\n",
       " 'دید': 165,\n",
       " 'نشین': 166,\n",
       " 'ساغر': 167,\n",
       " 'بهار': 168,\n",
       " 'وقت': 169,\n",
       " 'رسید': 170,\n",
       " 'سلطان': 171,\n",
       " 'ذره': 172,\n",
       " 'گوهر': 173,\n",
       " 'نهان': 174,\n",
       " 'ملک': 175,\n",
       " 'ترس': 176,\n",
       " 'علیک': 177,\n",
       " 'یاد': 178,\n",
       " 'زیرا': 179,\n",
       " 'صبر': 180,\n",
       " 'زبان': 181,\n",
       " 'گاه': 182,\n",
       " 'تیر': 183,\n",
       " 'اسرار': 184,\n",
       " 'حلقه': 185,\n",
       " 'نگار': 186,\n",
       " 'نما': 187,\n",
       " 'خراب': 188,\n",
       " 'دلبر': 189,\n",
       " 'کل': 190,\n",
       " 'گذر': 191,\n",
       " 'قمر': 192,\n",
       " 'جانب': 193,\n",
       " 'اقبال': 194,\n",
       " 'وین': 195,\n",
       " 'خوار': 196,\n",
       " 'ساز': 197,\n",
       " 'زلف': 198,\n",
       " 'چنگ': 199,\n",
       " 'اصل': 200,\n",
       " 'خوب': 201,\n",
       " 'قرار': 202,\n",
       " 'توس': 203,\n",
       " 'سماع': 204,\n",
       " 'شیرین': 205,\n",
       " 'روم': 206,\n",
       " 'شاد': 207,\n",
       " 'برو': 208,\n",
       " 'عیش': 209,\n",
       " 'زمان': 210,\n",
       " 'هین': 211,\n",
       " 'زند': 212,\n",
       " 'کوه': 213,\n",
       " 'اوست': 214,\n",
       " 'شاخ': 215,\n",
       " 'رقص': 216,\n",
       " 'قد': 217,\n",
       " 'دولت': 218,\n",
       " 'گلزار': 219,\n",
       " 'جگر': 220,\n",
       " 'درون': 221,\n",
       " 'گرم': 222,\n",
       " 'سودا': 223,\n",
       " 'جای': 224,\n",
       " 'الدین': 225,\n",
       " 'نوش': 226,\n",
       " 'بازار': 227,\n",
       " 'ابر': 228,\n",
       " 'برای': 229,\n",
       " 'عجب': 230,\n",
       " 'مپرس': 231,\n",
       " 'آرد': 232,\n",
       " 'حیات': 233,\n",
       " 'برد': 234,\n",
       " 'ترک': 235,\n",
       " 'هله': 236,\n",
       " 'پاک': 237,\n",
       " 'صنم': 238,\n",
       " 'عمر': 239,\n",
       " 'مجنون': 240,\n",
       " 'مر': 241,\n",
       " 'توام': 242,\n",
       " 'آه': 243,\n",
       " 'عیسی': 244,\n",
       " 'تنگ': 245,\n",
       " 'ریز': 246,\n",
       " 'ان': 247,\n",
       " 'روشن': 248,\n",
       " 'پرس': 249,\n",
       " 'راست': 250,\n",
       " 'گردون': 251,\n",
       " 'بیمار': 252,\n",
       " 'زانک': 253,\n",
       " 'فنا': 254,\n",
       " 'گشته': 255,\n",
       " 'خرد': 256,\n",
       " 'خفته': 257,\n",
       " 'موج': 258,\n",
       " 'خشک': 259,\n",
       " 'ولیک': 260,\n",
       " 'گذار': 261,\n",
       " 'زنده': 262,\n",
       " 'هوا': 263,\n",
       " 'کرده': 264,\n",
       " 'مگو': 265,\n",
       " 'کاین': 266,\n",
       " 'جنگ': 267,\n",
       " 'گهی': 268,\n",
       " 'نیز': 269,\n",
       " 'دمی': 270,\n",
       " 'بانگ': 271,\n",
       " 'بخش': 272,\n",
       " 'بخت': 273,\n",
       " 'رخت': 274,\n",
       " 'مرگ': 275,\n",
       " 'بلبل': 276,\n",
       " 'کور': 277,\n",
       " 'سرو': 278,\n",
       " 'درآ': 279,\n",
       " 'طرف': 280,\n",
       " 'بام': 281,\n",
       " 'گنج': 282,\n",
       " 'وصل': 283,\n",
       " 'افت': 284,\n",
       " 'الله': 285,\n",
       " 'طرب': 286,\n",
       " 'خندان': 287,\n",
       " 'شهر': 288,\n",
       " 'تیغ': 289,\n",
       " 'بیرون': 290,\n",
       " 'لعل': 291,\n",
       " 'بیدار': 292,\n",
       " 'دلدار': 293,\n",
       " 'حرف': 294,\n",
       " 'سه': 295,\n",
       " 'گردن': 296,\n",
       " 'درخت': 297,\n",
       " 'تعال': 298,\n",
       " 'سپر': 299,\n",
       " 'حریف': 300,\n",
       " 'سینه': 301,\n",
       " 'کرم': 302,\n",
       " 'برگ': 303,\n",
       " 'منگر': 304,\n",
       " 'بجز': 305,\n",
       " 'سرمستم': 306,\n",
       " 'تار': 307,\n",
       " 'نان': 308,\n",
       " 'جامه': 309,\n",
       " 'پشت': 310,\n",
       " 'گم': 311,\n",
       " 'جوی': 312,\n",
       " 'بنه': 313,\n",
       " 'بال': 314,\n",
       " 'دانه': 315,\n",
       " 'آینه': 316,\n",
       " 'لیک': 317,\n",
       " 'طواف': 318,\n",
       " 'زود': 319,\n",
       " 'چاه': 320,\n",
       " 'رحمت': 321,\n",
       " 'طبل': 322,\n",
       " 'صاف': 323,\n",
       " 'گلشن': 324,\n",
       " 'شور': 325,\n",
       " 'عدم': 326,\n",
       " 'بسته': 327,\n",
       " 'ناز': 328,\n",
       " 'باقی': 329,\n",
       " 'نو': 330,\n",
       " 'شادی': 331,\n",
       " 'قوم': 332,\n",
       " 'کمر': 333,\n",
       " 'مرده': 334,\n",
       " 'بستان': 335,\n",
       " 'منه': 336,\n",
       " 'هشیار': 337,\n",
       " 'هجر': 338,\n",
       " 'طبیب': 339,\n",
       " 'غیب': 340,\n",
       " 'کنون': 341,\n",
       " 'بسیار': 342,\n",
       " 'رود': 343,\n",
       " 'کوی': 344,\n",
       " 'سگ': 345,\n",
       " 'پیر': 346,\n",
       " 'غلام': 347,\n",
       " 'زبر': 348,\n",
       " 'موسی': 349,\n",
       " 'کر': 350,\n",
       " 'هوش': 351,\n",
       " 'یقین': 352,\n",
       " 'دی': 353,\n",
       " 'بدین': 354,\n",
       " 'صید': 355,\n",
       " 'بینی': 356,\n",
       " 'پست': 357,\n",
       " 'خاموش': 358,\n",
       " 'اینک': 359,\n",
       " 'مطرب': 360,\n",
       " 'زرد': 361,\n",
       " 'آهسته': 362,\n",
       " 'ذوق': 363,\n",
       " 'گلستان': 364,\n",
       " 'پری': 365,\n",
       " 'آنچ': 366,\n",
       " 'فارغ': 367,\n",
       " 'فتنه': 368,\n",
       " 'بت': 369,\n",
       " 'بیش': 370,\n",
       " 'نیک': 371,\n",
       " 'الحق': 372,\n",
       " 'ایمان': 373,\n",
       " 'ناله': 374,\n",
       " 'اندک': 375,\n",
       " 'اشک': 376,\n",
       " 'فراق': 377,\n",
       " 'جنس': 378,\n",
       " 'قدح': 379,\n",
       " 'آدم': 380,\n",
       " 'سجده': 381,\n",
       " 'هوس': 382,\n",
       " 'گور': 383,\n",
       " 'پوش': 384,\n",
       " 'ملول': 385,\n",
       " 'رشک': 386,\n",
       " 'خموش': 387,\n",
       " 'فر': 388,\n",
       " 'وصال': 389,\n",
       " 'شرم': 390,\n",
       " 'مجلس': 391,\n",
       " 'ایشان': 392,\n",
       " 'دیوانه': 393,\n",
       " 'سرمست': 394,\n",
       " 'کردی': 395,\n",
       " 'چمن': 396,\n",
       " 'گفتا': 397,\n",
       " 'مترس': 398,\n",
       " 'دستار': 399,\n",
       " 'غار': 400,\n",
       " 'خند': 401,\n",
       " 'خس': 402,\n",
       " 'برخیز': 403,\n",
       " 'کیست': 404,\n",
       " 'دستم': 405,\n",
       " 'آواز': 406,\n",
       " 'کافر': 407,\n",
       " 'خوبی': 408,\n",
       " 'رها': 409,\n",
       " 'لم': 410,\n",
       " 'جوش': 411,\n",
       " 'شاهد': 412,\n",
       " 'گهر': 413,\n",
       " 'شر': 414,\n",
       " 'کشتی': 415,\n",
       " 'طلب': 416,\n",
       " 'مخمور': 417,\n",
       " 'مشک': 418,\n",
       " 'کای': 419,\n",
       " 'خداوند': 420,\n",
       " 'خدمت': 421,\n",
       " 'مهر': 422,\n",
       " 'صفا': 423,\n",
       " 'رب': 424,\n",
       " 'خسته': 425,\n",
       " 'رنج': 426,\n",
       " 'حرص': 427,\n",
       " 'زنگ': 428,\n",
       " 'مدد': 429,\n",
       " 'جمع': 430,\n",
       " 'کفر': 431,\n",
       " 'مو': 432,\n",
       " 'حجاب': 433,\n",
       " 'ابد': 434,\n",
       " 'دیو': 435,\n",
       " 'نعره': 436,\n",
       " 'الا': 437,\n",
       " 'غلط': 438,\n",
       " 'بلا': 439,\n",
       " 'چهره': 440,\n",
       " 'خیره': 441,\n",
       " 'ننگ': 442,\n",
       " 'صبح': 443,\n",
       " 'زنهار': 444,\n",
       " 'زهر': 445,\n",
       " 'یعنی': 446,\n",
       " 'بیزار': 447,\n",
       " 'گفتار': 448,\n",
       " 'کاندر': 449,\n",
       " 'آهن': 450,\n",
       " 'اسب': 451,\n",
       " 'سرد': 452,\n",
       " 'شکل': 453,\n",
       " 'آموز': 454,\n",
       " 'غرقه': 455,\n",
       " 'تخت': 456,\n",
       " 'وجود': 457,\n",
       " 'خیز': 458,\n",
       " 'عشاق': 459,\n",
       " 'والله': 460,\n",
       " 'غبار': 461,\n",
       " 'خرقه': 462,\n",
       " 'جاء': 463,\n",
       " 'راز': 464,\n",
       " 'شناس': 465,\n",
       " 'حیران': 466,\n",
       " 'دعا': 467,\n",
       " 'ولیکن': 468,\n",
       " 'دکان': 469,\n",
       " 'غزل': 470,\n",
       " 'فردا': 471,\n",
       " 'فضل': 472,\n",
       " 'منکر': 473,\n",
       " 'تشنه': 474,\n",
       " 'نقل': 475,\n",
       " 'صف': 476,\n",
       " 'شکاف': 477,\n",
       " 'دود': 478,\n",
       " 'بقا': 479,\n",
       " 'پوست': 480,\n",
       " 'بشر': 481,\n",
       " 'سخت': 482,\n",
       " 'منی': 483,\n",
       " 'مثال': 484,\n",
       " 'صاحب': 485,\n",
       " 'هستی': 486,\n",
       " 'چراغ': 487,\n",
       " 'طمع': 488,\n",
       " 'پدر': 489,\n",
       " 'کژ': 490,\n",
       " 'میدان': 491,\n",
       " 'عیار': 492,\n",
       " 'وار': 493,\n",
       " 'مهمان': 494,\n",
       " 'زخمه': 495,\n",
       " 'علم': 496,\n",
       " 'دروغ': 497,\n",
       " 'ساعت': 498,\n",
       " 'محرم': 499,\n",
       " 'شرح': 500,\n",
       " 'تیز': 501,\n",
       " 'دمشق': 502,\n",
       " 'سود': 503,\n",
       " 'درآمد': 504,\n",
       " 'شمار': 505,\n",
       " 'انت': 506,\n",
       " 'لطیف': 507,\n",
       " 'سلیمان': 508,\n",
       " 'حکم': 509,\n",
       " 'ببر': 510,\n",
       " 'تاب': 511,\n",
       " 'حلوا': 512,\n",
       " 'بگفتم': 513,\n",
       " 'رخسار': 514,\n",
       " 'شیشه': 515,\n",
       " 'طالب': 516,\n",
       " 'اثر': 517,\n",
       " 'می\\u200cدار': 518,\n",
       " 'دامن': 519,\n",
       " 'گرفتار': 520,\n",
       " 'مباش': 521,\n",
       " 'معشوق': 522,\n",
       " 'بزم': 523,\n",
       " 'مکر': 524,\n",
       " 'تلخ': 525,\n",
       " 'مدار': 526,\n",
       " 'شکم': 527,\n",
       " 'آغاز': 528,\n",
       " 'دنگ': 529,\n",
       " 'جهانی': 530,\n",
       " 'بگفت': 531,\n",
       " 'قاف': 532,\n",
       " 'رهیدیم': 533,\n",
       " 'چشمه': 534,\n",
       " 'ظلمت': 535,\n",
       " 'نار': 536,\n",
       " 'قبا': 537,\n",
       " 'خرابات': 538,\n",
       " 'جسم': 539,\n",
       " 'حیوان': 540,\n",
       " 'خشم': 541,\n",
       " 'تیره': 542,\n",
       " 'بادا': 543,\n",
       " 'حسد': 544,\n",
       " 'دارو': 545,\n",
       " 'رگ': 546,\n",
       " 'آزاد': 547,\n",
       " 'باری': 548,\n",
       " 'گران': 549,\n",
       " 'نبات': 550,\n",
       " 'تست': 551,\n",
       " 'سقا': 552,\n",
       " 'گردی': 553,\n",
       " 'سیه': 554,\n",
       " 'کاسه': 555,\n",
       " 'حیله': 556,\n",
       " 'باید': 557,\n",
       " 'جفت': 558,\n",
       " 'زو': 559,\n",
       " 'عسل': 560,\n",
       " 'مرو': 561,\n",
       " 'دیدار': 562,\n",
       " 'نرگس': 563,\n",
       " 'دوار': 564,\n",
       " 'مار': 565,\n",
       " 'وفا': 566,\n",
       " 'ماست': 567,\n",
       " 'لاف': 568,\n",
       " 'شدست': 569,\n",
       " 'چار': 570,\n",
       " 'لقمه': 571,\n",
       " 'روزه': 572,\n",
       " 'دزد': 573,\n",
       " 'گردان': 574,\n",
       " 'لیل': 575,\n",
       " 'خمر': 576,\n",
       " 'قدم': 577,\n",
       " 'گمان': 578,\n",
       " 'رنجور': 579,\n",
       " 'سال': 580,\n",
       " 'خراباتم': 581,\n",
       " 'سبز': 582,\n",
       " 'عید': 583,\n",
       " 'گریز': 584,\n",
       " 'عشرت': 585,\n",
       " 'سعادت': 586,\n",
       " 'اجل': 587,\n",
       " 'فرمان': 588,\n",
       " 'سوار': 589,\n",
       " 'سجود': 590,\n",
       " 'حبس': 591,\n",
       " 'مزن': 592,\n",
       " 'مژده': 593,\n",
       " 'عین': 594,\n",
       " 'زنجیر': 595,\n",
       " 'نم': 596,\n",
       " 'برق': 597,\n",
       " 'خویشتن': 598,\n",
       " 'زندان': 599,\n",
       " 'اختر': 600,\n",
       " 'بردار': 601,\n",
       " 'محو': 602,\n",
       " 'تابش': 603,\n",
       " 'قدر': 604,\n",
       " 'وانگه': 605,\n",
       " 'نقد': 606,\n",
       " 'تماشا': 607,\n",
       " 'غصه': 608,\n",
       " 'اشتر': 609,\n",
       " 'نثار': 610,\n",
       " 'پز': 611,\n",
       " 'سوسن': 612,\n",
       " 'بیخود': 613,\n",
       " 'کهنه': 614,\n",
       " 'قند': 615,\n",
       " 'افسون': 616,\n",
       " 'حد': 617,\n",
       " 'فن': 618,\n",
       " 'آیینه': 619,\n",
       " 'کمان': 620,\n",
       " 'خنده': 621,\n",
       " 'بدر': 622,\n",
       " 'انداز': 623,\n",
       " 'برهان': 624,\n",
       " 'مکش': 625,\n",
       " 'چاره': 626,\n",
       " 'عاقبت': 627,\n",
       " 'اهل': 628,\n",
       " 'پریشان': 629,\n",
       " 'علی': 630,\n",
       " 'حور': 631,\n",
       " 'ایا': 632,\n",
       " 'خیر': 633,\n",
       " 'مده': 634,\n",
       " 'لیکن': 635,\n",
       " 'شهره': 636,\n",
       " 'بصر': 637,\n",
       " 'زنی': 638,\n",
       " 'صدف': 639,\n",
       " 'مال': 640,\n",
       " 'لشکر': 641,\n",
       " 'لاغر': 642,\n",
       " 'لذت': 643,\n",
       " 'طفل': 644,\n",
       " 'اله': 645,\n",
       " 'خلیل': 646,\n",
       " 'کله': 647,\n",
       " 'عشوه': 648,\n",
       " 'برآمد': 649,\n",
       " 'غمزه': 650,\n",
       " 'ندا': 651,\n",
       " 'ببینی': 652,\n",
       " 'روا': 653,\n",
       " 'جنت': 654,\n",
       " 'حدیث': 655,\n",
       " 'صوف': 656,\n",
       " 'اختیار': 657,\n",
       " 'خضر': 658,\n",
       " 'الفرار': 659,\n",
       " 'روزن': 660,\n",
       " 'زهره': 661,\n",
       " 'رسول': 662,\n",
       " 'کوزه': 663,\n",
       " 'موم': 664,\n",
       " 'فانی': 665,\n",
       " 'بیخ': 666,\n",
       " 'تک': 667,\n",
       " 'بگریزم': 668,\n",
       " 'شام': 669,\n",
       " 'قال': 670,\n",
       " 'کعبه': 671,\n",
       " 'بجستم': 672,\n",
       " 'سیل': 673,\n",
       " 'صحرا': 674,\n",
       " 'کون': 675,\n",
       " 'جانان': 676,\n",
       " 'بهل': 677,\n",
       " 'قصه': 678,\n",
       " 'فدا': 679,\n",
       " 'اشارت': 680,\n",
       " 'پاره': 681,\n",
       " 'معنی': 682,\n",
       " 'العشق': 683,\n",
       " 'دندان': 684,\n",
       " 'نهد': 685,\n",
       " 'غوغا': 686,\n",
       " 'پیدا': 687,\n",
       " 'عیان': 688,\n",
       " 'خواهی_که': 689,\n",
       " 'مشتاق': 690,\n",
       " 'طره': 691,\n",
       " 'کشته': 692,\n",
       " 'نهاده': 693,\n",
       " 'پخته': 694,\n",
       " 'اقرار': 695,\n",
       " 'دشمن': 696,\n",
       " 'گرو': 697,\n",
       " 'جنون': 698,\n",
       " 'بهتر': 699,\n",
       " 'صحت': 700,\n",
       " 'مفخر': 701,\n",
       " 'سرنا': 702,\n",
       " 'نشسته': 703,\n",
       " 'نوا': 704,\n",
       " 'قبله': 705,\n",
       " 'قضا': 706,\n",
       " 'سرخ': 707,\n",
       " 'مردی': 708,\n",
       " 'عشقست': 709,\n",
       " 'عکس': 710,\n",
       " 'صلا': 711,\n",
       " 'کشان': 712,\n",
       " 'جواب': 713,\n",
       " 'آمیزش': 714,\n",
       " 'سیاه': 715,\n",
       " 'کشدش': 716,\n",
       " 'دف': 717,\n",
       " 'جوییدش': 718,\n",
       " 'زده': 719,\n",
       " 'نمود': 720,\n",
       " 'میل': 721,\n",
       " 'دماغ': 722,\n",
       " 'ناگه': 723,\n",
       " 'حلال': 724,\n",
       " 'مسلمان': 725,\n",
       " 'دهل': 726,\n",
       " 'قالب': 727,\n",
       " 'انگور': 728,\n",
       " 'لیس': 729,\n",
       " 'نوبت': 730,\n",
       " 'هو': 731,\n",
       " 'شیخ': 732,\n",
       " 'لک': 733,\n",
       " 'درده': 734,\n",
       " 'ورا': 735,\n",
       " 'هجران': 736,\n",
       " 'شجر': 737,\n",
       " 'دیگ': 738,\n",
       " 'نیشکر': 739,\n",
       " 'ویران': 740,\n",
       " 'مادر': 741,\n",
       " 'نهی': 742,\n",
       " 'گاو': 743,\n",
       " 'بتر': 744,\n",
       " 'خزان': 745,\n",
       " 'فرعون': 746,\n",
       " 'فربه': 747,\n",
       " 'انکار': 748,\n",
       " 'برف': 749,\n",
       " 'غیرت': 750,\n",
       " 'اغیار': 751,\n",
       " 'خسرو': 752,\n",
       " 'پذیر': 753,\n",
       " 'نقطه': 754,\n",
       " 'پرگار': 755,\n",
       " 'جفا': 756,\n",
       " 'مگذار': 757,\n",
       " 'شهد': 758,\n",
       " 'امر': 759,\n",
       " 'مردار': 760,\n",
       " 'فغان': 761,\n",
       " 'دراز': 762,\n",
       " 'کوثر': 763,\n",
       " 'غریب': 764,\n",
       " 'سری': 765,\n",
       " 'قطار': 766,\n",
       " 'لایق': 767,\n",
       " 'پیچ': 768,\n",
       " 'دلا': 769,\n",
       " 'ذا': 770,\n",
       " 'ترشی': 771,\n",
       " 'اسیر': 772,\n",
       " 'گشاد': 773,\n",
       " 'رستم': 774,\n",
       " 'مقام': 775,\n",
       " 'بیم': 776,\n",
       " 'میاموز': 777,\n",
       " 'مات': 778,\n",
       " 'پند': 779,\n",
       " 'بدیدم': 780,\n",
       " 'فریاد': 781,\n",
       " 'میوه': 782,\n",
       " 'ببرد': 783,\n",
       " 'قطره': 784,\n",
       " 'جوان': 785,\n",
       " 'صور': 786,\n",
       " 'نعم': 787,\n",
       " 'پاینده': 788,\n",
       " 'تاج': 789,\n",
       " 'انا': 790,\n",
       " 'صبا': 791,\n",
       " 'حضرت': 792,\n",
       " 'هنر': 793,\n",
       " 'ابرو': 794,\n",
       " 'لقا': 795,\n",
       " 'ستاره': 796,\n",
       " 'زیبا': 797,\n",
       " 'دنیا': 798,\n",
       " 'جوال': 799,\n",
       " 'هلا': 800,\n",
       " 'خنجر': 801,\n",
       " 'قربان': 802,\n",
       " 'حالت': 803,\n",
       " 'نوری': 804,\n",
       " 'حمل': 805,\n",
       " 'سبک': 806,\n",
       " 'نکته': 807,\n",
       " 'خط': 808,\n",
       " 'عنبر': 809,\n",
       " 'وعده': 810,\n",
       " 'دیدن': 811,\n",
       " 'عطا': 812,\n",
       " 'ریگ': 813,\n",
       " 'وهم': 814,\n",
       " 'شیوه': 815,\n",
       " 'یعقوب': 816,\n",
       " 'وطن': 817,\n",
       " 'شرر': 818,\n",
       " 'حذر': 819,\n",
       " 'هش': 820,\n",
       " 'انبار': 821,\n",
       " 'جور': 822,\n",
       " 'چاکر': 823,\n",
       " 'آثار': 824,\n",
       " 'چوگان': 825,\n",
       " 'بن': 826,\n",
       " 'هنگام': 827,\n",
       " 'خال': 828,\n",
       " 'طبع': 829,\n",
       " 'آهو': 830,\n",
       " 'بتان': 831,\n",
       " 'سالار': 832,\n",
       " 'مصطفی': 833,\n",
       " 'مبین': 834,\n",
       " 'برادر': 835,\n",
       " 'مرید': 836,\n",
       " 'می\\u200cو': 837,\n",
       " 'درویش': 838,\n",
       " 'عدل': 839,\n",
       " 'کیمیا': 840,\n",
       " 'لنگ': 841,\n",
       " 'بهشت': 842,\n",
       " 'وای': 843,\n",
       " 'ازل': 844,\n",
       " 'مصر': 845,\n",
       " 'عهد': 846,\n",
       " 'سبزه': 847,\n",
       " 'شکست': 848,\n",
       " 'خلوت': 849,\n",
       " 'سرکه': 850,\n",
       " 'شیره': 851,\n",
       " 'قامت': 852,\n",
       " 'مسکین': 853,\n",
       " 'فعل': 854,\n",
       " 'احسان': 855,\n",
       " 'میزان': 856,\n",
       " 'پیشه': 857,\n",
       " 'سخره': 858,\n",
       " 'طریق': 859,\n",
       " 'صفت': 860,\n",
       " 'لاله': 861,\n",
       " 'دربان': 862,\n",
       " 'برآرد': 863,\n",
       " 'بری': 864,\n",
       " 'قلب': 865,\n",
       " 'صدر': 866,\n",
       " 'عام': 867,\n",
       " 'درآید': 868,\n",
       " 'مرکب': 869,\n",
       " 'خاص': 870,\n",
       " 'هی': 871,\n",
       " 'منست': 872,\n",
       " 'نهاد': 873,\n",
       " 'قوت': 874,\n",
       " 'پنهانک': 875,\n",
       " 'الرحیل': 876,\n",
       " 'سرگشته': 877,\n",
       " 'رسن': 878,\n",
       " 'پرتو': 879,\n",
       " 'نسیم': 880,\n",
       " 'زیان': 881,\n",
       " 'منت': 882,\n",
       " 'حرم': 883,\n",
       " 'مستانه': 884,\n",
       " 'بوسه': 885,\n",
       " 'عرش': 886,\n",
       " 'مغز': 887,\n",
       " 'الی': 888,\n",
       " 'ربنا': 889,\n",
       " 'قیامت': 890,\n",
       " 'آنی': 891,\n",
       " 'شمر': 892,\n",
       " 'نوح': 893,\n",
       " 'قلم': 894,\n",
       " 'بدید': 895,\n",
       " 'رطل': 896,\n",
       " 'شربت': 897,\n",
       " 'زاری': 898,\n",
       " 'دغل': 899,\n",
       " 'برج': 900,\n",
       " 'مونس': 901,\n",
       " 'پار': 902,\n",
       " 'پهلوی': 903,\n",
       " 'برآورد': 904,\n",
       " 'کباب': 905,\n",
       " 'دیار': 906,\n",
       " 'زرین': 907,\n",
       " 'ساقیا': 908,\n",
       " 'وام': 909,\n",
       " 'جم': 910,\n",
       " 'انوار': 911,\n",
       " 'فرست': 912,\n",
       " 'گشتی': 913,\n",
       " 'نزدیک': 914,\n",
       " 'لوح': 915,\n",
       " 'تخته': 916,\n",
       " 'پدید': 917,\n",
       " 'برآید': 918,\n",
       " 'صادق': 919,\n",
       " 'قرص': 920,\n",
       " 'منزل': 921,\n",
       " 'فقر': 922,\n",
       " 'گوشه': 923,\n",
       " 'کاهل': 924,\n",
       " 'سپار': 925,\n",
       " 'شرمسار': 926,\n",
       " 'قفص': 927,\n",
       " 'بلند': 928,\n",
       " 'نبرد': 929,\n",
       " 'همچنین': 930,\n",
       " 'پروانه': 931,\n",
       " 'بشد': 932,\n",
       " 'شعاع': 933,\n",
       " 'نطق': 934,\n",
       " 'کمال': 935,\n",
       " 'بدی': 936,\n",
       " 'نادر': 937,\n",
       " 'شکرستان': 938,\n",
       " 'خنک': 939,\n",
       " 'سوخته': 940,\n",
       " 'اطلس': 941,\n",
       " 'گفتمش': 942,\n",
       " 'جهت': 943,\n",
       " 'پران': 944,\n",
       " 'فروش': 945,\n",
       " 'هندو': 946,\n",
       " 'سست': 947,\n",
       " 'معدن': 948,\n",
       " 'رسدش': 949,\n",
       " 'بیابان': 950,\n",
       " 'هاش': 951,\n",
       " 'فرق': 952,\n",
       " 'امید': 953,\n",
       " 'بگیرمش': 954,\n",
       " 'می\\u200cرسدش': 955,\n",
       " 'دوا': 956,\n",
       " 'عربده': 957,\n",
       " 'جانا': 958,\n",
       " 'آر': 959,\n",
       " 'سبو': 960,\n",
       " 'ضمیر': 961,\n",
       " 'گنبد': 962,\n",
       " 'پیاپی': 963,\n",
       " 'زاده': 964,\n",
       " 'زال': 965,\n",
       " 'بدیدی': 966,\n",
       " 'حبیب': 967,\n",
       " 'پیغام': 968,\n",
       " 'افزون': 969,\n",
       " 'قهر': 970,\n",
       " 'درمان': 971,\n",
       " 'طوطی': 972,\n",
       " 'امان': 973,\n",
       " 'پیمانه': 974,\n",
       " 'حشر': 975,\n",
       " 'قافله': 976,\n",
       " 'برده': 977,\n",
       " 'برجه': 978,\n",
       " 'منبر': 979,\n",
       " 'شحنه': 980,\n",
       " 'رقصان': 981,\n",
       " 'شرف': 982,\n",
       " 'تخم': 983,\n",
       " 'غرق': 984,\n",
       " 'مایه': 985,\n",
       " 'نکو': 986,\n",
       " 'نزد': 987,\n",
       " 'عارف': 988,\n",
       " 'فکنده': 989,\n",
       " 'حوض': 990,\n",
       " 'مستور': 991,\n",
       " 'دگربار': 992,\n",
       " 'ایثار': 993,\n",
       " 'اکبر': 994,\n",
       " 'هاست': 995,\n",
       " 'طرار': 996,\n",
       " 'نماز': 997,\n",
       " 'غمخوار': 998,\n",
       " 'شهریار': 999,\n",
       " 'دوز': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fa8e462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182450"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a42abd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  11,   82, 1373, ..., 2598, 1895,  459])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "164e4218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(X)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "one_hotter = onehot_encoder.fit(integer_encoded)\n",
    "X_onehot_encoded = one_hotter.transform(integer_encoded)\n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "y_onehot_encoded = one_hotter.transform(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b91b3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"one_hot_encoder.pkl\", \"wb\") as f: \n",
    "    pickle.dump(one_hotter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aee8f592",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182450, 8368)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1b7d019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182450, 8368)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_onehot_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b92ea9c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145960,)\n",
      "(145960,)\n",
      "(36490,)\n",
      "(36490,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=50\n",
    ")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0463937a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1373, 1373,   11, ...,  459, 2598, 2598])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "050b3f5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 50)             418400    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8368)              426768    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 845,168\n",
      "Trainable params: 845,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 01:08:45.964470: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-15 01:08:45.964497: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Emoji-U): /proc/driver/nvidia/version does not exist\n",
      "2022-05-15 01:08:45.964714: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Reshape, Embedding\n",
    "\n",
    "embed_size = 50\n",
    "vocab_size = X_onehot_encoded.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embed_size,\n",
    "        embeddings_initializer=\"glorot_uniform\",\n",
    "        input_length=1,\n",
    "    )\n",
    ")\n",
    "model.add(Reshape((embed_size,)))\n",
    "model.add(Dense(vocab_size, kernel_initializer=\"glorot_uniform\", activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\", metrics=['mae', 'acc'])\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a85c7fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182450,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36d59bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-15 01:08:51.371346: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4885573120 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1141/1141 [==============================] - 23s 20ms/step - loss: 8.2539 - mae: 2.3881e-04 - acc: 0.0162 - val_loss: 8.0226 - val_mae: 2.3866e-04 - val_acc: 0.0147\n",
      "Epoch 2/20\n",
      "1141/1141 [==============================] - 22s 19ms/step - loss: 7.7416 - mae: 2.3860e-04 - acc: 0.0166 - val_loss: 8.0091 - val_mae: 2.3861e-04 - val_acc: 0.0153\n",
      "Epoch 3/20\n",
      "1141/1141 [==============================] - 22s 19ms/step - loss: 7.6830 - mae: 2.3854e-04 - acc: 0.0174 - val_loss: 8.0057 - val_mae: 2.3859e-04 - val_acc: 0.0159\n",
      "Epoch 4/20\n",
      "1141/1141 [==============================] - 22s 19ms/step - loss: 7.6581 - mae: 2.3850e-04 - acc: 0.0189 - val_loss: 8.0157 - val_mae: 2.3857e-04 - val_acc: 0.0164\n",
      "Epoch 5/20\n",
      "1141/1141 [==============================] - 22s 19ms/step - loss: 7.6329 - mae: 2.3845e-04 - acc: 0.0197 - val_loss: 8.0412 - val_mae: 2.3855e-04 - val_acc: 0.0165\n",
      "Epoch 6/20\n",
      "1141/1141 [==============================] - 23s 20ms/step - loss: 7.6049 - mae: 2.3841e-04 - acc: 0.0215 - val_loss: 8.0765 - val_mae: 2.3853e-04 - val_acc: 0.0178\n",
      "Epoch 7/20\n",
      "1141/1141 [==============================] - 20s 18ms/step - loss: 7.5823 - mae: 2.3837e-04 - acc: 0.0227 - val_loss: 8.1299 - val_mae: 2.3851e-04 - val_acc: 0.0180\n",
      "Epoch 8/20\n",
      "1141/1141 [==============================] - 21s 18ms/step - loss: 7.5758 - mae: 2.3832e-04 - acc: 0.0240 - val_loss: 8.1950 - val_mae: 2.3844e-04 - val_acc: 0.0199\n",
      "Epoch 9/20\n",
      "1141/1141 [==============================] - 23s 20ms/step - loss: 7.5876 - mae: 2.3824e-04 - acc: 0.0260 - val_loss: 8.2706 - val_mae: 2.3838e-04 - val_acc: 0.0208\n",
      "Epoch 10/20\n",
      "1141/1141 [==============================] - 23s 20ms/step - loss: 7.6203 - mae: 2.3813e-04 - acc: 0.0273 - val_loss: 8.3673 - val_mae: 2.3827e-04 - val_acc: 0.0212\n",
      "Epoch 11/20\n",
      "1141/1141 [==============================] - 23s 20ms/step - loss: 7.6653 - mae: 2.3802e-04 - acc: 0.0284 - val_loss: 8.4780 - val_mae: 2.3819e-04 - val_acc: 0.0226\n",
      "Epoch 12/20\n",
      "1141/1141 [==============================] - 23s 20ms/step - loss: 7.7077 - mae: 2.3793e-04 - acc: 0.0300 - val_loss: 8.5847 - val_mae: 2.3816e-04 - val_acc: 0.0232\n",
      "Epoch 13/20\n",
      "1141/1141 [==============================] - 23s 20ms/step - loss: 7.7340 - mae: 2.3789e-04 - acc: 0.0312 - val_loss: 8.6710 - val_mae: 2.3815e-04 - val_acc: 0.0240\n",
      "Epoch 14/20\n",
      "1141/1141 [==============================] - 22s 19ms/step - loss: 7.7546 - mae: 2.3786e-04 - acc: 0.0328 - val_loss: 8.7331 - val_mae: 2.3816e-04 - val_acc: 0.0243\n",
      "Epoch 15/20\n",
      "1141/1141 [==============================] - 24s 21ms/step - loss: 7.7761 - mae: 2.3784e-04 - acc: 0.0341 - val_loss: 8.7797 - val_mae: 2.3816e-04 - val_acc: 0.0221\n",
      "Epoch 16/20\n",
      "1141/1141 [==============================] - 23s 20ms/step - loss: 7.7966 - mae: 2.3782e-04 - acc: 0.0351 - val_loss: 8.8217 - val_mae: 2.3818e-04 - val_acc: 0.0243\n",
      "Epoch 17/20\n",
      "1141/1141 [==============================] - 24s 21ms/step - loss: 7.8167 - mae: 2.3780e-04 - acc: 0.0363 - val_loss: 8.8602 - val_mae: 2.3817e-04 - val_acc: 0.0224\n",
      "Epoch 18/20\n",
      "1141/1141 [==============================] - 24s 21ms/step - loss: 7.8362 - mae: 2.3778e-04 - acc: 0.0372 - val_loss: 8.8917 - val_mae: 2.3817e-04 - val_acc: 0.0226\n",
      "Epoch 19/20\n",
      "1141/1141 [==============================] - 22s 19ms/step - loss: 7.8517 - mae: 2.3775e-04 - acc: 0.0380 - val_loss: 8.9165 - val_mae: 2.3816e-04 - val_acc: 0.0224\n",
      "Epoch 20/20\n",
      "1141/1141 [==============================] - 24s 21ms/step - loss: 7.8645 - mae: 2.3773e-04 - acc: 0.0389 - val_loss: 8.9391 - val_mae: 2.3816e-04 - val_acc: 0.0240\n"
     ]
    }
   ],
   "source": [
    "models = model.fit(\n",
    "    X, y_onehot_encoded, epochs=20, validation_split=0.2, batch_size=128, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "894eb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_similar(word, model_, n=10):\n",
    "    word_id = word_to_id[word]\n",
    "    result = model_.predict([word_id]).squeeze()\n",
    "    for word in (id_to_word[id + 1] for id in np.argsort(result)[::-1][0:n]):\n",
    "        print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62503ed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "باد\n",
      "سر\n",
      "جان\n",
      "خاک\n",
      "دل\n",
      "کش\n",
      "دم\n",
      "عشق\n",
      "لطف\n",
      "خوش\n"
     ]
    }
   ],
   "source": [
    "n_similar('باغ', model_ = model, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a55b4199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02277675, 0.02288023, 0.01977304, ..., 0.00000015, 0.00000015,\n",
       "       0.00000015], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([5]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2842b2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tokens_ = lammatized_tokens[:2000]\n",
    "# t = Tokenizer(filters='')\n",
    "# t.fit_on_texts(tokens_)\n",
    "# sorted_count_list = sorted(t.word_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "# word_to_id, id_to_word = t.word_index, t.index_word\n",
    "# len(word_to_id)\n",
    "# X, y = generate_training_data(tokens_, word_to_id, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "838f9116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "410e9082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9d44b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31c00412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bfb06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network(vocab_size, n_embedding):\n",
    "    model = {\n",
    "        \"w1\": np.random.uniform(-1, 1, (vocab_size, n_embedding)),\n",
    "        \"w2\": np.random.uniform(-1, 1, (n_embedding, vocab_size))\n",
    "    }\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae19f5e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8368, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = init_network(len(word_to_id), 10)\n",
    "model[\"w1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ae306c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1171)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"w2\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "071c7c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "#     return e_x / e_x.sum(axis=0)\n",
    "\n",
    "    res = []\n",
    "    for x in X:\n",
    "        exp = np.exp(x)\n",
    "        res.append(exp / exp.sum())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7dc0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_sigmoid(x):\n",
    "    sig = np.where(x < 0, np.exp(x) / (1 + np.exp(x)), 1 / (1 + np.exp(-x)))\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65b4aae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11988, 1171)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f78c4529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11988, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X @ model[\"w1\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4aa8b522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11988, 1171)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X @ model[\"w1\"] @ model[\"w2\"]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0af7bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model, X, return_cache=True):\n",
    "    cache = {}\n",
    "    \n",
    "    cache[\"a1\"] = X @ model[\"w1\"]\n",
    "    cache[\"a2\"] = cache[\"a1\"] @ model[\"w2\"]\n",
    "    print(f\"a2 = {cache['a2']}\")\n",
    "    cache[\"z\"] = softmax(cache[\"a2\"])\n",
    "#     cache[\"z\"] = stable_sigmoid(cache[\"a2\"])\n",
    "    \n",
    "    if not return_cache:\n",
    "        return cache[\"z\"]\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "283a2af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(z, y):\n",
    "    return - np.sum(np.log(z) * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3259e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(model, X, y, alpha):\n",
    "    cache  = forward(model, X)\n",
    "#     dl_weight_inp_hidden = np.outer(target_word_vector, np.dot(weight_hidden_output, total_error.T))\n",
    "#     dl_weight_hidden_output = np.outer(hidden_layer, total_error)\n",
    "    da2 = cache[\"z\"] - y\n",
    "    dw2 = cache[\"a1\"].T @ da2\n",
    "    da1 = da2 @ model[\"w2\"].T\n",
    "    dw1 = X.T @ da1\n",
    "    assert(dw2.shape == model[\"w2\"].shape)\n",
    "    assert(dw1.shape == model[\"w1\"].shape)\n",
    "    model[\"w1\"] -= alpha * dw1\n",
    "    model[\"w2\"] -= alpha * dw2\n",
    "    \n",
    "    return cross_entropy(cache[\"z\"], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db05a107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = [[-2.74132539 -1.27900225 -1.80771619 ...  0.27653819  2.18316733\n",
      "   0.356036  ]\n",
      " [-2.74132539 -1.27900225 -1.80771619 ...  0.27653819  2.18316733\n",
      "   0.356036  ]\n",
      " [-2.74132539 -1.27900225 -1.80771619 ...  0.27653819  2.18316733\n",
      "   0.356036  ]\n",
      " ...\n",
      " [-0.86869516 -1.01409124 -1.90894888 ... -0.25463134  1.92658359\n",
      "   0.3085458 ]\n",
      " [-0.86869516 -1.01409124 -1.90894888 ... -0.25463134  1.92658359\n",
      "   0.3085458 ]\n",
      " [-0.86869516 -1.01409124 -1.90894888 ... -0.25463134  1.92658359\n",
      "   0.3085458 ]]\n",
      "a2 = [[-2.30536967 -1.2409838  -1.34889173 ...  0.30970255  2.12515847\n",
      "   0.32588619]\n",
      " [-2.30536967 -1.2409838  -1.34889173 ...  0.30970255  2.12515847\n",
      "   0.32588619]\n",
      " [-2.30536967 -1.2409838  -1.34889173 ...  0.30970255  2.12515847\n",
      "   0.32588619]\n",
      " ...\n",
      " [-0.67576492 -0.99458788 -1.69838724 ... -0.19292213  1.91841591\n",
      "   0.33170993]\n",
      " [-0.67576492 -0.99458788 -1.69838724 ... -0.19292213  1.91841591\n",
      "   0.33170993]\n",
      " [-0.67576492 -0.99458788 -1.69838724 ... -0.19292213  1.91841591\n",
      "   0.33170993]]\n",
      "a2 = [[-2.60561483 -1.58791375 -0.9940371  ...  0.34341315  2.07918233\n",
      "   0.30108846]\n",
      " [-2.60561483 -1.58791375 -0.9940371  ...  0.34341315  2.07918233\n",
      "   0.30108846]\n",
      " [-2.60561483 -1.58791375 -0.9940371  ...  0.34341315  2.07918233\n",
      "   0.30108846]\n",
      " ...\n",
      " [-0.91343399 -1.21449067 -1.53885513 ... -0.13284465  1.91826687\n",
      "   0.35724274]\n",
      " [-0.91343399 -1.21449067 -1.53885513 ... -0.13284465  1.91826687\n",
      "   0.35724274]\n",
      " [-0.91343399 -1.21449067 -1.53885513 ... -0.13284465  1.91826687\n",
      "   0.35724274]]\n",
      "a2 = [[-3.1239749  -2.04057303 -0.69829121 ...  0.37750607  2.04106249\n",
      "   0.28033747]\n",
      " [-3.1239749  -2.04057303 -0.69829121 ...  0.37750607  2.04106249\n",
      "   0.28033747]\n",
      " [-3.1239749  -2.04057303 -0.69829121 ...  0.37750607  2.04106249\n",
      "   0.28033747]\n",
      " ...\n",
      " [-1.27714974 -1.50629349 -1.40608168 ... -0.0739372   1.92363206\n",
      "   0.38456129]\n",
      " [-1.27714974 -1.50629349 -1.40608168 ... -0.0739372   1.92363206\n",
      "   0.38456129]\n",
      " [-1.27714974 -1.50629349 -1.40608168 ... -0.0739372   1.92363206\n",
      "   0.38456129]]\n",
      "a2 = [[-3.77247114 -2.56523105 -0.44783564 ...  0.41178571  2.00930754\n",
      "   0.26296845]\n",
      " [-3.77247114 -2.56523105 -0.44783564 ...  0.41178571  2.00930754\n",
      "   0.26296845]\n",
      " [-3.77247114 -2.56523105 -0.44783564 ...  0.41178571  2.00930754\n",
      "   0.26296845]\n",
      " ...\n",
      " [-1.72925676 -1.85458775 -1.29342357 ... -0.0158323   1.93367764\n",
      "   0.41352078]\n",
      " [-1.72925676 -1.85458775 -1.29342357 ... -0.0158323   1.93367764\n",
      "   0.41352078]\n",
      " [-1.72925676 -1.85458775 -1.29342357 ... -0.0158323   1.93367764\n",
      "   0.41352078]]\n",
      "a2 = [[-4.52953149 -3.16926167 -0.23591575 ...  0.4465382   1.98334538\n",
      "   0.24901587]\n",
      " [-4.52953149 -3.16926167 -0.23591575 ...  0.4465382   1.98334538\n",
      "   0.24901587]\n",
      " [-4.52953149 -3.16926167 -0.23591575 ...  0.4465382   1.98334538\n",
      "   0.24901587]\n",
      " ...\n",
      " [-2.26659324 -2.26626712 -1.1974069  ...  0.04193245  1.94812832\n",
      "   0.44435805]\n",
      " [-2.26659324 -2.26626712 -1.1974069  ...  0.04193245  1.94812832\n",
      "   0.44435805]\n",
      " [-2.26659324 -2.26626712 -1.1974069  ...  0.04193245  1.94812832\n",
      "   0.44435805]]\n",
      "a2 = [[-5.34646544 -3.85973706 -0.05841862 ...  0.48197833  1.96275256\n",
      "   0.23850707]\n",
      " [-5.34646544 -3.85973706 -0.05841862 ...  0.48197833  1.96275256\n",
      "   0.23850707]\n",
      " [-5.34646544 -3.85973706 -0.05841862 ...  0.48197833  1.96275256\n",
      "   0.23850707]\n",
      " ...\n",
      " [-2.86899782 -2.74797347 -1.11557771 ...  0.09971147  1.96681418\n",
      "   0.47729082]\n",
      " [-2.86899782 -2.74797347 -1.11557771 ...  0.09971147  1.96681418\n",
      "   0.47729082]\n",
      " [-2.86899782 -2.74797347 -1.11557771 ...  0.09971147  1.96681418\n",
      "   0.47729082]]\n",
      "a2 = [[-6.02616889 -4.61653871  0.08789161 ...  0.51812451  1.94698134\n",
      "   0.23121518]\n",
      " [-6.02616889 -4.61653871  0.08789161 ...  0.51812451  1.94698134\n",
      "   0.23121518]\n",
      " [-6.02616889 -4.61653871  0.08789161 ...  0.51812451  1.94698134\n",
      "   0.23121518]\n",
      " ...\n",
      " [-3.42208813 -3.2897     -1.04555572 ...  0.15771191  1.98950899\n",
      "   0.51236617]\n",
      " [-3.42208813 -3.2897     -1.04555572 ...  0.15771191  1.98950899\n",
      "   0.51236617]\n",
      " [-3.42208813 -3.2897     -1.04555572 ...  0.15771191  1.98950899\n",
      "   0.51236617]]\n",
      "a2 = [[-6.32922745 -5.35336833  0.20886969 ...  0.55486815  1.93531041\n",
      "   0.22660191]\n",
      " [-6.32922745 -5.35336833  0.20886969 ...  0.55486815  1.93531041\n",
      "   0.22660191]\n",
      " [-6.32922745 -5.35336833  0.20886969 ...  0.55486815  1.93531041\n",
      "   0.22660191]\n",
      " ...\n",
      " [-3.76941682 -3.83885823 -0.98288303 ...  0.21605097  2.01590056\n",
      "   0.54940948]\n",
      " [-3.76941682 -3.83885823 -0.98288303 ...  0.21605097  2.01590056\n",
      "   0.54940948]\n",
      " [-3.76941682 -3.83885823 -0.98288303 ...  0.21605097  2.01590056\n",
      "   0.54940948]]\n",
      "a2 = [[-6.77628276 -5.98071056  0.31542539 ...  0.59228343  1.92735293\n",
      "   0.2243574 ]\n",
      " [-6.77628276 -5.98071056  0.31542539 ...  0.59228343  1.92735293\n",
      "   0.2243574 ]\n",
      " [-6.77628276 -5.98071056  0.31542539 ...  0.59228343  1.92735293\n",
      "   0.2243574 ]\n",
      " ...\n",
      " [-4.23534819 -4.33527189 -0.9189793  ...  0.2749584   2.04588138\n",
      "   0.58831377]\n",
      " [-4.23534819 -4.33527189 -0.9189793  ...  0.2749584   2.04588138\n",
      "   0.58831377]\n",
      " [-4.23534819 -4.33527189 -0.9189793  ...  0.2749584   2.04588138\n",
      "   0.58831377]]\n",
      "a2 = [[-6.25604148 -6.3100721   0.40522268 ...  0.63001868  1.92257496\n",
      "   0.22418483]\n",
      " [-6.25604148 -6.3100721   0.40522268 ...  0.63001868  1.92257496\n",
      "   0.22418483]\n",
      " [-6.25604148 -6.3100721   0.40522268 ...  0.63001868  1.92257496\n",
      "   0.22418483]\n",
      " ...\n",
      " [-4.01720342 -4.62731488 -0.85234027 ...  0.33425943  2.0790138\n",
      "   0.62879247]\n",
      " [-4.01720342 -4.62731488 -0.85234027 ...  0.33425943  2.0790138\n",
      "   0.62879247]\n",
      " [-4.01720342 -4.62731488 -0.85234027 ...  0.33425943  2.0790138\n",
      "   0.62879247]]\n",
      "a2 = [[-6.88546962 -6.59422753  0.5127113  ...  0.66717511  1.9189064\n",
      "   0.22459043]\n",
      " [-6.88546962 -6.59422753  0.5127113  ...  0.66717511  1.9189064\n",
      "   0.22459043]\n",
      " [-6.88546962 -6.59422753  0.5127113  ...  0.66717511  1.9189064\n",
      "   0.22459043]\n",
      " ...\n",
      " [-4.63448368 -4.90676482 -0.75741172 ...  0.39384076  2.11440346\n",
      "   0.67000662]\n",
      " [-4.63448368 -4.90676482 -0.75741172 ...  0.39384076  2.11440346\n",
      "   0.67000662]\n",
      " [-4.63448368 -4.90676482 -0.75741172 ...  0.39384076  2.11440346\n",
      "   0.67000662]]\n",
      "a2 = [[-4.46697753 -5.76590365  0.59158266 ...  0.705169    1.91913253\n",
      "   0.22724139]\n",
      " [-4.46697753 -5.76590365  0.59158266 ...  0.705169    1.91913253\n",
      "   0.22724139]\n",
      " [-4.46697753 -5.76590365  0.59158266 ...  0.705169    1.91913253\n",
      "   0.22724139]\n",
      " ...\n",
      " [-2.9713895  -4.31668707 -0.66372736 ...  0.45432795  2.15327028\n",
      "   0.71277544]\n",
      " [-2.9713895  -4.31668707 -0.66372736 ...  0.45432795  2.15327028\n",
      "   0.71277544]\n",
      " [-2.9713895  -4.31668707 -0.66372736 ...  0.45432795  2.15327028\n",
      "   0.71277544]]\n",
      "a2 = [[-5.01167601 -5.83370187  0.77263606 ...  0.7278878   1.90347895\n",
      "   0.22177656]\n",
      " [-5.01167601 -5.83370187  0.77263606 ...  0.7278878   1.90347895\n",
      "   0.22177656]\n",
      " [-5.01167601 -5.83370187  0.77263606 ...  0.7278878   1.90347895\n",
      "   0.22177656]\n",
      " ...\n",
      " [-3.51547976 -4.41283894 -0.47580456 ...  0.50509543  2.18223479\n",
      "   0.74947551]\n",
      " [-3.51547976 -4.41283894 -0.47580456 ...  0.50509543  2.18223479\n",
      "   0.74947551]\n",
      " [-3.51547976 -4.41283894 -0.47580456 ...  0.50509543  2.18223479\n",
      "   0.74947551]]\n",
      "a2 = [[-6.27709372 -6.32205234  0.89374716 ...  0.76815961  1.90996621\n",
      "   0.22851339]\n",
      " [-6.27709372 -6.32205234  0.89374716 ...  0.76815961  1.90996621\n",
      "   0.22851339]\n",
      " [-6.27709372 -6.32205234  0.89374716 ...  0.76815961  1.90996621\n",
      "   0.22851339]\n",
      " ...\n",
      " [-4.61774783 -4.81227319 -0.31253473 ...  0.56965655  2.22873817\n",
      "   0.79563857]\n",
      " [-4.61774783 -4.81227319 -0.31253473 ...  0.56965655  2.22873817\n",
      "   0.79563857]\n",
      " [-4.61774783 -4.81227319 -0.31253473 ...  0.56965655  2.22873817\n",
      "   0.79563857]]\n",
      "a2 = [[-3.71857381 -5.20844506  0.99733146 ...  0.80859338  1.91819715\n",
      "   0.23543791]\n",
      " [-3.71857381 -5.20844506  0.99733146 ...  0.80859338  1.91819715\n",
      "   0.23543791]\n",
      " [-3.71857381 -5.20844506  0.99733146 ...  0.80859338  1.91819715\n",
      "   0.23543791]\n",
      " ...\n",
      " [-2.64001804 -3.91095612 -0.14288676 ...  0.63518363  2.27765941\n",
      "   0.8419208 ]\n",
      " [-2.64001804 -3.91095612 -0.14288676 ...  0.63518363  2.27765941\n",
      "   0.8419208 ]\n",
      " [-2.64001804 -3.91095612 -0.14288676 ...  0.63518363  2.27765941\n",
      "   0.8419208 ]]\n",
      "a2 = [[-4.6690617  -5.55594009  1.21318818 ...  0.83453085  1.90883988\n",
      "   0.23194446]\n",
      " [-4.6690617  -5.55594009  1.21318818 ...  0.83453085  1.90883988\n",
      "   0.23194446]\n",
      " [-4.6690617  -5.55594009  1.21318818 ...  0.83453085  1.90883988\n",
      "   0.23194446]\n",
      " ...\n",
      " [-3.52586218 -4.18663508  0.13759702 ...  0.69143927  2.31483159\n",
      "   0.87997696]\n",
      " [-3.52586218 -4.18663508  0.13759702 ...  0.69143927  2.31483159\n",
      "   0.87997696]\n",
      " [-3.52586218 -4.18663508  0.13759702 ...  0.69143927  2.31483159\n",
      "   0.87997696]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = [[-5.9980348  -5.95889827  1.36587994 ...  0.87812623  1.92214075\n",
      "   0.24219688]\n",
      " [-5.9980348  -5.95889827  1.36587994 ...  0.87812623  1.92214075\n",
      "   0.24219688]\n",
      " [-5.9980348  -5.95889827  1.36587994 ...  0.87812623  1.92214075\n",
      "   0.24219688]\n",
      " ...\n",
      " [-4.7517591  -4.49144355  0.38128546 ...  0.76334177  2.37185902\n",
      "   0.92954448]\n",
      " [-4.7517591  -4.49144355  0.38128546 ...  0.76334177  2.37185902\n",
      "   0.92954448]\n",
      " [-4.7517591  -4.49144355  0.38128546 ...  0.76334177  2.37185902\n",
      "   0.92954448]]\n",
      "a2 = [[-1.66831947 -4.46820011  1.49254524 ...  0.92144401  1.93494083\n",
      "   0.25116315]\n",
      " [-1.66831947 -4.46820011  1.49254524 ...  0.92144401  1.93494083\n",
      "   0.25116315]\n",
      " [-1.66831947 -4.46820011  1.49254524 ...  0.92144401  1.93494083\n",
      "   0.25116315]\n",
      " ...\n",
      " [-1.09994208 -3.26007664  0.62125857 ...  0.83668957  2.4304383\n",
      "   0.97857969]\n",
      " [-1.09994208 -3.26007664  0.62125857 ...  0.83668957  2.4304383\n",
      "   0.97857969]\n",
      " [-1.09994208 -3.26007664  0.62125857 ...  0.83668957  2.4304383\n",
      "   0.97857969]]\n",
      "a2 = [[-2.63858533 -4.91116733  1.76224117 ...  0.94630165  1.92337864\n",
      "   0.24516037]\n",
      " [-2.63858533 -4.91116733  1.76224117 ...  0.94630165  1.92337864\n",
      "   0.24516037]\n",
      " [-2.63858533 -4.91116733  1.76224117 ...  0.94630165  1.92337864\n",
      "   0.24516037]\n",
      " ...\n",
      " [-2.06102892 -3.59948732  1.00006637 ...  0.89722018  2.4710046\n",
      "   1.01550654]\n",
      " [-2.06102892 -3.59948732  1.00006637 ...  0.89722018  2.4710046\n",
      "   1.01550654]\n",
      " [-2.06102892 -3.59948732  1.00006637 ...  0.89722018  2.4710046\n",
      "   1.01550654]]\n",
      "a2 = [[-4.45659976 -5.42339884  1.93646135 ...  0.99187362  1.93790879\n",
      "   0.25547333]\n",
      " [-4.45659976 -5.42339884  1.93646135 ...  0.99187362  1.93790879\n",
      "   0.25547333]\n",
      " [-4.45659976 -5.42339884  1.93646135 ...  0.99187362  1.93790879\n",
      "   0.25547333]\n",
      " ...\n",
      " [-3.76984304 -3.96517868  1.30974111 ...  0.97824352  2.53647327\n",
      "   1.06725088]\n",
      " [-3.76984304 -3.96517868  1.30974111 ...  0.97824352  2.53647327\n",
      "   1.06725088]\n",
      " [-3.76984304 -3.96517868  1.30974111 ...  0.97824352  2.53647327\n",
      "   1.06725088]]\n",
      "a2 = [[-5.38454541 -4.05965258  2.08026462 ...  1.04094659  1.95662218\n",
      "   0.26845402]\n",
      " [-5.38454541 -4.05965258  2.08026462 ...  1.04094659  1.95662218\n",
      "   0.26845402]\n",
      " [-5.38454541 -4.05965258  2.08026462 ...  1.04094659  1.95662218\n",
      "   0.26845402]\n",
      " ...\n",
      " [-4.68580802 -2.86882052  1.61079622 ...  1.06476285  2.60806527\n",
      "   1.122229  ]\n",
      " [-4.68580802 -2.86882052  1.61079622 ...  1.06476285  2.60806527\n",
      "   1.122229  ]\n",
      " [-4.68580802 -2.86882052  1.61079622 ...  1.06476285  2.60806527\n",
      "   1.122229  ]]\n",
      "a2 = [[-3.09288531 -5.49226255  2.24930701 ...  1.08737173  1.97094277\n",
      "   0.27882433]\n",
      " [-3.09288531 -5.49226255  2.24930701 ...  1.08737173  1.97094277\n",
      "   0.27882433]\n",
      " [-3.09288531 -5.49226255  2.24930701 ...  1.08737173  1.97094277\n",
      "   0.27882433]\n",
      " ...\n",
      " [-2.48446575 -4.01914487  1.95000712 ...  1.1520555   2.67877477\n",
      "   1.17617492]\n",
      " [-2.48446575 -4.01914487  1.95000712 ...  1.1520555   2.67877477\n",
      "   1.17617492]\n",
      " [-2.48446575 -4.01914487  1.95000712 ...  1.1520555   2.67877477\n",
      "   1.17617492]]\n",
      "a2 = [[-4.86249191 -4.83715669  2.40928525 ...  1.13681892  1.98806973\n",
      "   0.29003492]\n",
      " [-4.86249191 -4.83715669  2.40928525 ...  1.13681892  1.98806973\n",
      "   0.29003492]\n",
      " [-4.86249191 -4.83715669  2.40928525 ...  1.13681892  1.98806973\n",
      "   0.29003492]\n",
      " ...\n",
      " [-4.236763   -3.39197656  2.29309758 ...  1.24609373  2.75517957\n",
      "   1.23221007]\n",
      " [-4.236763   -3.39197656  2.29309758 ...  1.24609373  2.75517957\n",
      "   1.23221007]\n",
      " [-4.236763   -3.39197656  2.29309758 ...  1.24609373  2.75517957\n",
      "   1.23221007]]\n",
      "a2 = [[-4.09613307 -5.25130785  2.542675   ...  1.18912373  2.00828448\n",
      "   0.30353345]\n",
      " [-4.09613307 -5.25130785  2.542675   ...  1.18912373  2.00828448\n",
      "   0.30353345]\n",
      " [-4.09613307 -5.25130785  2.542675   ...  1.18912373  2.00828448\n",
      "   0.30353345]\n",
      " ...\n",
      " [-3.7272045  -3.58085413  2.62549878 ...  1.34618476  2.83709481\n",
      "   1.29135431]\n",
      " [-3.7272045  -3.58085413  2.62549878 ...  1.34618476  2.83709481\n",
      "   1.29135431]\n",
      " [-3.7272045  -3.58085413  2.62549878 ...  1.34618476  2.83709481\n",
      "   1.29135431]]\n",
      "a2 = [[-5.13084913 -5.0787592   2.68818434 ...  1.24159695  2.02774722\n",
      "   0.31645889]\n",
      " [-5.13084913 -5.0787592   2.68818434 ...  1.24159695  2.02774722\n",
      "   0.31645889]\n",
      " [-5.13084913 -5.0787592   2.68818434 ...  1.24159695  2.02774722\n",
      "   0.31645889]\n",
      " ...\n",
      " [-4.81954038 -3.44224554  2.97464689 ...  1.45092462  2.92168748\n",
      "   1.35137759]\n",
      " [-4.81954038 -3.44224554  2.97464689 ...  1.45092462  2.92168748\n",
      "   1.35137759]\n",
      " [-4.81954038 -3.44224554  2.97464689 ...  1.45092462  2.92168748\n",
      "   1.35137759]]\n",
      "a2 = [[ 1.42207292 -4.65193301  2.7806706  ...  1.29438886  2.04662144\n",
      "   0.32829581]\n",
      " [ 1.42207292 -4.65193301  2.7806706  ...  1.29438886  2.04662144\n",
      "   0.32829581]\n",
      " [ 1.42207292 -4.65193301  2.7806706  ...  1.29438886  2.04662144\n",
      "   0.32829581]\n",
      " ...\n",
      " [ 1.70052414 -3.12894922  3.2863738  ...  1.55987302  3.00886837\n",
      "   1.41235078]\n",
      " [ 1.70052414 -3.12894922  3.2863738  ...  1.55987302  3.00886837\n",
      "   1.41235078]\n",
      " [ 1.70052414 -3.12894922  3.2863738  ...  1.55987302  3.00886837\n",
      "   1.41235078]]\n",
      "a2 = [[ 0.48853098 -4.53420971  2.98717648 ...  1.33814353  2.05002271\n",
      "   0.32794817]\n",
      " [ 0.48853098 -4.53420971  2.98717648 ...  1.33814353  2.05002271\n",
      "   0.32794817]\n",
      " [ 0.48853098 -4.53420971  2.98717648 ...  1.33814353  2.05002271\n",
      "   0.32794817]\n",
      " ...\n",
      " [ 0.67236977 -2.84389559  3.70710787 ...  1.66373939  3.08273462\n",
      "   1.4624229 ]\n",
      " [ 0.67236977 -2.84389559  3.70710787 ...  1.66373939  3.08273462\n",
      "   1.4624229 ]\n",
      " [ 0.67236977 -2.84389559  3.70710787 ...  1.66373939  3.08273462\n",
      "   1.4624229 ]]\n",
      "a2 = [[-1.20226392 -4.59525075  3.07445901 ...  1.39036857  2.06342683\n",
      "   0.33693332]\n",
      " [-1.20226392 -4.59525075  3.07445901 ...  1.39036857  2.06342683\n",
      "   0.33693332]\n",
      " [-1.20226392 -4.59525075  3.07445901 ...  1.39036857  2.06342683\n",
      "   0.33693332]\n",
      " ...\n",
      " [-1.05566623 -2.7802741   4.0242541  ...  1.78076672  3.16951179\n",
      "   1.5230743 ]\n",
      " [-1.05566623 -2.7802741   4.0242541  ...  1.78076672  3.16951179\n",
      "   1.5230743 ]\n",
      " [-1.05566623 -2.7802741   4.0242541  ...  1.78076672  3.16951179\n",
      "   1.5230743 ]]\n",
      "a2 = [[-3.17928862 -4.51262233  3.15854788 ...  1.44780506  2.08608346\n",
      "   0.35183118]\n",
      " [-3.17928862 -4.51262233  3.15854788 ...  1.44780506  2.08608346\n",
      "   0.35183118]\n",
      " [-3.17928862 -4.51262233  3.15854788 ...  1.44780506  2.08608346\n",
      "   0.35183118]\n",
      " ...\n",
      " [-3.15367465 -2.74439466  4.34084833 ...  1.90758271  3.26823012\n",
      "   1.59149674]\n",
      " [-3.15367465 -2.74439466  4.34084833 ...  1.90758271  3.26823012\n",
      "   1.59149674]\n",
      " [-3.15367465 -2.74439466  4.34084833 ...  1.90758271  3.26823012\n",
      "   1.59149674]]\n",
      "a2 = [[-4.55271229 -4.90211668  3.22396601 ...  1.50695227  2.11005664\n",
      "   0.36727336]\n",
      " [-4.55271229 -4.90211668  3.22396601 ...  1.50695227  2.11005664\n",
      "   0.36727336]\n",
      " [-4.55271229 -4.90211668  3.22396601 ...  1.50695227  2.11005664\n",
      "   0.36727336]\n",
      " ...\n",
      " [-4.69076366 -2.97063764  4.6369577  ...  2.04041822  3.37080009\n",
      "   1.66212727]\n",
      " [-4.69076366 -2.97063764  4.6369577  ...  2.04041822  3.37080009\n",
      "   1.66212727]\n",
      " [-4.69076366 -2.97063764  4.6369577  ...  2.04041822  3.37080009\n",
      "   1.66212727]]\n",
      "a2 = [[-0.53264167 -2.41538312  3.25725257 ...  1.56487624  2.13161991\n",
      "   0.38047099]\n",
      " [-0.53264167 -2.41538312  3.25725257 ...  1.56487624  2.13161991\n",
      "   0.38047099]\n",
      " [-0.53264167 -2.41538312  3.25725257 ...  1.56487624  2.13161991\n",
      "   0.38047099]\n",
      " ...\n",
      " [-0.42761261 -1.28576242  4.90429531 ...  2.17703665  3.474696\n",
      "   1.73292705]\n",
      " [-0.42761261 -1.28576242  4.90429531 ...  2.17703665  3.474696\n",
      "   1.73292705]\n",
      " [-0.42761261 -1.28576242  4.90429531 ...  2.17703665  3.474696\n",
      "   1.73292705]]\n",
      "a2 = [[-1.52249332 -3.48244196  3.39433624 ...  1.60932955  2.14002749\n",
      "   0.38716066]\n",
      " [-1.52249332 -3.48244196  3.39433624 ...  1.60932955  2.14002749\n",
      "   0.38716066]\n",
      " [-1.52249332 -3.48244196  3.39433624 ...  1.60932955  2.14002749\n",
      "   0.38716066]\n",
      " ...\n",
      " [-1.78476036 -2.00011354  5.23802329 ...  2.30687242  3.5683853\n",
      "   1.79839132]\n",
      " [-1.78476036 -2.00011354  5.23802329 ...  2.30687242  3.5683853\n",
      "   1.79839132]\n",
      " [-1.78476036 -2.00011354  5.23802329 ...  2.30687242  3.5683853\n",
      "   1.79839132]]\n",
      "a2 = [[-3.21587741 -4.72151502  3.47285761 ...  1.66912102  2.16257739\n",
      "   0.40163213]\n",
      " [-3.21587741 -4.72151502  3.47285761 ...  1.66912102  2.16257739\n",
      "   0.40163213]\n",
      " [-3.21587741 -4.72151502  3.47285761 ...  1.66912102  2.16257739\n",
      "   0.40163213]\n",
      " ...\n",
      " [-3.90050882 -2.88609145  5.56869484 ...  2.45368404  3.67611436\n",
      "   1.87265301]\n",
      " [-3.90050882 -2.88609145  5.56869484 ...  2.45368404  3.67611436\n",
      "   1.87265301]\n",
      " [-3.90050882 -2.88609145  5.56869484 ...  2.45368404  3.67611436\n",
      "   1.87265301]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = [[-3.67260638 -1.53700187  3.4852808  ...  1.72973698  2.18606308\n",
      "   0.41579631]\n",
      " [-3.67260638 -1.53700187  3.4852808  ...  1.72973698  2.18606308\n",
      "   0.41579631]\n",
      " [-3.67260638 -1.53700187  3.4852808  ...  1.72973698  2.18606308\n",
      "   0.41579631]\n",
      " ...\n",
      " [-4.40268915 -0.23729693  5.79760099 ...  2.60515046  3.78679666\n",
      "   1.94762952]\n",
      " [-4.40268915 -0.23729693  5.79760099 ...  2.60515046  3.78679666\n",
      "   1.94762952]\n",
      " [-4.40268915 -0.23729693  5.79760099 ...  2.60515046  3.78679666\n",
      "   1.94762952]]\n",
      "a2 = [[-2.3767334  -3.04214528  3.54412939 ...  1.78290792  2.20560842\n",
      "   0.42966066]\n",
      " [-2.3767334  -3.04214528  3.54412939 ...  1.78290792  2.20560842\n",
      "   0.42966066]\n",
      " [-2.3767334  -3.04214528  3.54412939 ...  1.78290792  2.20560842\n",
      "   0.42966066]\n",
      " ...\n",
      " [-3.27130698 -1.42870191  6.01174377 ...  2.75661738  3.89666166\n",
      "   2.02379091]\n",
      " [-3.27130698 -1.42870191  6.01174377 ...  2.75661738  3.89666166\n",
      "   2.02379091]\n",
      " [-3.27130698 -1.42870191  6.01174377 ...  2.75661738  3.89666166\n",
      "   2.02379091]]\n",
      "a2 = [[-3.29458551 -4.7033014   3.57406752 ...  1.84408361  2.22886287\n",
      "   0.4441354 ]\n",
      " [-3.29458551 -4.7033014   3.57406752 ...  1.84408361  2.22886287\n",
      "   0.4441354 ]\n",
      " [-3.29458551 -4.7033014   3.57406752 ...  1.84408361  2.22886287\n",
      "   0.4441354 ]\n",
      " ...\n",
      " [-4.37477948 -2.63831437  6.22584021 ...  2.91479806  4.0076982\n",
      "   2.10023807]\n",
      " [-4.37477948 -2.63831437  6.22584021 ...  2.91479806  4.0076982\n",
      "   2.10023807]\n",
      " [-4.37477948 -2.63831437  6.22584021 ...  2.91479806  4.0076982\n",
      "   2.10023807]]\n",
      "a2 = [[-2.45235004 -1.82980616  3.57348845 ...  1.90488091  2.25130737\n",
      "   0.45819092]\n",
      " [-2.45235004 -1.82980616  3.57348845 ...  1.90488091  2.25130737\n",
      "   0.45819092]\n",
      " [-2.45235004 -1.82980616  3.57348845 ...  1.90488091  2.25130737\n",
      "   0.45819092]\n",
      " ...\n",
      " [-3.24697257 -0.70433154  6.41723808 ...  3.07693665  4.12090139\n",
      "   2.17862284]\n",
      " [-3.24697257 -0.70433154  6.41723808 ...  3.07693665  4.12090139\n",
      "   2.17862284]\n",
      " [-3.24697257 -0.70433154  6.41723808 ...  3.07693665  4.12090139\n",
      "   2.17862284]]\n",
      "a2 = [[-2.83504458 -3.34145556  3.6210518  ...  1.95542802  2.26820085\n",
      "   0.47157494]\n",
      " [-2.83504458 -3.34145556  3.6210518  ...  1.95542802  2.26820085\n",
      "   0.47157494]\n",
      " [-2.83504458 -3.34145556  3.6210518  ...  1.95542802  2.26820085\n",
      "   0.47157494]\n",
      " ...\n",
      " [-3.96137843 -1.89159431  6.58971716 ...  3.23590722  4.23035972\n",
      "   2.2570456 ]\n",
      " [-3.96137843 -1.89159431  6.58971716 ...  3.23590722  4.23035972\n",
      "   2.2570456 ]\n",
      " [-3.96137843 -1.89159431  6.58971716 ...  3.23590722  4.23035972\n",
      "   2.2570456 ]]\n",
      "a2 = [[-3.00322549 -4.60276027  3.64674035 ...  2.01588972  2.2900379\n",
      "   0.48599658]\n",
      " [-3.00322549 -4.60276027  3.64674035 ...  2.01588972  2.2900379\n",
      "   0.48599658]\n",
      " [-3.00322549 -4.60276027  3.64674035 ...  2.01588972  2.2900379\n",
      "   0.48599658]\n",
      " ...\n",
      " [-4.33013423 -2.74554226  6.78538896 ...  3.40314476  4.3430718\n",
      "   2.33736139]\n",
      " [-4.33013423 -2.74554226  6.78538896 ...  3.40314476  4.3430718\n",
      "   2.33736139]\n",
      " [-4.33013423 -2.74554226  6.78538896 ...  3.40314476  4.3430718\n",
      "   2.33736139]]\n",
      "a2 = [[-0.7633183   0.06640688  3.6217294  ...  2.07534466  2.31085765\n",
      "   0.49925547]\n",
      " [-0.7633183   0.06640688  3.6217294  ...  2.07534466  2.31085765\n",
      "   0.49925547]\n",
      " [-0.7633183   0.06640688  3.6217294  ...  2.07534466  2.31085765\n",
      "   0.49925547]\n",
      " ...\n",
      " [-0.74195534  0.91953639  6.91210188 ...  3.57227633  4.4561686\n",
      "   2.41806745]\n",
      " [-0.74195534  0.91953639  6.91210188 ...  3.57227633  4.4561686\n",
      "   2.41806745]\n",
      " [-0.74195534  0.91953639  6.91210188 ...  3.57227633  4.4561686\n",
      "   2.41806745]]\n",
      "a2 = [[-1.20567235 -0.93099718  3.71037126 ...  2.12791484  2.32568388\n",
      "   0.50882539]\n",
      " [-1.20567235 -0.93099718  3.71037126 ...  2.12791484  2.32568388\n",
      "   0.50882539]\n",
      " [-1.20567235 -0.93099718  3.71037126 ...  2.12791484  2.32568388\n",
      "   0.50882539]\n",
      " ...\n",
      " [-2.02827117  0.33393103  7.09546602 ...  3.73818049  4.56302476\n",
      "   2.49532412]\n",
      " [-2.02827117  0.33393103  7.09546602 ...  3.73818049  4.56302476\n",
      "   2.49532412]\n",
      " [-2.02827117  0.33393103  7.09546602 ...  3.73818049  4.56302476\n",
      "   2.49532412]]\n",
      "a2 = [[-2.19326335 -2.28713402  3.6988089  ...  2.17486608  2.33449666\n",
      "   0.52044156]\n",
      " [-2.19326335 -2.28713402  3.6988089  ...  2.17486608  2.33449666\n",
      "   0.52044156]\n",
      " [-2.19326335 -2.28713402  3.6988089  ...  2.17486608  2.33449666\n",
      "   0.52044156]\n",
      " ...\n",
      " [-3.91399562 -0.56317122  7.23473795 ...  3.90085901  4.66511775\n",
      "   2.57581842]\n",
      " [-3.91399562 -0.56317122  7.23473795 ...  3.90085901  4.66511775\n",
      "   2.57581842]\n",
      " [-3.91399562 -0.56317122  7.23473795 ...  3.90085901  4.66511775\n",
      "   2.57581842]]\n",
      "a2 = [[-1.9983936  -3.9267067   3.67486659 ...  2.23154703  2.35386539\n",
      "   0.53596136]\n",
      " [-1.9983936  -3.9267067   3.67486659 ...  2.23154703  2.35386539\n",
      "   0.53596136]\n",
      " [-1.9983936  -3.9267067   3.67486659 ...  2.23154703  2.35386539\n",
      "   0.53596136]\n",
      " ...\n",
      " [-3.23393386 -1.75427152  7.31773167 ...  4.07394635  4.77669621\n",
      "   2.66109273]\n",
      " [-3.23393386 -1.75427152  7.31773167 ...  4.07394635  4.77669621\n",
      "   2.66109273]\n",
      " [-3.23393386 -1.75427152  7.31773167 ...  4.07394635  4.77669621\n",
      "   2.66109273]]\n",
      "a2 = [[-2.97189224 -1.44604275  3.67083696 ...  2.28673255  2.37247182\n",
      "   0.55013461]\n",
      " [-2.97189224 -1.44604275  3.67083696 ...  2.28673255  2.37247182\n",
      "   0.55013461]\n",
      " [-2.97189224 -1.44604275  3.67083696 ...  2.28673255  2.37247182\n",
      "   0.55013461]\n",
      " ...\n",
      " [-4.8723715  -0.23984184  7.44925725 ...  4.24764944  4.88897895\n",
      "   2.7477237 ]\n",
      " [-4.8723715  -0.23984184  7.44925725 ...  4.24764944  4.88897895\n",
      "   2.7477237 ]\n",
      " [-4.8723715  -0.23984184  7.44925725 ...  4.24764944  4.88897895\n",
      "   2.7477237 ]]\n",
      "a2 = [[ 2.02437594 -2.84668067  3.68439492 ...  2.33651426  2.38810404\n",
      "   0.56404043]\n",
      " [ 2.02437594 -2.84668067  3.68439492 ...  2.33651426  2.38810404\n",
      "   0.56404043]\n",
      " [ 2.02437594 -2.84668067  3.68439492 ...  2.33651426  2.38810404\n",
      "   0.56404043]\n",
      " ...\n",
      " [ 3.53838891 -1.39501088  7.51595972 ...  4.4198513   4.99954395\n",
      "   2.83540205]\n",
      " [ 3.53838891 -1.39501088  7.51595972 ...  4.4198513   4.99954395\n",
      "   2.83540205]\n",
      " [ 3.53838891 -1.39501088  7.51595972 ...  4.4198513   4.99954395\n",
      "   2.83540205]]\n",
      "a2 = [[ -8.83310496  -3.68513387   3.73597319 ...   2.38757799   2.40456682\n",
      "    0.57822745]\n",
      " [ -8.83310496  -3.68513387   3.73597319 ...   2.38757799   2.40456682\n",
      "    0.57822745]\n",
      " [ -8.83310496  -3.68513387   3.73597319 ...   2.38757799   2.40456682\n",
      "    0.57822745]\n",
      " ...\n",
      " [-12.99214893  -1.50722855   7.70285584 ...   4.59230816   5.10976958\n",
      "    2.92459305]\n",
      " [-12.99214893  -1.50722855   7.70285584 ...   4.59230816   5.10976958\n",
      "    2.92459305]\n",
      " [-12.99214893  -1.50722855   7.70285584 ...   4.59230816   5.10976958\n",
      "    2.92459305]]\n",
      "a2 = [[14.2935966  -3.89947026  3.76334846 ...  2.43766663  2.41981635\n",
      "   0.58844406]\n",
      " [14.2935966  -3.89947026  3.76334846 ...  2.43766663  2.41981635\n",
      "   0.58844406]\n",
      " [14.2935966  -3.89947026  3.76334846 ...  2.43766663  2.41981635\n",
      "   0.58844406]\n",
      " ...\n",
      " [17.59485607  3.11886793  7.99583438 ...  4.77499931  5.23382582\n",
      "   3.01865398]\n",
      " [17.59485607  3.11886793  7.99583438 ...  4.77499931  5.23382582\n",
      "   3.01865398]\n",
      " [17.59485607  3.11886793  7.99583438 ...  4.77499931  5.23382582\n",
      "   3.01865398]]\n",
      "a2 = [[ 19.17273799  -2.94162441   4.19253026 ...   2.32615282   2.19933685\n",
      "    0.18062067]\n",
      " [ 19.17273799  -2.94162441   4.19253026 ...   2.32615282   2.19933685\n",
      "    0.18062067]\n",
      " [ 19.17273799  -2.94162441   4.19253026 ...   2.32615282   2.19933685\n",
      "    0.18062067]\n",
      " ...\n",
      " [-12.53416041   0.67701808   8.46050241 ...   4.87887608   5.22082186\n",
      "    2.76966173]\n",
      " [-12.53416041   0.67701808   8.46050241 ...   4.87887608   5.22082186\n",
      "    2.76966173]\n",
      " [-12.53416041   0.67701808   8.46050241 ...   4.87887608   5.22082186\n",
      "    2.76966173]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17114/2941007396.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  exp = np.exp(x)\n",
      "/tmp/ipykernel_17114/2941007396.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  res.append(exp / exp.sum())\n",
      "/tmp/ipykernel_17114/677205509.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  return - np.sum(np.log(z) * y)\n",
      "/tmp/ipykernel_17114/677205509.py:2: RuntimeWarning: invalid value encountered in multiply\n",
      "  return - np.sum(np.log(z) * y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "a2 = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17114/389600865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17114/389600865.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17114/1363522774.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(model, X, y, alpha)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"w2\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdw2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"z\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_17114/677205509.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(z, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "model = init_network(len(word_to_id), 10)\n",
    "\n",
    "n_iter = 100\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "history = [backward(model, X, y, learning_rate) for _ in range(n_iter)]\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(range(len(history)), history, color=\"skyblue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "e16649f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41174.36920437467,\n",
       " 34001.97985689214,\n",
       " 36940.93215854208,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1b8dee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w1': array([[ 2.13567115,  1.56644306, -3.31168808, ..., -1.27881225,\n",
       "         -3.665346  , -0.71643332],\n",
       "        [ 2.94476094,  6.58798465, -1.4649149 , ..., -2.23153483,\n",
       "         -0.37211619, -2.20278355],\n",
       "        [ 0.55475392,  1.25378585,  0.35800644, ..., -1.14515458,\n",
       "         -1.38277165,  0.17231827],\n",
       "        ...,\n",
       "        [-0.3725349 , -0.38839347, -0.72622149, ..., -0.41574326,\n",
       "          0.22873693,  0.41594231],\n",
       "        [ 0.65206881,  0.13455332, -0.77005649, ..., -0.54984952,\n",
       "          0.67393012,  0.74957822],\n",
       "        [-0.06613055,  1.20413236,  0.14463711, ..., -0.24066138,\n",
       "          1.16531767,  0.13553259]]),\n",
       " 'w2': array([[-0.38738713, -0.20646114, -1.97325222, ..., -1.9887021 ,\n",
       "          0.37277566, -0.68325111],\n",
       "        [ 1.07978176,  1.52915627,  1.04595509, ...,  1.44282791,\n",
       "          0.73902303, -0.02384995],\n",
       "        [ 1.66933701, -1.79943934,  0.94013394, ..., -0.23462402,\n",
       "          1.0196433 ,  1.28843454],\n",
       "        ...,\n",
       "        [-1.11376898,  0.75841651,  1.07337967, ..., -1.23886764,\n",
       "          1.32588322, -0.37369725],\n",
       "        [ 0.51986184, -0.25637104, -0.12081685, ...,  0.40536259,\n",
       "          1.04164823,  0.31125386],\n",
       "        [-1.40846999, -1.72980199, -0.61670572, ..., -0.04288887,\n",
       "         -1.08684338, -1.00064972]])}"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "9af89108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.05350373e-05, 2.07845523e-03, 1.52483075e-07, ...,\n",
       "       1.66334004e-04, 9.25094728e-07, 4.76827251e-06])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning = one_hot_encode(word_to_id[\"گرم\"], len(word_to_id))\n",
    "result = forward(model, [learning], return_cache=False)[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24d8bc0e",
   "metadata": {},
   "source": [
    "np.argsort(result)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "910a9318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18,   90,  533, 1048, 1127])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(result)[::-1][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "0a72eddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "آتش\n",
      "ربود\n",
      "فشرد\n",
      "نگار\n",
      "برق\n",
      "درده\n",
      "وان\n",
      "فرید\n",
      "خبر\n",
      "عدم\n"
     ]
    }
   ],
   "source": [
    "for word in (id_to_word[id] for id in np.argsort(result)[::-1][0:10]):\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "47657db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_similarities(word, model, n_similars=10):\n",
    "    try:\n",
    "        learning = one_hot_encode(word_to_id[word]-1, len(word_to_id))\n",
    "    except KeyError:\n",
    "        print(f\"Word = {word} is not in corpus\")\n",
    "        exit()\n",
    "    result = forward(model, [learning], return_cache=False)[0]\n",
    "    for word in (id_to_word[id+1] for id in np.argsort(result)[::-1][0:n_similars]):\n",
    "        print(word)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ecb0269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(model, word):\n",
    "    try:\n",
    "        idx = word_to_id[word] -1\n",
    "    except KeyError:\n",
    "        print(\"`word` not in corpus\")\n",
    "    one_hot = one_hot_encode(idx, len(word_to_id))\n",
    "    return forward(model, one_hot)[\"a1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "35c22cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.003464  , -0.59311171,  0.6253052 , -1.32282204, -0.69900121,\n",
       "        2.49275488, -1.19139365, -1.16855214,  0.6965306 , -0.49444951])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_embedding(model, \"دیو\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "127159ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "خور\n",
      "غلام\n",
      "عشق\n",
      "رقاد\n",
      "قوم\n",
      "عاشق\n",
      "باللقاء\n",
      "منت\n",
      "پارس\n",
      "جوع\n"
     ]
    }
   ],
   "source": [
    "get_word_similarities('عیش', model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "add097d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "معاد\n",
      "نسیم\n",
      "مستفید\n",
      "الکتب\n",
      "شیفته\n",
      "بلا\n",
      "کرده\n",
      "حمرا\n",
      "خواهی_چو\n",
      "اجل\n"
     ]
    }
   ],
   "source": [
    "get_word_similarities('میخانه', model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "bb3e7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جان\n",
      "قوم\n",
      "خور\n",
      "باده\n",
      "چشم\n",
      "زود\n",
      "خواب\n",
      "دل\n",
      "الفناء\n",
      "نظر\n"
     ]
    }
   ],
   "source": [
    "get_word_similarities('بشر', model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "91dcfbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "رو\n",
      "عاطفه\n",
      "عاشق\n",
      "سقف\n",
      "لست\n",
      "قافله\n",
      "درآ\n",
      "گنبد\n",
      "انفک\n",
      "شبت\n"
     ]
    }
   ],
   "source": [
    "get_word_similarities('ویرانه', model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "83a27fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "گنبد\n",
      "گرد\n",
      "آتش\n",
      "بموتی\n",
      "جمیلا\n",
      "نسیم\n",
      "دین\n",
      "الکتب\n",
      "رو\n",
      "اوباش\n"
     ]
    }
   ],
   "source": [
    "get_word_similarities('حلال', model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e36eb26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.87561612, -1.14905166,  0.10131987, -1.86758747],\n",
       "       [-1.55412121,  0.31428543,  1.61102762, -1.25036518]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0759bb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6661623 ,  0.70206294, -0.97759554,  0.75347279],\n",
       "       [-0.7818824 , -0.63595427, -0.05453096,  0.15557554]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(-1, 1, (vocab_size, word_embedding_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94f96c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 16)                128       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 4)                 64        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 192\n",
      "Trainable params: 192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense, Reshape \n",
    "\n",
    " \n",
    "model = Sequential() \n",
    "layer_1 = Dense(16, input_shape = (8,), use_bias=False) \n",
    "model.add(layer_1) \n",
    "# layer_2 = Reshape((16,8)) \n",
    "# model.add(layer_2) \n",
    "layer_3 = Dense(4, use_bias=False) \n",
    "model.add(layer_3) \n",
    "\n",
    "# print(layer_2.input_shape) \n",
    "#(None, 8, 16) \n",
    "# print(layer_2.ouput_shape) \n",
    "#(None, 16, 8)\n",
    "\n",
    "print(model.summary())\n",
    "visualizer(model, format='png', view=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense, Reshape \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
